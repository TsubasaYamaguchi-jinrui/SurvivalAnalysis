[["index.html", "Event History and Survival Analysis Using R 本稿の目的", " Event History and Survival Analysis Using R Tsubasa Yamaguchi 2023-06-04 本稿の目的 本稿はイベント・ヒストリー分析(event history analysis)または生存時間分析（Survival Analysis）と呼ばれる手法の概要をまとめたものである。また、Rでこうした分析を実行する方法についても解説している。新たに個人的に勉強した内容があれば、随時追加していく。 本稿が主に参考にしたのは参考にしたのは Allison (2014) の”Event History and Survival Analysis, Second Edition”である。 また以下の書籍やサイトも参考にした。 杉本 (2021) 生存時間解析. 朝倉書店 大橋 et al. (2021) 生存時間解析 第2版 SASによる生物統計. 東京大学出版 Kurz (2021) Applied longitudinal data analysis in brms and the tidyverse. Survival Analysis in R 疫学のためのRハンドブック Prediction Modeling with the Cox model - all about the baseline hazard なお、本稿の作成に使用したファイルとRのコードは筆者のGithubですべて閲覧できる。 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. Kurz, A. S. (2021). Applied longitudinal data analysis in brms and the tidyverse (version 0.0.2). https://bookdown.org/content/4253/ 大橋靖雄., 浜田知久馬., &amp; 魚住龍史. (2021). 生存時間解析 第2版 SASによる生物統計. 東京大学出版. 杉本知之. (2021). 生存時間解析. 朝倉書店. "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 生存時間解析の実行と結果の描画には以下のパッケージを使用している。 survivalパッケージ flexsurvパッケージ ehaパッケージ metsパッケージ flexsurvパッケージ ggsurvfitパッケージ survminerパッケージ cmprskパッケージ brmsパッケージ rstanarmパッケージ ## 生存時間分析 library(survival) library(eha) library(flexsurv) library(brms) library(rstanarm) library(cmprsk) ## ggplotでの可視化 library(survminer) library(ggsurvfit) ## データハンドリング library(tidyverse) library(haven) library(easystats) ## グラフや表関連 library(patchwork) library(flextable) library(ggeffects) library(DT) library(knitr) library(kableExtra) library(stargazer) library(ggsci) library(lemon) library(ggplotify) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) なお、本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham &amp; Grolemund, 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang, 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al., 2021) 出版社サイト References Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. "],["Chapter1.html", "1 はじめに 1.1 イベントヒストリー分析とは何か 1.2 イベント・ヒストリー分析の難しさ 1.3 イベント・ヒストリー分析の種類", " 1 はじめに 1.1 イベントヒストリー分析とは何か イベント・ヒストリーとは、研究対象である「個体や集団で、ある事象が生じた時間的な記録」を意味する。霊長類学では、個体が何歳で死亡したかや、オスが何年群れに在籍したかといったデータがこれに該当する。イベント・ヒストリー分析(event history analysis)または生存時間分析(survival analysis)1は、イベント・ヒステリーを持つデータを用いて、事象の発生パターンや発生の原因を分析する一連の手法である。例えば霊長類の研究では、個体の寿命に影響する要因を調べたり(Ellis et al., 2019; Silk et al., 2010; Thompson &amp; Cords, 2018; Tung et al., 2016)、オスが群れに在籍する確率が時間と共にどう変化するのかを調べたりする(Swedell et al., 2011)ために用いられている。 1.2 イベント・ヒストリー分析の難しさ イベント・ヒストリーを持つデータの分析が難しい要因としては、扱うデータに以下の2つの特殊性があることが多いことが挙げられる。イベント・ヒストリー分析では、これらの困難に対処するため様々な手法が研究されてきた。 1.2.1 打ち切り イベント・ヒステリーを持つデータの特殊性の一つは、打ち切りが存在する点である。 具体例として、 Rossi et al. (1980) のデータを見ていこう。この研究では、432名の服役囚が出所後12ヶ月間に再逮捕されるかどうかを調べ、それに年齢や人種、学歴、配偶状態などの要因が影響しているかを調べようとしている。変数の詳細は、こちらを参照。 Rossi &lt;- read_csv(&quot;data/Rossi.csv&quot;) Rossi %&gt;% head(20) %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 実際にデータからランダムに抽出した20人が再逮捕されたかどうかを見ていこう(図1.1)。arrestは再逮捕されたかどうかを0/1で、weekは再逮捕された場合出所後何週間目だったかを表している。図からわかるように、12ヶ月(52週)経過後も逮捕されていないデータが数多く存在することが分かる。 Rossi %&gt;% sample_n(20) %&gt;% mutate(id = row_number()) %&gt;% mutate(arrest = as.factor(arrest)) %&gt;% ggplot(aes(x = week, y = id))+ geom_segment(aes(x = 0, xend = week, yend = id, y = id), color = &quot;grey&quot;)+ geom_point(shape = 23, size = 3, aes(fill = arrest))+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1) 図1.1: 服役囚が出所後何週間で逮捕されたか このようなデータは、通常の分析ではデータを扱うのが難しい。なぜなら、再逮捕されなかった服役囚に適切に従属変数(応答変数ともいう)2を割り当てることができないからである。彼らは10年たっても再逮捕されなかったかもしれないし、出所後13ヶ月に再逮捕されていたかもしれないが、このデータから知ることは不可能である。彼らに一律に同じ値を割り振っても（例えば期間の最大値である1年を割り振る）、彼らのデータを除外してもデータに大きなバイアスがかかってしまう。 このように、測定値が不完全にしかわからないデータを打ち切りデータという。打ち切りには、上記のように(1)調査終了時点ではまだイベントが起きていない場合と、(2)何らかの事情(e.g., 予期せぬ死、消息不明など)で調査期間の途中でその個体のデータが追跡できなくなっている場合(= 脱落)の2種類が存在する。 1.2.2 時間依存共変量 もう一つの特殊性は、対象の期間中に独立変数(説明変数ともいう)の値が変化する場合があることである（＝時間依存共変量）。 例えば、先ほどの例でも対象の12ヶ月の間に仕事の有無が変化していた(emp1~emp52)。こうした場合、回帰モデルに1ヶ月ごとの仕事の有無（e.g., 1ヶ月目の仕事の有無、2ヶ月目の仕事の有無、…）をすべて独立変数として入れることはできるが、この方法では出所後12ヶ月以内に再逮捕された服役囚に対して独立変数を割り振れないところが出てくる。なぜなら、出所後3ヶ月で再逮捕されたとすると、その服役囚の4ヶ月目以降の仕事のデータはないからである。 1.3 イベント・ヒストリー分析の種類 イベント・ヒストリー分析の手法は以下のような点を基準に分類される。本稿では、まず単純なモデルの説明から始め、徐々に難しいモデルの説明へ移る。 1.3.1 繰り返しの有無 生物学で扱うことの多い「死」という事象は一個体に一度しか生じないが、転職や結婚といった事象を扱う場合、これらは個人の一生において何度も発生する可能性がある。繰り返しの阿辻賞を扱う際にはより複雑な分析モデルが必要になる。 1.3.2 単一の事象と複数の事象 例えば生物の生死を扱うとき、多くの場合では死亡のタイプ（e.g., 死因など）を区別せず単一の死亡として扱う。しかし、死亡のタイプを分けて分析を行うことも可能である。このような複数の事象を扱うためには、単一な事象を扱う分析よりも複雑なモデルが必要である。 1.3.3 パラメトリック法とノンパラメトリック法 分析には、事象の発生時間の分布（どのような時間間隔で事象が発生するか）に仮定を置かないノンパラメトリックな分析と、特定の分布族（e.g., 指数分布、ワイブル分布など）を仮定するパラメトリックな分析がある。また、これら2つを結合したCoxの比例ハザードモデルは事象の発生時間に特定の分布を仮定しないが、線形関数に基づく回帰モデルであるというという点でセミパラメトリックな手法であるといえる。 1.3.4 離散時間と連続時間 事象の発生時間が正確に記録できている場合は「連続時間」モデルといわれる。通常は、時間の測定単位が小さい場合は（時間、分、秒）、連続時間として扱ってよい。一方、時間の測定単位が大きい場合（月、年）は「離散時間」モデルで扱うのが適している。実際の分析では離散時間モデルの方が理解するのが容易である。 References Ellis, S., Snyder-Mackler, N., Ruiz-Lambides, A., Platt, M. L., &amp; Brent, L. J. N. (2019). Deconstructing sociality: The types of social connections that predict longevity in a group-living primate. Proc. Biol. Sci., 286(1917), 20191991. Rossi, P. H., Berk, R. A., &amp; Lenihan, K. J. (1980). Money, work and crime: Some experimental results. New York: Academic Press. Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C., Engh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth, R. M., &amp; Cheney, D. L. (2010). Strong and consistent social bonds enhance the longevity of female baboons. Curr. Biol., 20(15), 1359–1361. Swedell, L., Saunders, J., Schreier, A., Davis, B., Tesfaye, T., &amp; Pines, M. (2011). Female “dispersal” in hamadryas baboons: Transfer among social units in a multilevel society. Am. J. Phys. Anthropol., 145(3), 360–370. Thompson, N. A., &amp; Cords, M. (2018). Stronger social bonds do not always predict greater longevity in a gregarious primate. Ecol. Evol., 8(3), 1604–1614. Tung, J., Archie, E. A., Altmann, J., &amp; Alberts, S. C. (2016). Cumulative early life adversity predicts longevity in wild baboons. Nat. Commun., 7. このような分析手法は様々な分野で発展してきたため、分野ごとに呼ばれ方が異なる。例えば生物学では動物の寿命を扱うことが多いため「生存時間分析」、工学の分野では機械の故障を扱うことが多いため「故障時間分析」などと呼ばれる。「イベント・ヒストリー分析」という呼び方は、こうした様々な分野で発展した分析手法の包括的な呼称である。↩︎ 従属変数、独立変数がわからない場合はこちらを参照。↩︎ "],["Chapter2.html", "2 パラメトリックな離散時間モデル 2.1 離散時間モデルの例 2.2 離散時間ハザード 2.3 ロジスティック回帰モデル 2.4 モデルの推定 2.5 Rでの実装 2.6 尤度比検定 2.7 離散時間ロジスティック回帰モデルの注意点 2.8 打ち切りデータの扱い 2.9 離散時間モデルと連続時間モデル", " 2 パラメトリックな離散時間モデル 本章では、繰り返しのない単一の事象を離散時間モデルで分析するパラメトリックな方法を概観する。 2.1 離散時間モデルの例 ここでは具体例として、1950年代後半から60年代前半に博士号を取得した生化学者301人(助教として勤務経験あり)が准教授に昇進するのに要する年数を記録したデータを使用する。データはdataフォルダにある(rank.dta)。dta形式のファイルは、havenパッケージのread_dta()で読み込める。 library(haven) rank &lt;- read_dta(&quot;data/rank.dta&quot;) データの先頭10行を取り出すと以下のようになっている。変数の説明は以下の通り。 ここでは、独立変数を用いて1年ごとの昇進の条件付き確率を回帰モデルを用いて推定することを目的とする。 従属変数にかかわる変数 - dur: 助教としての勤続年数 - promo: 助教への昇進の有無 独立変数(非時間依存変数) - undgrad: 対象者の出身学部の選抜の厳しさの尺度 - phdprest: 博士号を取得した大学の威信の尺度 - phdmed: 医学博士の有無 独立変数(時間依存変数) - prest: 勤務している大学の威信の尺度 - arts: 勤続年数ごとの累積発表論文数 - cits: 勤続年数ごとの論文の累積被引用回数 そのほか jobtime: 職場を変わった場合、何年目に変わったか rank %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 准教授への昇進時期の分布は以下のようになる(表2.1)。なお、リスク集合(risk set)とは、各時点で事象を経験する可能性のある個体の集まり、ハザード率(hazard rate)とは、ある時点でリスク集合に入っている個体がその時点で事象を経験する条件付き確率である(i.e., この表では昇進人数/リスク集合の大きさ)。 打ち切りは、25人については10年たっても准教授に昇進できていないために生じているが、それ以外については大学を離れたために生じている。 rank %&gt;% group_by(dur) %&gt;% summarise(昇進人数 = sum(promo), 打ち切り数 = sum(promo == &quot;0&quot;)) %&gt;% rename(勤続年数 = dur) %&gt;% ungroup() -&gt; hyou1 hyou1 %&gt;% mutate(勤続年数 = 勤続年数+1) %&gt;% mutate(N = 昇進人数 + 打ち切り数) %&gt;% mutate(sum = cumsum(N)) -&gt; hyou1_b hyou1 %&gt;% left_join(hyou1_b %&gt;% select(勤続年数, sum)) %&gt;% replace_na(list(sum = 0)) %&gt;% mutate(リスク集合の大きさ = sum(昇進人数 + 打ち切り数) - sum) %&gt;% select(-sum) %&gt;% mutate(推定されたハザード率 = 昇進人数/リスク集合の大きさ) %&gt;% kable(align = &quot;c&quot;, caption = &quot;准教授への昇進時期の分布&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.1: 准教授への昇進時期の分布 勤続年数 昇進人数 打ち切り数 リスク集合の大きさ 推定されたハザード率 1 1 1 301 0.0033223 2 1 6 299 0.0033445 3 17 12 292 0.0582192 4 42 10 263 0.1596958 5 53 9 211 0.2511848 6 46 7 149 0.3087248 7 31 6 96 0.3229167 8 15 2 59 0.2542373 9 7 6 42 0.1666667 10 4 25 29 0.1379310 2.2 離散時間ハザード イベント・ヒストリー分析では、上でも説明した「リスク集合」と「ハザード率」の二つが重要な概念である。分析ではハザード率を従属変数として、それぞれの独立変数がハザード率に与える影響を分析していく。 2.3 ロジスティック回帰モデル 離散時間モデルでは、ロジット変換3を利用することでハザード関数\\(P(t)\\)を以下のようにあらわす。なお、\\(x_1\\)は非時間依存変数を、\\(x_2(t)\\)は時間依存変数を表す。また、\\(t\\)は勤続年数を表す。\\(b_1\\)と\\(b_2\\)は偏回帰係数と呼ぶ。ロジット変換を施すことで、右辺がどのような値も取っても\\(P(t)\\)が0から1の範囲に収まる。 \\[ \\begin{equation} log\\biggl(\\frac{P(t)}{1-P(t)}\\biggl) = b_0 + b_1x_1 + b_2x_2(t) + b_3t + b_4t^2 \\tag{2.1} \\end{equation} \\] 2.4 モデルの推定 次に、データを基にパラメータ(\\(b_1から b_4\\))を推定する。推定は基本的に最尤法を用いて行う。これは、実際に観察された値が得られる確率が最大になるようにパラメータを推定する方法である。 実際の推定手順は以下のようになる。 各個体がリスク集合に入っている期間をある時間単位で分け(今回は1年)、その1単位ごと(= 人年ごと)に事象の発生を記録していく。 各個体は各単位ごとに(この場合は1年ごとに)昇進した場合は従属変数に1を、してない場合は0を割り当てられる。 データセットを作成し、最尤法を用いてロジスティック回帰モデルのパラメータを推定する。 2.5 Rでの実装 2.5.1 データの加工 それでは、Rで実際にモデルのパラメータを推定してみる。分析をするためには、データフレームを縦長にする必要がある。具体的には、発表論文数(art1art10)と被引用数(cit1cit10)をそれぞれ一列にする必要がある。 rank %&gt;% ## 個体IDの列を作成 rowid_to_column(var = &quot;id&quot;) %&gt;% ## 勤続年数ごとの論文数を一列に pivot_longer(cols = art1:art10, names_to = &quot;art&quot;, values_to = &quot;art_n&quot;) %&gt;% ## 欠損値を除く filter(!is.na(art_n)) %&gt;% arrange(id) %&gt;% ## 行番号を作る rowid_to_column(&quot;rowid&quot;) %&gt;% select(-(cit1:cit10), -art) -&gt; rank2 rank %&gt;% ## 個体IDの列を作成 rowid_to_column(var = &quot;id&quot;) %&gt;% ## 勤続年数ごとの引用数を一列に pivot_longer(cols = cit1:cit10, names_to = &quot;cit&quot;, values_to = &quot;cit_n&quot;) %&gt;% ## 欠損値を除く filter(!is.na(cit_n)) %&gt;% arrange(id) %&gt;% ## 行番号を作る rowid_to_column(&quot;rowid&quot;) %&gt;% select(cit_n, rowid) -&gt; rank3 ## 結合 rank2 %&gt;% inner_join(rank3, by = &quot;rowid&quot;) %&gt;% arrange(id) %&gt;% group_by(id) %&gt;% ## 個体ごとに勤続年数の列を作成 mutate(year = row_number()) %&gt;% ## 変数promoが昇進のあった年のみ1をとるようにする ungroup() %&gt;% mutate(promo = ifelse(year &lt; dur,0,promo)) %&gt;% ## jobtimeの欠損値を0に replace_na(list(jobtime = 0)) %&gt;% ## 大学威信度の列を作成 mutate(jobpres = ifelse(year &lt; jobtime, prest1, prest2)) %&gt;% select(-prest1, -prest2)-&gt; rank4 できたデータシートは以下の通り。 datatable(rank4, options = list(scrollX = 100), rownames = FALSE) 2.5.2 分析 それでは、実際に分析する。分析には一般化線形モデルによる分析ができるglm()関数を用いる。 まずは1つ目のモデルとして、勤続年数を入れない線形モデルを考えてみる。 mod1 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n, data = rank4, family = binomial(link = &quot;logit&quot;)) 結果は以下の通り(表2.2)。 model_parameters(mod1) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod1の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.2: mod1の結果 Parameter Coefficient 95%CI SE z p (Intercept) -2.9636747 [-3.80, -2.15} 0.4210727 -7.0383926 0.0000000 undgrad 0.1802769 [0.06, 0.30} 0.0607534 2.9673535 0.0030038 phdmed -0.2650547 [-0.58, 0.05} 0.1614778 -1.6414308 0.1007080 phdprest -0.0029980 [-0.18, 0.17} 0.0886335 -0.0338249 0.9730168 jobpres -0.2535299 [-0.46, -0.05} 0.1054517 -2.4042272 0.0162067 art_n 0.1270934 [0.10, 0.16} 0.0165769 7.6669053 0.0000000 cit_n -0.0014547 [-0.00, 0.00} 0.0012590 -1.1554230 0.2479173 2つ目のモデルとして、勤続年数とその二乗を説明変数に入れたモデルを考える。 mod2 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + year + I(year^2), data = rank4, family = &quot;binomial&quot;) 結果は以下の通り(表2.3)。 model_parameters(mod2) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod2の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.3: mod2の結果 Parameter Coefficient 95%CI SE z p (Intercept) -8.4846678 [-10.07, -7.02} 0.7756586 -10.9386630 0.0000000 undgrad 0.1939331 [0.07, 0.32} 0.0635127 3.0534551 0.0022622 phdmed -0.2356943 [-0.57, 0.10} 0.1717631 -1.3722061 0.1699993 phdprest 0.0270565 [-0.16, 0.21} 0.0931669 0.2904086 0.7715036 jobpres -0.2535406 [-0.48, -0.03} 0.1138113 -2.2277268 0.0258987 art_n 0.0733840 [0.04, 0.11} 0.0181374 4.0459977 0.0000521 cit_n 0.0001255 [-0.00, 0.00} 0.0013125 0.0956291 0.9238152 year 2.0818890 [1.65, 2.56} 0.2337665 8.9058484 0.0000000 I(year^2) -0.1585829 [-0.20, -0.12} 0.0203027 -7.8109434 0.0000000 2つのモデルを比較すると以下の通り。 stargazer(mod1, mod2, type = &quot;text&quot;) ## ## ============================================== ## Dependent variable: ## ---------------------------- ## promo ## (1) (2) ## ---------------------------------------------- ## undgrad 0.180*** 0.194*** ## (0.061) (0.064) ## ## phdmed -0.265 -0.236 ## (0.161) (0.172) ## ## phdprest -0.003 0.027 ## (0.089) (0.093) ## ## jobpres -0.254** -0.254** ## (0.105) (0.114) ## ## art_n 0.127*** 0.073*** ## (0.017) (0.018) ## ## cit_n -0.001 0.0001 ## (0.001) (0.001) ## ## year 2.082*** ## (0.234) ## ## I(year2) -0.159*** ## (0.020) ## ## Constant -2.964*** -8.485*** ## (0.421) (0.776) ## ## ---------------------------------------------- ## Observations 1,741 1,741 ## Log Likelihood -595.566 -506.013 ## Akaike Inf. Crit. 1,205.132 1,030.025 ## ============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 2.5.3 結果の解釈 モデル1(mod1)では(表2.2)、3つの独立変数が有意に准教授への昇進のハザード率に影響していることが分かる(undgrad、jobpres、art_n)。具体的には、より選抜度合いの高い大学を卒業した生化学者とより多くの論文を発表した生化学者はハザード率が高い。一方で、より威信度の高い大学で現在働いている生化学者ほどハザード率は低い。 各変数が1増加したときに、准教授に昇進するオッズ比(\\(\\frac{P(t)}{1-P(t)}\\))がどの程度増加するかを計算すると(これは、\\(e^{偏回帰係数}\\)で求まる。式(2.1)を参照)、以下のようになる。すなわち、「学部選抜度(undgrad)」が1増えるとオッズ比が約1.2倍に、「累積論文発表数(art_n)」が1増えるとオッズ比が約1.14倍になる。一方、「勤務先の大学の威信度(jobpres)」が1増加すると、オッズ比は0.78倍に減少する。 model_parameters(mod1) %&gt;% data.frame() %&gt;% select(Parameter, Coefficient) %&gt;% mutate(odds = exp(Coefficient)) ## Parameter Coefficient odds ## 1 (Intercept) -2.963674661 0.05162885 ## 2 undgrad 0.180276920 1.19754894 ## 3 phdmed -0.265054700 0.76716399 ## 4 phdprest -0.002998022 0.99700647 ## 5 jobpres -0.253529874 0.77605656 ## 6 art_n 0.127093447 1.13552312 ## 7 cit_n -0.001454692 0.99854637 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.1)。曲線はモデルに基づく回帰曲線を、塗りつぶし部分は95%信頼区間を表す。 fit_mod1_a &lt;- ggpredict(mod1, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod1_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit1_a fit_mod1_b &lt;- ggpredict(mod1, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod1_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit1_b p_fit1_a + p_fit1_b 図2.1: モデル1の推定結果 モデル2も結果自体は大きく変わらないが、勤続年数とその二乗が有意に影響していることが分かる。また、「累積論文発表数(art_n)」の偏回帰係数が大幅に小さくなっており、オッズ比も1.14倍から1.08倍に減少している。 model_parameters(mod2) %&gt;% data.frame() %&gt;% select(Parameter, Coefficient) %&gt;% mutate(odds = exp(Coefficient)) ## Parameter Coefficient odds ## 1 (Intercept) -8.4846678008 0.000206612 ## 2 undgrad 0.1939331150 1.214015081 ## 3 phdmed -0.2356943107 0.790022138 ## 4 phdprest 0.0270564703 1.027425820 ## 5 jobpres -0.2535405982 0.776048238 ## 6 art_n 0.0733840049 1.076143702 ## 7 cit_n 0.0001255168 1.000125525 ## 8 year 2.0818890246 8.019603843 ## 9 I(year^2) -0.1585829127 0.853352207 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.2)。左図の傾きが図2.1に比べて緩やかになっており、図からもモデル1との違いが読み取れる。 fit_mod2_a &lt;- ggpredict(mod2, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod2_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit2_a fit_mod2_b &lt;- ggpredict(mod2, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod2_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit2_b p_fit2_a + p_fit2_b 図2.2: モデル2の推定結果 2.6 尤度比検定 あるモデルが別のモデルの「入れ子」構造(一方のモデルが他方のモデルの独立変数をすべて含む)であるとき、尤度比検定によってどちらの方が適合度が高いか検定を行うことができる。2つのモデルの対数尤度の差の2倍が\\(\\chi^2\\)分布に近似できることを利用して帰無仮説検定を行うことが多い4。 Rでは以下のように行う。結果を見ると、モデル2の方が有意に適合度が高いことが分かる。 このような検定は、本稿で以後出てくるモデルやパラメータの検定にも応用可能である。 anova(mod1,mod2, test = &quot;Chisq&quot;) ## Analysis of Deviance Table ## ## Model 1: promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n ## Model 2: promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + ## year + I(year^2) ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 1734 1191.1 ## 2 1732 1012.0 2 179.11 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.7 離散時間ロジスティック回帰モデルの注意点 上記のモデルにはいくつか注意点がある。 一個体が複数の事象を経験する場合は、事象の回数の影響を修正する必要がある。 ロバスト推定による標準誤差を求めたり、一般化推定式やランダム(変量)効果モデルを用いたりする。 区切る時間単位を適切に設定する必要がある。 今回は、准教授の昇進が各年度の初めに行われるため、1年ごとにデータを区切ることは適切であった。これを1日ごとに区切るとデータが膨大になってしまうし、５年ごとに区切ると多くの情報が失われてしまう。分析対象の事象に応じて、適切に区切る時間単位を適切に設定する必要がある。 代替手法 式(2.1)は独立変数のハザード率に対する影響を検討する最も知られた方法だが、以下の「補対数対数モデル」も代替手法として有用である。このモデルでも、右辺がどのような値をとろうと\\(P(t)\\)は0から1に収まる。 \\[ \\begin{equation} log[-log(1-P(t))] = b_0 + b_1x_1 + b_2x_2(t) + b_3t + b_4t^2 \\tag{2.2} \\end{equation} \\] Rでは、以下のように実装できる。 mod3 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + year + I(year^2), data = rank4, family = binomial(link = &quot;cloglog&quot;)) 結果は以下の通り(表2.4)。ロジスティック回帰モデルと結果は大きく変わらない。特にP値だけに着目する場合はどちらのモデルを選んでも決定的な差はない。 model_parameters(mod3) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod3の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.4: mod3の結果 Parameter Coefficient 95%CI SE z p (Intercept) -7.9961202 [-9.40, -6.69} 0.6943534 -11.5159220 0.0000000 undgrad 0.1694896 [0.06, 0.28} 0.0548959 3.0874751 0.0020186 phdmed -0.2153786 [-0.50, 0.08} 0.1469985 -1.4651751 0.1428732 phdprest 0.0100102 [-0.15, 0.17} 0.0806278 0.1241530 0.9011941 jobpres -0.1934044 [-0.38, -0.01} 0.0967829 -1.9983313 0.0456808 art_n 0.0623539 [0.03, 0.09} 0.0142864 4.3645723 0.0000127 cit_n -0.0004238 [-0.00, 0.00} 0.0010398 -0.4075788 0.6835830 year 1.9223437 [1.53, 2.36} 0.2128381 9.0319539 0.0000000 I(year^2) -0.1469834 [-0.19, -0.11} 0.0184860 -7.9510496 0.0000000 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.3)。 fit_mod3_a &lt;- ggpredict(mod3, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod3_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit3_a fit_mod3_b &lt;- ggpredict(mod3, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod3_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit3_b p_fit3_a + p_fit3_b 図2.3: モデル3の推定結果 2.8 打ち切りデータの扱い 今回のデータでは打ち切りは以下の2通りで生じており、これらは「右側打ち切り(right censoring)」と呼ばれ、最後に対象が観察された時点で事象がまだ発生していないことによるものである。 10年経ってもまだ准教授に昇進していない(= 固定打ち切り(fixed censoring))) 打ち切りの時点は全ての個体で同じ。 准教授昇進前に大学を辞めた(= ランダムな打ち切り(random censoring)) 打ち切りの時点は個体によって異なる。脂肪や転居による追跡の終了などが理由。ただし、「ランダム」とは打ち切りのタイミングが変数と一切関係ないという意味でない点に注意。 2の場合、ほぼすべてのイベント・ヒストリー分析では打ち切りが生じた時間は「無情報」であると仮定している。すなわち、特定の時点である個体に打ち切りが生じても、その個体のハザード率には何の要因も影響していないことを仮定している。この仮定は、今回の例では昇進の可能性の低い研究者ほど大学を辞める傾向があるのであれば妥当ではない。おそらく何人かは准教授に昇進できずに雇用期間が終了したことが打ち切りの原因になっていたと考えられる。 しかし、今のところこの仮定を緩めて分析する方法はなく、ほとんどの研究者はこの問題に目をつぶって分析を行うしかない。そのため、研究デザインの段階でランダムでない打ち切りを最小限にするために可能な限りあらゆることを行う必要がある。 2.9 離散時間モデルと連続時間モデル 一般的に、離散時間モデルは後述する連続時間モデルと極めて似た結果をもたらすことが多い。実際、式(2.1)の離散時間モデルは、時間の単位を小さくするにつれて第4章で見る比例ハザードモデルに近づく。したがって、離散時間モデルと連続時間モデルのいずれを用いるかは一般的に計算にかかる手間と簡便さを考慮して判断する。時間依存の独立変数がない場合、しばしば以降の2つの章で説明する連続時間モデルを使う方が簡単である。他方、時間依存の独立変数があるならば、いずれのモデルでも手間や簡便さは変わらない。 References 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 粕谷英一. (2012). 一般化線形モデル. 共立出版. ロジット変換がわからない方はこちら。 ↩︎ 対数尤度や尤度比検定の詳細については、 粕谷 (2012) や 久保 (2012) を参照。パラメトリックブーストラップ法を用いたより正確な検定を行うこともできる(久保, 2012)。↩︎ "],["Chapter3.html", "3 連続時間を用いたパラメトリックな手法 3.1 連続時間ハザード率 3.2 パラメトリックな比例ハザードモデル 3.3 加速時間ハザードモデル 3.4 Rでの実装 3.5 適合度の評価 3.6 観察されない異質性の原因 3.7 なぜパラメトリックモデルを用いるのか", " 3 連続時間を用いたパラメトリックな手法 前章(2)の離散時間モデルは汎用性が高いが、イベント・ヒストリー分析では連続時間モデルが使われることが多い。本章では、事象が起きた時点が正確に記録されているデータに対して一般的に使われるパラメトリックな手法を解説する。この方法では、推定されるパラメータを除いて、モデルに含まれる値の分布の型がはっきり仮定される。 3.1 連続時間ハザード率 連続時間モデルでは、時点\\(t\\)で事象を経験する可能性のある個体が、時点\\(t\\)から\\(t+s\\)までの間に事象を経験する確率\\(P(t,t+s)\\)を考える。なお、\\(t=1\\)のとき、これは離散時間のハザード率と同じになる。 この確率を\\(s\\)で割り、\\(s\\)を0に限りなく近づけたときの極限値が連続時間のハザード率になる(式(3.1))。この値は、1より大きな値をとることもあるが負にはならない。 \\[ h(t) = \\lim_{s \\to 0} \\frac{P(t,t+s)}{s} \\tag{3.1} \\] ハザード関数\\(h(t)\\)の形によって連続時間のイベント・ヒストリー分析のタイプが分類できる。 3.2 パラメトリックな比例ハザードモデル 3.2.1 モデルの分類 パラメトリックな分析には、「比例ハザードモデル(proportional hazards model)」と「加速時間ハザードモデル(accelerated failure time model)」の2種類があるが、本節では前者について解説する。 比例ハザードモデルは、ハザード関数が時間と独立変数によってどのように規定されるかによって、以下の3つに分類できる。なお、いずれのモデルでもパラメータの推定は最尤法で行う。 3.2.1.1 指数回帰モデル 最もわかりやすい分析は、\\(h(t)\\)を独立変数の線形関数にすることである(式(3.2))。左辺で\\(log\\)をとっているのは、線形関数が0より小さくならないようにするためである。\\(x_1\\)と\\(x_2\\)は非時間依存の独立変数を、\\(b_0\\)~\\(b_2\\)は推定されるパラメータを表す。なかでも\\(b_1\\)と\\(b_2\\)は偏回帰係数である。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 \\tag{3.2} \\] この式ではハザード関数は時間に依存しない(= 時間に対して一定)。このようなモデルでは通常事象が発生するまでの時間として指数分布5を仮定するので、「指数回帰モデル」といわれる。指数分布の確率密度関数は1つのパラメータ\\(\\lambda\\)を用いて以下のように表せる。ハザード率は一定の値\\(\\lambda\\)で与えられる。 \\[ f(t) = \\lambda e^{-\\lambda t} \\;\\; (t \\geq 0) \\tag{3.3} \\] 3.2.1.2 ゴンぺルツ回帰モデル 一般的に、ハザード率が時間を通して一定であると仮定するのは現実的でない。例えば生物の死を考えると、老化するほど死亡する確率は増大するはずである。そこで、指数回帰モデルの仮定を緩め、ハザード率の対数(log)が時間と共に直線的に増加/現象すると仮定するモデルを考える(式(3.4))。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + ct \\tag{3.4} \\] このようなモデルでは通常事象が発生するまでの時間としてゴンぺルツ分布6を仮定するので、「ゴンぺルツ回帰モデル」といわれる。ゴンぺルツ分布の確率密度関数は２つのパラメータ\\(a\\)と\\(b\\)を用いて以下のように表せる。ハザード率は\\(ae^{bt}\\)で与えられる。 \\[ f(t) = a exp(at - \\frac{a}{b}e^{bt} + \\frac{a}{b}) \\;\\;(t \\geq 0) \\tag{3.5} \\] 3.2.1.3 ワイブル回帰モデル あるいは、ハザード率の対数が時間の対数と共に直線的に増加/減少するモデルを考えることもできる(式(3.6))。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + clog(t) \\tag{3.6} \\] このようなモデルでは通常事象が発生するまでの時間としてワイブル分布7を仮定するので、「ワイブル回帰モデル」といわれる。ワイブル分布の確率密度関数は２つのパラメータ\\(a\\)と\\(b\\)を用いて以下のように表せる。ハザード率は\\(\\frac{a}{b^a} t^{a-1}\\)で与えられる。なお、式からわかるように指数分布はワイブル分布で\\(a=1\\)のときである(\\(\\lambda = 1/b\\))。 \\[ f(t) =\\frac{a}{b} \\biggl(\\frac{t}{b}\\biggl)^{a-1} exp\\biggl(-\\biggl(\\frac{t}{b}\\biggl)^a\\biggl) \\;\\;(t \\geq 0) \\tag{3.7} \\] 3.2.2 注意点 時間と独立変数の間の交互作用がない \\(x_1\\)と\\(x_2\\)の効果(\\(b_1\\)と\\(b_2\\))は全ての時点で同じである。 ワイブル回帰モデルもゴンぺルツ回帰モデルも時間に対して単調増加/減少である ハザード率と時間の関係がU字型や逆U字型になることはない。これは、実際の分析では使いにくい場合がある。なお、次節(3.3)でこの制約のないモデルを検討する。 誤差項がない ただし、実際に事象が発生するまでの時間とモデルで推定される時間には誤差が含まれるので、決定論的なモデルではない。 3.2.3 Rでの実装 3.2.3.1 データの読み込み まず、分析に用いる第1章で触れた服役囚の再販データを読み込む。このデータでは、432人の元服役囚の内、ランダムに選ばれた半分は経済的支援を受け、残りの半分は対照群として支援を受けなかった。変数の説明は以下の通り。なお、時間依存的な変数は本章では扱わず、次章で扱う。 従属変数にかかわる変数 - week: 出所後の経過週数 - arrest: 再犯の有無 独立変数(非時間依存変数) - age: 年齢 - race: 黒人か否か(1/0) - mar: 婚姻の有無(1/0) - prio: 前科の数 - paro: 仮釈放か否か(1/0) - wexp: 過去の就業経験の有無(1/0) - fin: 経済的支援の有無(1/0) 独立変数(時間依存変数) - work: 週ごとの就業状態 recid &lt;- read_dta(&quot;data/recid.dta&quot;) recid %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 3.2.3.2 分析の実行 ehaパッケージのphreg関数を用いる。従属変数としては、期間中に事象を経験したかの変数(arrest)と、事象を経験した場合はその時間を、しなかった場合は打ち切りの時間を示す変数(week)を入れる必要がある。 以下のように実行できる。指数分布はワイブル分布で\\(a=1\\)のときなので、dist = \"weibullでshape = 1としてあげればよい。 ## 指数回帰モデル mod_exp &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;, shape = 1) ## ゴンぺルツ回帰モデル mod_gom &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;gompertz&quot;) ## ワイブル回帰モデル mod_wei &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) 結果は以下の通りである。Coefは偏回帰係数の推定値を、Exp(Coef)は偏回帰係数を指数変換したもの(\\(e^{偏回帰係数}\\))を、se(Coef)は偏回帰係数の標準誤差を表している。ゴンぺルツモデルとワイブルモデルの結果では、shapeは確率密度関数(式(3.5)と式(3.7))のパラメータ\\(a\\)の、scale`はパラメータ\\(b\\)の推定値である。 ## 指数回帰モデル mod_exp ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;weibull&quot;, shape = 1) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.366 0.693 0.191 0.055 ## age 24.765 -0.056 0.946 0.022 0.011 ## race 0.872 0.305 1.357 0.308 0.322 ## wexp 0.596 -0.147 0.864 0.212 0.488 ## mar 0.132 -0.427 0.652 0.381 0.263 ## paro 0.622 -0.083 0.921 0.196 0.673 ## prio 2.841 0.086 1.089 0.028 0.002 ## ## log(scale) 4.051 0.586 0.000 ## ## Shape is fixed at 1 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -686.37 ## LR test statistic 31.22 ## Degrees of freedom 7 ## Overall p-value 5.65729e-05 ## ゴンぺルツ回帰モデル mod_gom ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;gompertz&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.381 0.683 0.191 0.046 ## age 24.765 -0.057 0.944 0.022 0.009 ## race 0.872 0.313 1.367 0.308 0.310 ## wexp 0.596 -0.148 0.862 0.212 0.485 ## mar 0.132 -0.435 0.648 0.382 0.255 ## paro 0.622 -0.082 0.921 0.196 0.674 ## prio 2.841 0.092 1.096 0.029 0.001 ## ## log(scale) 3.894 0.311 0.000 ## log(shape) -0.676 0.816 0.408 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -681.14 ## LR test statistic 33.35 ## Degrees of freedom 7 ## Overall p-value 2.27754e-05 ## ワイブル回帰モデル mod_wei ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;weibull&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.382 0.682 0.191 0.046 ## age 24.765 -0.057 0.944 0.022 0.009 ## race 0.872 0.316 1.371 0.308 0.306 ## wexp 0.596 -0.150 0.861 0.212 0.481 ## mar 0.132 -0.437 0.646 0.382 0.253 ## paro 0.622 -0.083 0.921 0.196 0.673 ## prio 2.841 0.092 1.097 0.029 0.001 ## ## log(scale) 3.990 0.419 0.000 ## log(shape) 0.339 0.089 0.000 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -679.92 ## LR test statistic 33.42 ## Degrees of freedom 7 ## Overall p-value 2.2149e-05 3つのモデルから推定されたハザード関数を描画したのが図3.1である。定義通り、指数回帰モデルでは時間に依らずハザード率が一定であることが分かる。なお、これらは全ての独立変数を平均値にしたときのものであり、以後本稿で示されるハザード関数はいずれも同様である。 as.ggplot(~plot(mod_exp, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;exponential model&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_gom, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Gompertz model&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_wei, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Weibull model&quot;, ylim = c(0,0.03))) 図3.1: モデルから推定されたハザード関数 なお、推定された生存曲線(= 時間の経過とともに再犯をしていない元服役囚の数がどのように減っていくかを表したもの)は以下のようになる(図3.2)。ハザード関数と同様に、これらは全ての独立変数を平均値にしたときのものである。 as.ggplot(~plot(mod_exp, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;exponential model&quot;))+ as.ggplot(~plot(mod_gom, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;Gompertz model&quot;))+ as.ggplot(~plot(mod_wei, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;Weibull model&quot;)) 図3.2: モデルから推定された生存曲線 各モデルの偏回帰係数の推定値を比較したものが以下の表である(表3.1)。３つのモデルの推定結果はほとんど変わらない。いずれのモデルでも有意な影響を持っていたのはageとprioであり、finはワイブル回帰モデルのみで有意になった。 偏回帰係数は、ほかの変数の影響を統制したうえでその独立変数が1増加したときにハザード率の対数(式(3.2) ~ 式(3.6)を思い出してほしい)がどの程度増加するかを表している。例えば指数回帰モデルでは、表3.1の偏回帰係数の推定値(Coef(exp))より、他の変数の影響をコントロールしたときに年齢(age)が1歳上がるとハザード率の対数が0.056低下する。より直感的に理解するためには、偏回帰係数を指数変換すればよい(Exp(Coef_exp))。これは、ハザード比と呼ばれ、独立変数が1増加したときにハザード率の比がどの程度変化するかを示している。例えば、経済的援助がある場合(fin = 1)のハザード率は、ない場合(fin = 0)に比べると0.693倍になる。 tibble(Covariate = mod_exp$covar, &quot;Coef(exp)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_exp))[1:7], &quot;Exp(Coef_exp)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_exp)))[1:7], &quot;Coef(gom)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_gom))[1:7], &quot;Exp(Coef_gom)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_gom)))[1:7], &quot;Coef(wei)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_wei))[1:7], &quot;Exp(Coef_wei)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_wei))[1:7])) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;指数分布&quot;,&quot;ゴンぺルツ&quot;, &quot;ワイブル&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-1a0e7682{}.cl-1a063760{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1a0a5bba{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1a0a70fa{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1a0a7104{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1a0a7105{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表3.1: 各モデルの推定値の比較 指数分布ゴンぺルツワイブルCovariateCoef(exp)Exp(Coef_exp)Coef(gom)Exp(Coef_gom)Coef(wei)Exp(Coef_wei)fin-0.3660.693-0.3810.683-0.3820.682age-0.0560.946-0.0570.944-0.0570.944race0.3051.3570.3131.3670.3161.371wexp-0.1470.864-0.1480.862-0.1500.861mar-0.4270.652-0.4350.648-0.4370.646paro-0.0830.921-0.0820.921-0.0830.921prio0.0861.0890.0921.0960.0921.097 指数回帰モデルはワイブル回帰モデルの特殊な場合(\\(a=1\\)の場合)なので、これらのモデルは尤度比検定で適合度を比較することができる。anova()関数はphregクラスには適用できないようだが、自分で対数尤度を求めることで計算することはできる。以下の自作関数8を用いて尤度比検定を行うと、ワイブル回帰モデルの方が有意に適合度が高い。すなわち、ハザード率が時間によって変化すると考える方がより妥当だと考えられる。 anova.phreg &lt;- function(...){ phreg.models &lt;- list(...) log.liks &lt;- NULL n.parameters &lt;- NULL for(i in 1:length(phreg.models)){ log.liks &lt;- c( log.liks, phreg.models[[i]]$loglik[2] ) n.parameters &lt;- c( n.parameters, nrow(phreg.models[[i]]$var) ) } deviance.models &lt;- -2 * log.liks Df &lt;- n.parameters[-1] - n.parameters[-length(log.liks)] lrs &lt;- deviance.models[-length(log.liks)] - deviance.models[-1] p.values &lt;- 1 - pchisq(lrs, Df) lr.test &lt;- cbind(&quot;deviance&quot; = lrs, Df, p.values) lr.test &lt;- rbind(c(NA, NA, NA), lr.test) output &lt;- cbind(&quot;Log likelihood&quot; = log.liks, n.parameters, lr.test) Call &lt;- match.call() # 以下3行は返値の行列に各モデルの名前をつけるための操作だが、 Call$k &lt;- NULL # 訳も分からず AIC.logLik() を真似ているだけなので、 rownames(output) &lt;- as.character(Call[-1L]) # おかしなことをやっているかも return(output) } anova.phreg(mod_exp, mod_wei) ## Log likelihood n.parameters deviance Df p.values ## mod_exp -686.3659 8 NA NA NA ## mod_wei -679.9166 9 12.89875 1 0.000328801 3.3 加速時間ハザードモデル 3.3.1 モデルの概要 加速時間ハザードモデルは、\\(T\\)を事象が発生するまでの時間とするとき、次のように書くことができる。なお、\\(u\\)は誤差項であり、独立変数とは統計的に独立で均一の分散\\(\\sigma^2\\)をもつ。このモデルは、従属変数を\\(logT\\)とする通常のモデルと同じである。 \\[ logT = b_0 + b_1x_1 + b_2x_2 + u \\tag{3.8} \\] モデルでは誤差項\\(u\\)の分布にとしては、正規分布、対数ガンマ分布、ロジスティック分布、極値分布など様々な分布が仮定される。これらの分布を仮定するとき、\\(T\\)はそれぞれ対数正規分布、ガンマ分布、対数ロジスティック分布、ワイブル分布になる(表3.2)。 tibble(&quot;uの分布&quot; = c(&quot;正規分布&quot;,&quot;対数ガンマ分布&quot;,&quot;ロジスティック分布&quot;,&quot;極値分布&quot;), &quot;Tの分布&quot; = c(&quot;対数正規分布&quot;,&quot;ガンマ分布&quot;,&quot;対数ロジスティック分布&quot;,&quot;ワイブル分布&quot;)) %&gt;% kable(caption = &quot;uの分布とTの分布の対応&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.2: uの分布とTの分布の対応 uの分布 Tの分布 正規分布 対数正規分布 対数ガンマ分布 ガンマ分布 ロジスティック分布 対数ロジスティック分布 極値分布 ワイブル分布 加速ハザードモデルでは従属変数を\\(logT\\)ではなくハザード率になるように書き換えることもできるが、複雑な式になる傾向がある。比例ハザードモデルと異なり、対数ロジスティックモデルと対数正規モデルではハザード率は非単調関数(= 時間の経過とともに柔軟に増えたり減ったりする)である。パラメータの推定値は最尤法によって求められる。 3.4 Rでの実装 ここでは、Allison (2014) に倣って再犯データにガンマ分布モデルを当てはめる。分析にはflexsurvパッケージのflexsurvreg()関数を用いる。このパッケージは比例ハザードモデルも含め様々なパラメトリックモデルに対応している。 以下のようにモデリングできる。methodで採用推定を行うアルゴリズムを指定でき、「Nelder-Mead法」「BFGS法」「L-BFGS法」などを選べる。今回はL-BFGS法を用いる mod_gam &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;gamma&quot;, method = &quot;L-BFGS-B&quot;) 結果は以下の通り。比例ハザードモデルと同様に、ageとprioが5%水準で有意な影響を持った(95%信頼区間が0にまたがっていない)。 mod_gam ## Call: ## flexsurvreg(formula = Surv(week, arrest) ~ fin + age + race + ## wexp + mar + paro + prio, data = recid, dist = &quot;gamma&quot;, method = &quot;L-BFGS-B&quot;) ## ## Estimates: ## data mean est L95% U95% se exp(est) L95% ## shape NA 1.51810 1.21665 1.89424 0.17145 NA NA ## rate NA 0.02684 0.01127 0.06392 0.01188 NA NA ## fin 0.50000 -0.28265 -0.56177 -0.00353 0.14241 0.75378 0.57020 ## age 24.59722 -0.03890 -0.07036 -0.00745 0.01605 0.96184 0.93206 ## race 0.87731 0.23924 -0.20559 0.68408 0.22696 1.27029 0.81417 ## wexp 0.57176 -0.13353 -0.43936 0.17229 0.15604 0.87500 0.64445 ## mar 0.12269 -0.34183 -0.88623 0.20257 0.27776 0.71047 0.41221 ## paro 0.61806 -0.05718 -0.34191 0.22756 0.14527 0.94443 0.71041 ## prio 2.98380 0.06740 0.02453 0.11027 0.02187 1.06973 1.02483 ## U95% ## shape NA ## rate NA ## fin 0.99647 ## age 0.99258 ## race 1.98194 ## wexp 1.18802 ## mar 1.22455 ## paro 1.25553 ## prio 1.11658 ## ## N = 432, Events: 114, Censored: 318 ## Total time at risk: 19809 ## Log-likelihood = -680.0054, df = 9 ## AIC = 1378.011 注意が必要なのは、生存時間分析でよく使われる統計ソフト(StataやSAS)とは偏回帰係数の推定値の正負が逆になっている点である。推定値の正負を逆転させ、指数回帰モデルとワイブル回帰モデルの結果と比較したのが表3.3である。指数回帰モデルやワイブル回帰モデルとガンマ分布モデルの偏回帰係数の正負が逆になるのは、前者がハザード率を従属変数にしているのに対し、後者は事象が起きるまでの時間\\(T\\)を従属変数にしているからである。ハザード率が低いほど\\(T\\)は大きくなるので、偏回帰係数の符号は逆になる。 tibble(Covariate = mod_exp$covar, &quot;Coef(exp)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_exp))[1:7], &quot;Exp(Coef_exp)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_exp)))[1:7], &quot;Coef(wei)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_wei))[1:7], &quot;Exp(Coef_wei)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_wei))[1:7]), &quot;Coef(gam)&quot; = sprintf(&quot;%.3f&quot;,-coef(mod_gam))[3:9], &quot;Exp(Coef_gam)&quot; = sprintf(&quot;%.3f&quot;,exp(-coef(mod_gam)))[3:9]) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;指数分布&quot;,&quot;ワイブル&quot;,&quot;ガンマ&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較2&quot;) .cl-4cc144aa{}.cl-4cba6978{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4cbd64fc{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4cbd7ad2{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cbd7ad3{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cbd7adc{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表3.3: 各モデルの推定値の比較2 指数分布ワイブルガンマCovariateCoef(exp)Exp(Coef_exp)Coef(wei)Exp(Coef_wei)Coef(gam)Exp(Coef_gam)fin-0.3660.693-0.3820.6820.2831.327age-0.0560.946-0.0570.9440.0391.040race0.3051.3570.3161.371-0.2390.787wexp-0.1470.864-0.1500.8610.1341.143mar-0.4270.652-0.4370.6460.3421.408paro-0.0830.921-0.0830.9210.0571.059prio0.0861.0890.0921.097-0.0670.935 ガンマ分布モデルでは、指数変換されたExp(Coef_gam)は事象が起きるまでの時間のとして解釈できる。例えば、経済的支援(fin)の偏回帰係数を指数変換した値は1.327だが、これは経済的支援を受けた元服役囚の方がそうでない元服役囚よりも再犯までの時間が32.7%長くなることを表す。 ガンマ分布以外の分布のモデルはehaパッケージのaftreg()関数か、ガンマ分布と同様にflexsurvreg()関数で実行できる。aftreg()の方がStataなどと符号が同じなので使いやすそう？ ## 対数正規分布 mod_lnorm &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;lognormal&quot;) mod_lnorm2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;lognormal&quot;) ## 対数ロジスティックモデル mod_llog &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;loglogistic&quot;) mod_llog2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;llogis&quot;) ## ワイブル分布 mod_wei_acc &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) mod_wei_acc2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) ## flexsurvreg関数で比例ハザードモデルのワイブル回帰モデルをおこなうときは、`dist = &quot;weibullPH&quot;`とする。 モデルから推定されたハザード関数は以下のようになる(図3.3)。 as.ggplot(~plot(mod_lnorm, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log normal&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_llog, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log logistic&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_wei_acc, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Weibull model (AFT)&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03))) 図3.3: モデルから推定されたハザード関数 3.5 適合度の評価 たくさんのモデルがあるが、どのモデルが最も妥当なモデルといえるだろうか?以下では、まったく同じデータを使用しているモデルに限ってその比較方法を見ていく。 1つの目の方法としては、推定されたモデルの対数尤度(= 推定したモデルから観測データが得られる確率の対数)を比較することである。対数尤度は大まかにいえば、推定したモデルが観測データにどの程度当てはまっているかを表す。対数尤度は通常負の値をとるので-2をかけて比較することが多く、小さいほど当てはまりがよい。これはモデルの逸脱度と呼ばれる。 表3.4は各モデルの逸脱度(対数尤度の-2倍)を表したものである。表からわかるように、ワイブル回帰モデルが最も当てはまりが良いが、対数ロジスティックモデルやガンマ分布モデルとの差は大きくない。前述したように、アルモデルが別のモデルの特殊なケースであり、一方が他方の「入れ子構造」になっている場合は尤度比検定で適合度の検定を行うこともできる。 tibble(model = c(&quot;ガンマ分布&quot;, &quot;対数正規分布&quot;, &quot;対数ロジスティック分布&quot;, &quot;ワイブル回帰&quot;, &quot;ゴンぺルツ回帰&quot;, &quot;指数回帰&quot;), 逸脱度 = c(-2*mod_gam$loglik,-2*mod_lnorm$loglik[[2]], -2*mod_llog$loglik[[2]], -2*mod_wei$loglik[[2]], -2*mod_gom$loglik[[2]],-2*mod_exp$loglik[[2]])) %&gt;% kable(caption = &quot;各モデルの逸脱度&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.4: 各モデルの逸脱度 model 逸脱度 ガンマ分布 1360.011 対数正規分布 1366.469 対数ロジスティック分布 1359.877 ワイブル回帰 1359.833 ゴンぺルツ回帰 1362.279 指数回帰 1372.732 対数尤度を適合度の指標として用いる問題点は、推定するパラメータの数が多ければ多いほど対数尤度が高くなってしまうことである9。そこで、その特性を修正するためにパラメータ数による影響を取り除いたものがAIC(赤池情報量規準)やBIC(ベイズ情報量規準)である。なお、\\(L\\)はモデルの対数尤度を、\\(k\\)はパラメータ数を、\\(n\\)はデータ数を表す。\\(log(n)\\)は通常2より大きいので、BICのほうがよりパラメータの数の影響を強く修正している。これらいずれもは予測の良さを重視した指標で、いずれも小さいほど予測がいいことを表す。 \\[ \\begin{align} AIC &amp;= -2log(L) + 2k\\\\ BIC &amp;= -2log(L) +klog(n) \\end{align} \\] AICとBICは以下の自作関数で容易に求められる。 AICreg &lt;- function(mod, k = 2){ if(class(mod) == &quot;flexsurvreg&quot;){ loglik &lt;- mod_gam$loglik n_parameters &lt;- mod$npars AIC &lt;- -2*loglik + k*n_parameters }else{ loglik &lt;- mod$loglik[[2]] n_parameters &lt;- nrow(mod$var) AIC &lt;- -2*loglik + k*n_parameters } return(AIC) } BICreg &lt;- function(mod){ if(class(mod) == &quot;flexsurvreg&quot;){ loglik &lt;- mod_gam$loglik n_parameters &lt;- mod$npars N = nrow(mod$data$Y) BIC &lt;- -2*loglik + n_parameters*log(N) }else{ loglik &lt;- mod$loglik[[2]] n_parameters &lt;- nrow(mod$var) N = mod$n BIC &lt;- -2*loglik + n_parameters*log(N) } return(BIC) } 各モデルのAICとBICを記したのが表3.5である。いずれにおいても、ワイブル回帰モデルの適合度が最も高く、その次に対数ロジスティックモデルの適合度が高いことが分かる。 list_mod &lt;- list(mod_gam, mod_lnorm, mod_llog, mod_wei, mod_gom, mod_exp) tibble(model = c(&quot;ガンマ分布&quot;, &quot;対数正規分布&quot;, &quot;対数ロジスティック分布&quot;, &quot;ワイブル回帰&quot;, &quot;ゴンぺルツ回帰&quot;, &quot;指数回帰&quot;), AIC = map_dbl(list_mod, AICreg), BIC = map_dbl(list_mod, BICreg)) %&gt;% kable(caption = &quot;各モデルのAICとBIC&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.5: 各モデルのAICとBIC model AIC BIC ガンマ分布 1378.011 1414.627 対数正規分布 1384.469 1421.085 対数ロジスティック分布 1377.877 1414.493 ワイブル回帰 1377.833 1414.449 ゴンぺルツ回帰 1380.279 1416.895 指数回帰 1388.732 1421.279 両者のモデルから推定されるハザード率を再度図示すると以下のようになる。ワイブル回帰モデルはハザード率が単調増加なのに対し、対数ロジスティックモデルは途中まではハザード率が上昇するものの、その後低下していることが分かる。今回のデータの期間(52週)はハザード率が減少に転じるほど十分に長くはなかったため、ワイブル回帰モデルの方が適合度が高くなったのかもしれない。 as.ggplot(~plot(mod_wei, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;weibull&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_llog, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log logistic&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03))) 3.6 観察されない異質性の原因 個体のハザード率が期間を通して一定であっても、独立変数では説明しきれない個体間の異質性によって、時間とともにハザード率が減少する傾向があることが知られている。これは、一般的にハザード率が高い個体は早い段階で事象を経験してリスク集合から抜けていくため、時間が経過するにつれてハザード率の低い個体がリスク集合に残りやすい傾向があるためである。このとき、ハザード率が時間の減少と共に本当に減少しているのか、それとも個体の異質性によってハザード率が低下しているのかを区別するのは難しい10。このように、一般に時間がハザード率に与える影響を検討する際には十分な注意が必要である。 個体の異質性に対処する最も良い方法は、個体の異質性をもたらす要因を独立変数としてモデルに明示的に入れることである。しかし、こうした要因をすべて測定することは現実的ではない。この問題を解決するため、異質性の原因を誤差項に含めるパラメトリックなモデル(= frailty model)が提案されている。例えば、ランダムな誤差項を持つワイブル回帰モデルは以下のようにs定式化できる(式(3.9))。理論的には、これによって時間がハザード率に与える影響と、個体の異質性による影響を区別することができる。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + clog(t) + e \\tag{3.9} \\] 通常、誤差項\\(e\\)にどのような分布を仮定するかで偏回帰係数の推定値は大きく変わってしまう。一般に、以下の2つの場合を除いてこのモデルを用いることは推奨されない。 分析対象が繰り返し事象を経験する場合 分析対象をいくつかの大きなグループに分けることができ、同じグループに属するすべての個体の\\(e\\)が同じだと仮定できる場合。 3.7 なぜパラメトリックモデルを用いるのか 次章では最も一般的な手法であるコックス比例ハザードモデルを扱うが、パラメトリックモデルはコックス比例ハザードモデルよりも優れた特徴が二つある。ただし、多くのパッケージで時間依存の独立変数を扱うことができないという弱点もある。 「左側打ち切り」と「区間打ち切り」を扱うのが容易 左側打ち切り: すでに事象を経験したが、それがいつか分からない場合 区間打ち切り: 事象が二つの時点の間に発生したことはわかっているが、それがいつか正確にわからない場合 予測値の推定が優れている 次章の発生までの予想時間、事象発生までの時間の中央値や分位点、事象の確率分布などあらゆる推定が可能である。 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 指数分布が分からない方はこちら。↩︎ ゴンぺルツ分布が分からない方はこちら。↩︎ ワイブル分布が分からない方はこちら。↩︎ 自作関数はこちらのサイトを参考にした。↩︎ このあたりの説明やAICについては 久保 (2012) が分かりやすい。↩︎ 他方で、時間の経過とともにハザード率の上昇が観察されたなら、それはかなりの個体で実際にハザード率が時間とともに増加していると考えてよい。↩︎ "],["Chapter4.html", "4 コックス回帰モデル 4.1 比例ハザードモデル 4.2 部分尤度法 4.3 Rによる実装 4.4 時間に依存する独立変数 4.5 時間依存独立変数を含むモデル 4.6 比例ハザード性の仮定の検討と修正 4.7 観測期間の選択 4.8 コックス・モデルによる予測", " 4 コックス回帰モデル 前章(3)で解説したパラメトリックモデルは非常に有効である一方で以下の2点の欠点もあった。 最も適切な分布を決めなくてはならず、それがしばしば難しい 時間依存的な独立変数を使うことができない コックスの比例ハザードモデル(Cox, 1972) (コックス回帰モデル)はこうした欠点をどちらも解決してくれる優れた分析手法である。 4.1 比例ハザードモデル コックス回帰モデルはこれまで説明したパラメトリックな比例ハザードモデルを一般化したものといえる。ひとまず、非時間依存な独立変数2つを持つモデルを考えると、比例ハザードモデルは以下のように書ける(式(4.1))。ここで、\\(a(t)\\)は時間の関数であり、どんな形でもよい。この形を一定の形に決める必要がないので、このモデルはしばしば「セミパラメトリック」なモデルと呼ばれる。 \\[ log(h(t)) = a(t) + b_1x_1 + b_2x_2 \\tag{4.1} \\] 任意の時間\\(t\\)に対して、個体\\(i\\)と\\(j\\)のハザード比(\\(h_i(t)/h_j(t)\\))の値が一定なので比例ハザードモデルといわれている。個体Aのハザード率を\\(h_A(t)\\)、個体\\(B\\)のハザード率を\\(h_B(t)\\)とするとき、式(4.1)より以下のように導ける。このように、ハザード比は\\(t\\)に依らず一定になる。 \\[ \\begin{align} \\frac{h_A(t)}{h_B(t)} &amp;= \\frac{exp(a(t) + b_1x_{1A} + b_2x_{2A})}{exp(a(t) + b_1x_{1A} + b_2x_{2B})}\\\\ &amp;= \\frac{e^{a(t)} \\times e^{b_1} \\times e^{x_{1A}} \\times e^{b_2} \\times e^{x_{2A}}}{e^{a(t)} \\times e^{b_1} \\times e^{x_{1B}} \\times e^{b_2} \\times e^{x_{2B}}}\\\\ &amp;= \\frac{e^{x_{1A}+x_{2A}}}{e^{x_{1B}+x_{2B}}} \\end{align} \\] 第3章のパラメトリックなモデルはコックス回帰モデルの特殊例である。\\(a(t)\\)が定数なら指数分布モデル、\\(a(t) = ct\\)ならワイブル回帰モデルになる。\\(a(t)\\)はいかなる形も取れるので、例えば以下のような4次の多項式にすることもできる(式(4.2))。 \\[ a(t) = a_0 + a_1t + a_2t^2 + a_3t^3 + a_4t^4 \\tag{4.2} \\] 4.2 部分尤度法 コックス回帰モデルでは部分尤度法と呼ばれる方法でパラメータの推定を行う。この方法では、尤度関数を偏回帰係数(\\(b_1,b_2\\))のみを含む部分と偏回帰係数と関数\\(a(t)\\)の両方を含む部分に分解し、前者のみに着目して通常のパラメータ推定を行う。つまり、時間\\(t\\)に依存する部分を無視して偏回帰係数のみを推定できるのである。部分尤度法では正確な事象の発生時間ではなく、事象の発生順序のみに基づいて推定が行われるため、時間を二乗したり整数倍しても推定結果は変わらない。 4.3 Rによる実装 第3章で分析した元服役囚の再犯データにコックス回帰モデルを当てはめる。分析には、survivalパッケージのcoxph()関数を使用する。 mod_cox &lt;- coxph(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid) 結果は以下の通り。係数の推定値自体はワイブル回帰モデルとほとんど変わらない(表3.3参照)。指数変換された標準偏回帰係数はパラメトリックなモデルと同様にハザード比として解釈できる。例えば、経済的支援を受けた元服役囚は受けてない元服役囚よりも再犯の可能性が約32%低下することが分かる。 mod_cox ## Call: ## coxph(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid) ## ## coef exp(coef) se(coef) z p ## fin -0.37942 0.68426 0.19138 -1.983 0.04742 ## age -0.05744 0.94418 0.02200 -2.611 0.00903 ## race 0.31390 1.36875 0.30799 1.019 0.30812 ## wexp -0.14980 0.86088 0.21222 -0.706 0.48029 ## mar -0.43370 0.64810 0.38187 -1.136 0.25606 ## paro -0.08487 0.91863 0.19576 -0.434 0.66461 ## prio 0.09150 1.09581 0.02865 3.194 0.00140 ## ## Likelihood ratio test=33.27 on 7 df, p=2.362e-05 ## n= 432, number of events= 114 survminerパッケージのggforest()関数で結果を図示することもできる(図4.1)。推定されたハザード比と95%信頼区間、検定結果が示されている。 ggforest(mod_cox) 図4.1: mod_coxで推定されたハザード比 4.4 時間に依存する独立変数 コックス回帰モデルは時間依存的な独立変数を含むモデルに拡張できる(式(4.3))。 \\[ log(h(t)) = a(t) + b_1x_1 + b_2x_2(t) \\tag{4.3} \\] 独立変数の値の変化とそれがハザード率に与える影響の間にタイムラグがある場合は、例えば以下のように1週間前の値を独立変数にするようにモデリングすることもできる(式(4.4))。 \\[ log(h(t)) = a(t) + b_1x_1 + b_2x_2(t-1) \\tag{4.4} \\] 再犯データのモデルの独立変数に、各週の就業状況(work)を加えてモデリングを行う。Rで分析を行う際には、それぞれの人の各週のデータすべてが1行ずつあるようなデータフレームを作成する必要がある。 recid %&gt;% rownames_to_column(var = &quot;id&quot;) %&gt;% ### 就業状態を一列に pivot_longer(cols = work1:work52, names_to = &quot;work_week&quot;, values_to = &quot;work&quot;, values_drop_na = TRUE) %&gt;% arrange(id) %&gt;% group_by(id) %&gt;% ## 各行データの観察開始時点 mutate(start = 1:n() -1) %&gt;% ## 各行データの観察終了時点(何週目か) mutate(stop = 1:n()) %&gt;% ## 再犯があった州のarrestのみを1にして、そのほかは0にする mutate(arrest = ifelse(arrest == 1 &amp; week == stop,1,0)) %&gt;% ##1週前の就業状態 mutate(worklag = lag(work,1))-&gt; recid_long それでは、時間依存変数を含んだコックス回帰モデルを実行する。まずは式(4.3)のモデルを推定する。従属変数は、Surv(start, stop,arrest)となる点に注意。 mod_cox_ti &lt;- coxph(Surv(start, stop, arrest) ~ fin + age + race + wexp + mar + paro + prio + work, data = recid_long) 結果は以下の通り。 mod_cox_ti ## Call: ## coxph(formula = Surv(start, stop, arrest) ~ fin + age + race + ## wexp + mar + paro + prio + work, data = recid_long) ## ## coef exp(coef) se(coef) z p ## fin -0.35672 0.69997 0.19113 -1.866 0.06198 ## age -0.04634 0.95472 0.02174 -2.132 0.03301 ## race 0.33866 1.40306 0.30960 1.094 0.27402 ## wexp -0.02555 0.97477 0.21142 -0.121 0.90380 ## mar -0.29375 0.74546 0.38303 -0.767 0.44314 ## paro -0.06421 0.93781 0.19468 -0.330 0.74156 ## prio 0.08514 1.08887 0.02896 2.940 0.00328 ## work -1.32832 0.26492 0.25072 -5.298 1.17e-07 ## ## Likelihood ratio test=68.65 on 8 df, p=9.114e-12 ## n= 19809, number of events= 114 ggforest()関数によって図示した結果が図4.2である。 ggforest(mod_cox_ti) 図4.2: mod_coxで推定されたハザード比 続いて、式(4.4)のモデルを推定する。workの代わりにworklagを説明変数に入れる。 mod_cox_tlag &lt;- coxph(Surv(start, stop, arrest) ~ fin + age + race + wexp + mar + paro + prio + worklag, data = recid_long) 結果は以下の通り。 mod_cox_tlag ## Call: ## coxph(formula = Surv(start, stop, arrest) ~ fin + age + race + ## wexp + mar + paro + prio + worklag, data = recid_long) ## ## coef exp(coef) se(coef) z p ## fin -0.35130 0.70377 0.19181 -1.831 0.067035 ## age -0.04977 0.95144 0.02189 -2.274 0.022969 ## race 0.32147 1.37915 0.30912 1.040 0.298369 ## wexp -0.04764 0.95348 0.21323 -0.223 0.823207 ## mar -0.34476 0.70839 0.38322 -0.900 0.368310 ## paro -0.04710 0.95399 0.19630 -0.240 0.810375 ## prio 0.09199 1.09635 0.02880 3.194 0.001402 ## worklag -0.78689 0.45526 0.21808 -3.608 0.000308 ## ## Likelihood ratio test=47.16 on 8 df, p=1.43e-07 ## n= 19377, number of events= 113 ## (432 observations deleted due to missingness) ggforest()関数によって図示した結果が図4.3である。 ggforest(mod_cox_tlag) 図4.3: mod_coxで推定されたハザード比 推定した3つのモデルの推定値をまとめたものが表4.1である。推定結果自体は非常によく似ているが、先ほどの検定結果を見ると経済的支援の効果は時間依存変数を含まない基本モデルのみで有意になっている。また、時間依存変数の就業状態(workまたはworklag)が他の変数よりも大きな影響を与えていたことも分かった。、2つ目のモデルのハザード比(Exp(Coef) = 0.265)をみると就業している元服役囚の再犯率が就業していない服役囚の26.5%であると推定された。 ただし、この結果のみでは就業状態が再犯に影響したのか、再犯が就業状態に影響したのかはわからない。そこで、就業状態に1週間のラグがあるモデル3の結果を見ると、2つ目のモデルより効果量は減少するものの、依然として大きな影響を及ぼしていることが分かる。モデル3のハザード比(Exp(Coef) = 0.455)から、就業状態にある元服役囚はそうでない元服役囚に比べて翌週の再犯率が約54.5%低いことが分かる。このように、タイムラグを持つ変数を用いることで再犯が就業状態に影響する可能性を除外することができる。 tibble(Covariate = rownames(mod_cox_ti$coefficients %&gt;% data.frame()), &quot;Coef(basic)&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_cox))[1:7],NA), &quot;Exp(Coef_basic)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_cox)))[1:7],NA), &quot;Coef(ti)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_cox_ti))[1:8], &quot;Exp(Coef_ti)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_ti)))[1:8], &quot;Coef(tlag)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_cox_tlag))[1:8], &quot;Exp(Coef_tlag)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_tlag))[1:8])) %&gt;% mutate(Covariate = ifelse(str_detect(Covariate,&quot;work&quot;),&quot;work/worklag&quot;,Covariate)) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;基本モデル&quot;,&quot;時間依存独立変数\\nあり&quot;, &quot;タイムラグのある\\n時間独立変数あり&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-8b5576bc{}.cl-8b4e85d2{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-8b5193da{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-8b51a8de{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-8b51a8df{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-8b51a8e8{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表4.1: 各モデルの推定値の比較 基本モデル時間依存独立変数ありタイムラグのある時間独立変数ありCovariateCoef(basic)Exp(Coef_basic)Coef(ti)Exp(Coef_ti)Coef(tlag)Exp(Coef_tlag)fin-0.3790.684-0.3570.700-0.3510.704age-0.0570.944-0.0460.955-0.0500.951race0.3141.3690.3391.4030.3211.379wexp-0.1500.861-0.0260.975-0.0480.953mar-0.4340.648-0.2940.745-0.3450.708paro-0.0850.919-0.0640.938-0.0470.954prio0.0911.0960.0851.0890.0921.096work/worklag-1.3280.265-0.7870.455 4.5 時間依存独立変数を含むモデル 時間依存独立変数があるモデルの推定をするとき、ある時点で事象が発生した場合、その時点で事象を経験しうるすべての個体について時間依存変数の値が分かっていなければいけない。例えば、\\(t =10\\)で事象が発生し、その時点で15人が事象を経験する可能性がある(= リスク集合にいる)場合、15人全員について\\(t=10\\)時点の時間依存変数が分かっていなければいけない。そのため、事象の発生が日単位で測定されているにもかかわらず、時間依存変数の値が1週間ごとにしか測定されていないといったことがあるとき、問題が生じることになる。 このような場合、特定の方法で事象が発生した時点の独立変数の値を補完して代入する必要がある。いろいろな方法があるが、最も安全なものは直前に観察された値を使用する方法である。保管によって必要な代入ができたら、次に分析のためにデータを加工する必要がある。加工方法には以下の2つがあるが、統計ソフトではいずれかを使用している(Rはエピソード分割法)。どちらも選べるならば後者の方が望ましい。 4.5.1 プログラミング・ステートメント法(programming statements method) この方法を使用するには、データをワイド形式にする必要がある。すなわち、今回の例では各週の就業状態が1列ずつになるようにする必要がある。 4.5.2 エピソード分割法(episode splitting method) この方法のデータは先ほど加工したrecid_longのようにロング形式で問題ない。それぞれの個体が複数の行を持ち、各行のデータについて観察し始めた時点(start)と観察が終了した時点(stop)を記した列を作る。また独立変数が変化するたびに行を変えるか、もしくは独立変数の変化に関係なく小さな時間間隔ごとに行を変える(どちらでも問題ない)。例えばrecid_longでは各個体が1週間ごとに1行ずつのデータを持つ。 recid_long %&gt;% head(50) %&gt;% datatable(options = list(scrollX = 20)) 4.6 比例ハザード性の仮定の検討と修正 4.6.1 シェフィールド残差を用いた検討 コックス回帰モデルの仮定として、どの時点でも2個体のハザード比が一定であるとする「比例ハザード性」があった。この仮定が満たされないときはどのようなときだろうか? ハザード比が一定になるのは、ハザード率の対数に対して各独立変数の影響が全ての時点で同じときである。そのため、時間と独立変数に交互作用があるときはハザード率の比は一定にならない。式(4.5)はその一例である。この式で独立変数\\(x\\)がハザード率の対数に与える影響は\\(b + ct\\)なので、時間と共に増加/減少する。 \\[ log(h(t)) = a(t) + bx + cxt \\tag{4.5} \\] 比例ハザード性を検討する方法はいくつかあるが、最も簡便なものはシェーンフィールド残差を用いる方法である。子の残差は独立変数の一つ一つに対して研鑽され、比例ハザード性が満たされるならば時間、あるいは時間の関数と相関がない。 Rでシェーンフィールド残差を調べるためには、以下のようなコードを実行する。ここでは、2つ目のモデル(mod_cox_ti)について分析を行う。chisqの列には「相関係数が0である」を帰無仮説とする検定を行った際のカイ二乗値が、pにはp値が示されている。年齢(age)はp値が0.05を下回っており、比例ハザード性の仮定を満たしていない可能性が示唆された。一番下には「全ての相関係数が0である」を帰無仮説とする包括的検定(GLOBAL)が行われており、これも5%水準で有意である。 cox.zph(mod_cox_ti, transform = &quot;identity&quot;) ## chisq df p ## fin 0.0143 1 0.905 ## age 6.5021 1 0.011 ## race 1.9489 1 0.163 ## wexp 3.5032 1 0.061 ## mar 0.8508 1 0.356 ## paro 0.0118 1 0.913 ## prio 0.3363 1 0.562 ## work 0.1972 1 0.657 ## GLOBAL 17.1128 8 0.029 survminerパッケージのggcoxzphをもちいて視覚的に仮定をチェックすることもできる(図4.4)。 ggcoxzph(cox.zph(mod_cox_ti, transform = &quot;identity&quot;) ) 図4.4: 各独立変数の比例ハザード性のチェック なお、比例ハザード性が満たされるためには実際は時間そのものだけではなく、時間の関数(時間の対数や順位、および事象が発生した時間の累積分布関数の推定値など)とも無相関である必要である。Rでは、時間の順位と、Kaplan-meiyer法による生存確率の推定値(後述)との相関も調べることができる。結果はほとんど変わらない。 ## 時間 cox.zph(mod_cox_ti, transform = &quot;rank&quot;) ## chisq df p ## fin 0.0181 1 0.8929 ## age 6.7334 1 0.0095 ## race 1.9342 1 0.1643 ## wexp 3.3284 1 0.0681 ## mar 0.8976 1 0.3434 ## paro 0.0166 1 0.8975 ## prio 0.2838 1 0.5942 ## work 0.1756 1 0.6752 ## GLOBAL 17.1526 8 0.0286 ## 生存確率の推定値 cox.zph(mod_cox_ti, transform = &quot;km&quot;) ## chisq df p ## fin 9.58e-04 1 0.975 ## age 5.89e+00 1 0.015 ## race 1.87e+00 1 0.171 ## wexp 3.83e+00 1 0.050 ## mar 8.29e-01 1 0.363 ## paro 5.64e-03 1 0.940 ## prio 4.27e-01 1 0.514 ## work 2.50e-01 1 0.617 ## GLOBAL 1.66e+01 8 0.034 4.6.2 仮定が満たされないときの修正 4.6.2.1 時間との交互作用をモデルに加える 仮定が満たされないときの解決策の一つは独立変数と時間の交互作用を含んだ式(4.5)のようなモデルを推定することである。コックス回帰モデルのすばらしさは、このように比例ハザード性を持たないモデルを柔軟に修正できる点である。ここでは、p値が0.1以下だった年齢(age)と過去の就業経験(wexp)について各データポイント時点の週(stop)との交互作用を入れたモデルを検討する。 mod_cox_int &lt;- coxph(Surv(start, stop, arrest) ~ fin + age + race + wexp + mar + paro + prio + work + age:stop + wexp:stop, data = recid_long) 結果は以下の通りである。いずれの交互作用も有意な影響を持っていることが分かる。 mod_cox_int ## Call: ## coxph(formula = Surv(start, stop, arrest) ~ fin + age + race + ## wexp + mar + paro + prio + work + age:stop + wexp:stop, data = recid_long) ## ## coef exp(coef) se(coef) z p ## fin -0.361738 0.696465 0.190891 -1.895 0.058093 ## age 0.085368 1.089118 0.040598 2.103 0.035484 ## race 0.305627 1.357476 0.309442 0.988 0.323313 ## wexp -1.209155 0.298449 0.481342 -2.512 0.012003 ## mar -0.233974 0.791382 0.383910 -0.609 0.542226 ## paro -0.063033 0.938913 0.194910 -0.323 0.746398 ## prio 0.080920 1.084284 0.028951 2.795 0.005188 ## work -1.318052 0.267656 0.251332 -5.244 1.57e-07 ## age:stop -0.005091 0.994922 0.001541 -3.304 0.000952 ## wexp:stop 0.041276 1.042139 0.014512 2.844 0.004451 ## ## Likelihood ratio test=83.62 on 10 df, p=9.751e-14 ## n= 19809, number of events= 114 交互作用項については、一般化線形モデルなどと同様に解釈することができる11。式(4.5)を書き換えると以下のように書ける。 \\[ log(h(t)) = a(t) + (b+ct)x \\] ここからわかるように、独立変数\\(x\\)が1増えると、ハザード関数の対数は\\(b+ct\\)増える。つまり、\\(x\\)の「効果」は時間の線形関数になっていて、\\(t=0\\)のときは\\(b\\)でそこから時間が１単位増えるごとに効果が\\(c\\)ずつ増えていくということになる。例えば先ほどの推定結果から、就業経験の有無の効果は\\(-1.21 + 0.041 \\times t\\)となり、効果が1週ごとに\\(0.041\\)ずつ増加することが分かる。表4.2は、出所時の年齢(age)と就業経験の有無(wexp)の効果が時間がたつにつれてどのように変化すると推定されたかを示している。例えばwexpについては、出所直後は就業経験があるとない場合に比べてハザード率が29.8%になることが分かるが、50週後にはむしろ就業経験があるとない場合に比べてハザード比が235%上昇することが分かり、このような効果の逆転は30週くらいで起こっていることが分かる。 tibble(t = seq(0,50,10), `偏回帰係数\\n(b + ct)` = sprintf(&quot;%.3f&quot;,mod_cox_int$coefficients[[2]] + mod_cox_int$coefficients[[9]]*t), `Exp(b+ct)` = sprintf(&quot;%.3f&quot;, exp(mod_cox_int$coefficients[[2]] + mod_cox_int$coefficients[[9]]*t)), `偏回帰係数\\n(b + ct) ` = sprintf(&quot;%.3f&quot;, mod_cox_int$coefficients[[4]] + mod_cox_int$coefficients[[10]]*t), `Exp(b+ct) ` = sprintf(&quot;%.3f&quot;, exp(mod_cox_int$coefficients[[4]] + mod_cox_int$coefficients[[10]]*t))) %&gt;% rename(`出所して\\nからの週(t)` = t) %&gt;% flextable() %&gt;% width(width = 2/2) %&gt;% add_header_row(colwidth = c(1,2,2), values = c(&quot;&quot;,&quot;出所時の年齢&quot;,&quot;就業経験の有無&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-4468392a{}.cl-446050b6{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-44630b8a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4463216a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-44632174{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-44632175{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表4.2: 各モデルの推定値の比較 出所時の年齢就業経験の有無出所してからの週(t)偏回帰係数(b + ct)Exp(b+ct)偏回帰係数(b + ct) Exp(b+ct) 00.0851.089-1.2090.298100.0341.035-0.7960.45120-0.0160.984-0.3840.68130-0.0670.9350.0291.03040-0.1180.8880.4421.55650-0.1690.8440.8552.350 交互作用モデルでは、全ての独立変数についてモデルのシェーンフィールド残差と時間の相関がなくなっていることが分かる。 cox.zph(mod_cox_int) ## chisq df p ## fin 0.0290 1 0.86 ## age 2.4002 1 0.12 ## race 1.5400 1 0.21 ## wexp 2.6158 1 0.11 ## mar 0.6847 1 0.41 ## paro 0.1608 1 0.69 ## prio 0.0111 1 0.92 ## work 0.2701 1 0.60 ## age:stop 0.4199 1 0.52 ## wexp:stop 1.5229 1 0.22 ## GLOBAL 6.6780 10 0.76 交互作用モデルの欠点は、交互作用項をパラメトリックな特定の形で定式化する必要がある点である。ただし、これまで時間と独立変数は一次の線形関係にあるとしていたが、代わりに時間の二乗や対数変換した時間をモデルに含めることも可能である。 4.6.2.2 層化(stratification) もう一つの方法が層化という方法で、就業経験のような離散的な変数が比例ハザード性を満たさないときに使える。 例えば就業経験について層化を行うとすると、就業経験のある元服役囚のデータのみを含むモデルと、就業経験のない元服役囚のデータのみを含むモデルの2つを考える。いずれも同じ偏回帰係数を持つが、時間の関数の形が異なる。時間tにおける就業経験の効果は\\(a_1(t) - a_2(t)\\)であり、いかなる制約も比例ハザード性も仮定していない。しかし、部分尤度法を用いる以上これを推定することはできない。 \\[ \\begin{aligned} 就業経験あり: log(h(t)) &amp;= a_1(t) + b_1x_1 + b_2x_2 + ...\\\\ 就業経験なし: log(h(t)) &amp;= a_2(t) + b_1x_1 + b_2x_2 + ... \\end{aligned} \\] 層化モデルは、Rで以下のように実行できる。 mod_cox_str &lt;- coxph(Surv(start, stop, arrest) ~ fin + age + race + mar + paro + prio + work + strata(wexp), data = recid_long) 結果は以下の通り。層化したことで、就業経験の偏回帰係数がなくなる。このように、層化するとその独立変数の効果は推定できなくなる。 mod_cox_str ## Call: ## coxph(formula = Surv(start, stop, arrest) ~ fin + age + race + ## mar + paro + prio + work + strata(wexp), data = recid_long) ## ## coef exp(coef) se(coef) z p ## fin -0.35910 0.69831 0.19121 -1.878 0.06038 ## age -0.04766 0.95346 0.02192 -2.174 0.02969 ## race 0.34453 1.41133 0.30963 1.113 0.26583 ## mar -0.30368 0.73810 0.38355 -0.792 0.42850 ## paro -0.06255 0.93937 0.19477 -0.321 0.74811 ## prio 0.08419 1.08784 0.02905 2.898 0.00375 ## work -1.32825 0.26494 0.25091 -5.294 1.2e-07 ## ## Likelihood ratio test=59.08 on 7 df, p=2.307e-10 ## n= 19809, number of events= 114 交互作用モデルと層化モデルの偏回帰係数を比較したのが表4.3である。推定結果に少し違いがみられる。 tibble(Covariate = rownames(mod_cox_int$coefficients %&gt;% data.frame()), &quot;Coef(int)&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_cox_int))[1:10]), &quot;Exp(Coef_int)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_int)))[1:10]), &quot;Coef(str)&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_cox_str))[1:3], &quot;-&quot;,sprintf(&quot;%.3f&quot;,coef(mod_cox_str))[4:7],NA,NA), &quot;Exp(Coef_str)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_str)))[1:3], &quot;-&quot;, sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_str)))[4:7],NA,NA)) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2), values = c(&quot;&quot;,&quot;時間との交互作用モデル&quot;,&quot;層化モデル&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-889ff0d2{}.cl-88993e9a{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-889c17b4{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-889c2d80{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-889c2d81{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-889c2d8a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表4.3: 各モデルの推定値の比較 時間との交互作用モデル層化モデルCovariateCoef(int)Exp(Coef_int)Coef(str)Exp(Coef_str)fin-0.3620.696-0.3590.698age0.0851.089-0.0480.953race0.3061.3570.3451.411wexp-1.2090.298--mar-0.2340.791-0.3040.738paro-0.0630.939-0.0630.939prio0.0811.0840.0841.088work-1.3180.268-1.3280.265age:stop-0.0050.995wexp:stop0.0411.042 4.7 観測期間の選択 今回の例では出所した日を観測の起点とするので比較的明確であるが、なかには観測時間の起点がそれほど明確でないデータもある。例えば、今回の再犯データでも個人の年齢や暦上の時間を観測時間の単位とすることも可能である。いずれにしても部分尤度法による推定は行えるが、重要な点はその観測時間の単位が妥当かを考えることである。例えばハザード率が強く年齢に依存しており、そのほかの時間単位にあまり依存していないと考えられるのであれば、年齢を観測時間の単位にすることは適切である。 理論的にはハザード率が二つ以上の時間に依存するモデルを定式化することはできるが、一般に大きなサンプルサイズや特殊な条件が必要である。このような方法が困難な場合は、異なる時間の単位を明示的に独立変数に含めるのが妥当である。今回も年齢(age)を独立変数に含めた。 4.8 コックス・モデルによる予測 第3章で見たように、予測という観点で見るとパラメトリックなモデルが最も優れており、予測が非常に簡単である。一方で、コックス回帰モデルでも限定的であるが予測を行うことはできる。 コックス回帰を用いて主に予測できるのは生存関数(= 時間の経過とともに事象が生じていない確率がどのように変化するかを表す関数)の推測値であり、実際に観察された時間の範囲について行える。詳しい推定方法は 杉本 (2021) を参照。生存関数には独立変数の値を指定することができ、これは実際に観測された値でなくても問題ない。例えば、1つ目のモデル(mod_cox)で、経済的支援を受けており、出所時の年齢21歳、黒人で未婚、仮釈放として出所し、就業経験があり、過去に有罪判決を4回受けている人について予測される生存確率は以下のようになる。 survfit(mod_cox, newdata = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4), ## 信頼区間の範囲 conf.int = 0.95) %&gt;% summary(times = c(seq(0,50,5),52)) ## Call: survfit(formula = mod_cox, newdata = tibble(fin = 1, age = 21, ## race = 1, wexp = 1, mar = 0, paro = 1, prio = 4), conf.int = 0.95) ## ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 0 432 0 1.000 0.0000 1.000 1.000 ## 5 428 5 0.989 0.0053 0.979 1.000 ## 10 418 10 0.967 0.0105 0.947 0.988 ## 15 409 10 0.945 0.0151 0.916 0.975 ## 20 397 15 0.911 0.0216 0.869 0.954 ## 25 384 11 0.886 0.0262 0.836 0.939 ## 30 374 9 0.865 0.0298 0.809 0.925 ## 35 365 11 0.839 0.0341 0.775 0.909 ## 40 351 14 0.806 0.0394 0.732 0.887 ## 45 339 10 0.782 0.0430 0.702 0.871 ## 50 325 15 0.746 0.0482 0.658 0.847 ## 52 322 4 0.737 0.0495 0.646 0.840 作図にはsurveminerパッケージのggsurvplot()関数とggsurvfitパッケージのggsurvfit()関数が有用である。結果をggplotオブジェクトとして出力してくれるので、グラフの修飾が容易である。作り方の詳細はパッケージのウェブページを参考にされたし。上記と同じ条件で予測した生存関数を図示したものが図4.5である。なお、塗りつぶし部分は95%信頼区間である。 predict_cox &lt;- survfit(mod_cox, newdata = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4), ## 信頼区間の範囲 conf.int = 0.95) ## ggsurvplot ggsurvplot(predict_cox, data = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4), ## 色 palette = &quot;black&quot;, ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, ggtheme = theme_bw()) -&gt; p1 p1$plot + labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ ggtitle(&quot;ggsurvplot()&quot;)+ theme_bw(base_size = 16)+ theme(legend.position = &quot;none&quot;)+ coord_cartesian(ylim = c(0.64556,1))+ scale_y_continuous(breaks = seq(0.65,1,0.05)) -&gt; p1 ## ggsurvfit ggsurvfit(predict_cox)+ add_confidence_interval()+ labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ ggtitle(&quot;ggsurfit()&quot;)+ theme_bw(base_size = 16)+ scale_y_continuous(breaks = seq(0,1,0.05)) -&gt; p2 p1 + p2 図4.5: モデルから推定された生存曲線 なお、何も指定しない場合、survfit()関数は連続変数は平均値で、二値変数は0で中心化した値を当てはめて予測を行う(図4.6)。 mod_cox$means ## fin age race wexp mar paro prio ## 0.000000 24.597222 0.000000 0.000000 0.000000 0.000000 2.983796 predict_cox2 &lt;- survfit(mod_cox, ## 信頼区間の範囲 conf.int = 0.95) ## ggsurvplot ggsurvplot(predict_cox2, data = recid, ## 色 palette = &quot;black&quot;, ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, ggtheme = theme_bw()) -&gt; p3 p3$plot + labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ theme_bw(base_size = 16)+ theme(legend.position = &quot;none&quot;)+ coord_cartesian(ylim = c(0.64556,1))+ scale_y_continuous(breaks = seq(0.65,1,0.05)) 図4.6: 独立変数を指定しないときにモデルから推定された生存曲線 複数の値を当てはめて生存関数を予測することもできる(図4.7)。ここでは、前科の数prioが0,5,10回のときの予測を行う。 predict_cox3 &lt;- survfit(mod_cox, newdata = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = c(0,5,10)), ## 信頼区間の範囲 conf.int = 0.95) ## ggsurvplot ggsurvplot(predict_cox3, data = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = c(0,5,10)), ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, legend.title = &quot;prio&quot;, legend.labs = c(&quot;0&quot;,&quot;5&quot;,&quot;10&quot;), ggtheme = theme_bw()) -&gt; p4 p4$plot + scale_color_nejm()+ scale_fill_nejm()+ labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ theme_bw(base_size = 16)+ theme(legend.position = &quot;top&quot;)+ coord_cartesian(ylim = c(0.4,1))+ scale_y_continuous(breaks = seq(0,1,0.2)) 図4.7: 独立変数を指定しないときにモデルから推定された生存曲線 時間依存独立変数を持つ場合も同様に予測することができる(図??)。 predict_cox_ti &lt;- survfit(mod_cox_ti, newdata = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4, work = c(0,1)), ## 信頼区間の範囲 conf.int = 0.95) ## ggsurvplot ggsurvplot(predict_cox_ti, data = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4, work = c(0,1)), ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, legend.title = &quot;work&quot;, legend.labs = c(0,1), ggtheme = theme_bw()) -&gt; p5 p5$plot + scale_color_nejm()+ scale_fill_nejm()+ labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ theme_bw(base_size = 16)+ theme(legend.position = &quot;top&quot;)+ coord_cartesian(ylim = c(0.5,1))+ scale_y_continuous(breaks = seq(0,1,0.05)) 図4.8: 時間依存独立変数をもつモデルから推定された生存曲線 References Cox, D. R. (1972). Regression models and life-tables. J. R. Stat. Soc., 34(2), 187–202. 杉本知之. (2021). 生存時間解析. 朝倉書店. 粕谷英一. (2012). 一般化線形モデル. 共立出版. 交互作用の解釈については、 粕谷 (2012) なども参照。↩︎ "],["Chapterx.html", "補遺 ノンパラメトリックな推定 Kaplan-Meier法 Nelson-Aalen法", " 補遺 ノンパラメトリックな推定 Allison (2014) ではほとんど解説がなかったが、分布に何も仮定を置かないノンパラメトリックな方法で分析を行うこともできる。以下では、2つの代表的な方法を紹介する。 Kaplan-Meier法 Kaplan-Maier法は生存関数を推定するための推定量で、時点\\(t_n\\)における生存率\\(S_n\\)の推定値は以下のように定義される。なお、時点\\(t_n\\)でのリスク集合の大きさを\\(l_n\\)、時点\\(t_n\\)に発生した事象の数を\\(d_n\\)としている。推定量は最尤推定によって得られる。 \\[ \\begin{aligned} S(t_n) &amp;= \\biggl(1-\\frac{d_1}{l_1}\\biggl) \\times \\biggl(1-\\frac{d_2}{l_2}\\biggl) \\times \\cdots \\times \\biggl(1-\\frac{d_n}{l_n}\\biggl) \\\\ &amp;= \\prod_{k=1}^n \\biggl(1-\\frac{d_k}{l_k}\\biggl) \\end{aligned} \\] Kaplan-Meier推定量は1からスタートし、事象の発生が確認されるたびに値が小さくなる階段関数である。Rではsurvivalパケージのsurvfit()関数で推定できる。ここでは、第2章で使用した生化学者の准教授への昇進データ(rank)を使用する。 library(haven) rank &lt;- read_dta(&quot;data/rank.dta&quot;) 第3章と第4章のモデルと同様に、従属変数をSurv(観察期間, 事象の発生の有無)もしくは、Surv(観察開始時点, 観察終了時点, 事象の発生の有無)として推定できる。推定の結果は以下のとおりである。 est_km &lt;- survfit(Surv(dur, promo) ~ 1, type = &quot;kaplan-meier&quot;, data = rank) summary(est_km) ## Call: survfit(formula = Surv(dur, promo) ~ 1, data = rank, type = &quot;kaplan-meier&quot;) ## ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 1 301 1 0.997 0.00332 0.990 1.000 ## 2 299 1 0.993 0.00469 0.984 1.000 ## 3 292 17 0.936 0.01431 0.908 0.964 ## 4 263 42 0.786 0.02431 0.740 0.835 ## 5 211 53 0.589 0.02970 0.533 0.650 ## 6 149 46 0.407 0.03030 0.352 0.471 ## 7 96 31 0.276 0.02825 0.225 0.337 ## 8 59 15 0.205 0.02622 0.160 0.264 ## 9 42 7 0.171 0.02484 0.129 0.228 ## 10 29 4 0.148 0.02406 0.107 0.203 結果の図示はsurvminerパッケージのggsurvplot()関数で行うことができる(図4.9)。 ggsurvplot(est_km, data = rank, censor = FALSE, palette = &quot;black&quot;, size = 0.5, conf.int.alpha = 0.15, legend = &quot;none&quot;, legend.title = &quot;&quot;) -&gt; p_km p_km$plot + labs(x = &quot;year&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ coord_cartesian(ylim = c(0.15,1)) 図4.9: Kaplan-Meier法で推定した生存曲線 説明変数を含めて、独立変数の値ごとに推定することもできる。 est_km2 &lt;- survfit(Surv(dur, promo) ~ phdmed, data = rank, type = &quot;kaplan-meier&quot;) summary(est_km2) ## Call: survfit(formula = Surv(dur, promo) ~ phdmed, data = rank, type = &quot;kaplan-meier&quot;) ## ## phdmed=0 ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 3 107 6 0.944 0.0222 0.9013 0.989 ## 4 96 19 0.757 0.0423 0.6785 0.845 ## 5 73 17 0.581 0.0496 0.4913 0.687 ## 6 54 19 0.376 0.0496 0.2908 0.487 ## 7 31 11 0.243 0.0455 0.1682 0.351 ## 8 17 4 0.186 0.0428 0.1182 0.292 ## 9 13 3 0.143 0.0395 0.0831 0.245 ## 10 8 1 0.125 0.0383 0.0685 0.228 ## ## phdmed=1 ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 1 189 1 0.995 0.00528 0.984 1.000 ## 2 188 1 0.989 0.00744 0.975 1.000 ## 3 185 11 0.931 0.01857 0.895 0.968 ## 4 167 23 0.802 0.02953 0.747 0.862 ## 5 138 36 0.593 0.03710 0.525 0.670 ## 6 95 27 0.425 0.03819 0.356 0.506 ## 7 65 20 0.294 0.03591 0.231 0.373 ## 8 42 11 0.217 0.03317 0.161 0.293 ## 9 29 4 0.187 0.03179 0.134 0.261 ## 10 21 3 0.160 0.03076 0.110 0.233 また、2つ以上の集団で生存関数が有意に異なるかを、ログランク検定や一般化ウィルコクソン検定で調べることもできる。Rではsurvdiff()関数で以下のように実行することができる。今回は、医学博士を持っているか否か(phdmed)によって生存関数が有意に異なるわけではないことが分かった。コックス回帰などとは異なり、他の変数の影響を統制できない点は注意が必要である。 ## ログランク検定 survdiff(Surv(dur, promo) ~ phdmed, data = rank, rho = 0) ## Call: ## survdiff(formula = Surv(dur, promo) ~ phdmed, data = rank, rho = 0) ## ## N Observed Expected (O-E)^2/E (O-E)^2/V ## phdmed=0 112 80 74.9 0.345 0.685 ## phdmed=1 189 137 142.1 0.182 0.685 ## ## Chisq= 0.7 on 1 degrees of freedom, p= 0.4 ## 一般化ウィルコクソン検定 survdiff(Surv(dur, promo) ~ phdmed, data = rank, rho = 1) ## Call: ## survdiff(formula = Surv(dur, promo) ~ phdmed, data = rank, rho = 1) ## ## N Observed Expected (O-E)^2/E (O-E)^2/V ## phdmed=0 112 54.6 51.4 0.206 0.516 ## phdmed=1 189 91.1 94.4 0.112 0.516 ## ## Chisq= 0.5 on 1 degrees of freedom, p= 0.5 検定の結果を反映させた図を作成することもできる(図4.10)。 ggsurvplot(est_km2, data = rank, censor = FALSE, conf.int = TRUE, palette = c(&quot;blue3&quot;,&quot;red2&quot;), size = 0.5, conf.int.alpha = 0.15, legend.title = &quot;&quot;, ## p値を表示 pval = TRUE, ## 一般化ウィルコクソン検定の場合は&quot;S1&quot; log.rank.weights = &quot;1&quot;) -&gt; p_km2 p_km2$plot + labs(x = &quot;year&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;top&quot;)+ coord_cartesian(ylim = c(0.15,1)) 図4.10: ロングランク検定の結果を示した生存曲線 Nelson-Aalen法 もう一つよく用いられる方法がNelson-Aalen法であり、累積ハザード関数(ある時点までのハザード率の総和)を推定するための推定量である。時点\\(t_n\\)における累積ハザード率$ H_n\\(の推定値は以下のように定義される。なお、時点\\)t_n\\(でのリスク集合の大きさを\\)l_n\\(、時点\\)t_n\\(に発生した事象の数を\\)d_n$としている。 \\[ \\begin{aligned} H(t_n) &amp;= \\biggl(\\frac{d_1}{l_1}\\biggl) + \\biggl(\\frac{d_2}{l_2}\\biggl) + \\cdots + \\biggl(\\frac{d_n}{l_n}\\biggl) \\\\ &amp;= \\sum_{k=1}^n \\biggl(\\frac{d_k}{l_k}\\biggl) \\end{aligned} \\] Nelson-Aalen推定量は0からスタートし、事象の発生が確認されるたびに値が大きくなる階段関数である。Rではcoxph()で説明変数のないモデルを推定したのち、basehaz()関数で求められる。 est_na &lt;- coxph(Surv(dur, promo) ~ 1, data = rank) basehaz(est_na) 結果の図示はsurvminerパッケージのggsurvplot()関数で、fun = \"cumhaz\"とすることで行うことができる(図4.11)。 fit_na &lt;- survfit(est_na, data = rank, ## 信頼区間の範囲 conf.int = 0.95) ggsurvplot(fit_na, fun = &quot;cumhaz&quot;, data = rank, censor = FALSE, legend = &quot;none&quot;) -&gt; p_na p_na$plot + labs(x = &quot;year&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;) 図4.11: Nelson-Aalen法で推定した累積ハザード関数 生存関数\\(S_n\\)と累積ハザード関数\\(H(t_n)\\)の関係は以下のように記述できる。よって、Nelson-Aalen法で推定した累積ハザード関数から生存関数を推定することもできる。 \\[ S(t_n) = exp[-H(t_n)] \\] Nelson-Aalen法によって推定された生存関数は以下のように図示できる。 est_na2 &lt;- survfit(Surv(dur, promo) ~ 1, data = rank, type = &quot;fh&quot;) ggsurvplot(est_na2, data = rank, censor = FALSE, legend = &quot;none&quot;, palette = &quot;black&quot;, conf.int.alpha = 0.15, size = 0.5) -&gt; p_na2 p_na2$plot + labs(x = &quot;year&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ coord_cartesian(ylim = c(0.15,1)) 図4.12: Nelson-Aalen法で推定した生存曲線 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] survminer_0.4.9 ggpubr_0.5.0 ggplotify_0.1.0 flextable_0.9.1 ## [5] flexsurv_2.2.2 eha_2.10.3 ggeffects_1.1.4 rstanarm_2.21.4 ## [9] brms_2.18.0 Rcpp_1.0.9 fontregisterer_0.3 systemfonts_1.0.4 ## [13] extrafont_0.18 lemon_0.4.6 ggsci_2.9 stargazer_5.2.3 ## [17] kableExtra_1.3.4 knitr_1.42 DT_0.27 patchwork_1.1.2 ## [21] data.table_1.14.6 see_0.7.5.5 report_0.5.7.4 parameters_0.20.3 ## [25] performance_0.10.3 modelbased_0.8.6.3 insight_0.19.1.4 effectsize_0.8.3.6 ## [29] datawizard_0.7.1.1 correlation_0.8.4 bayestestR_0.13.1 easystats_0.6.0.8 ## [33] haven_2.5.1 forcats_0.5.2 stringr_1.5.0 dplyr_1.0.10 ## [37] purrr_1.0.0 readr_2.1.3 tidyr_1.2.1 tibble_3.1.8 ## [41] tidyverse_1.3.2 ggplot2_3.4.2 ggsurvfit_0.3.0 survival_3.5-5 ## ## loaded via a namespace (and not attached): ## [1] estimability_1.4.1 muhaz_1.2.6.4 coda_0.19-4 ## [4] ragg_1.2.4 dygraphs_1.1.1.6 inline_0.3.19 ## [7] generics_0.1.3 callr_3.7.3 cowplot_1.1.1 ## [10] tzdb_0.3.0 webshot_0.5.4 xml2_1.3.3 ## [13] lubridate_1.9.0 httpuv_1.6.7 StanHeaders_2.26.13 ## [16] assertthat_0.2.1 gargle_1.2.1 xfun_0.36 ## [19] hms_1.1.2 jquerylib_0.1.4 bayesplot_1.10.0 ## [22] evaluate_0.20 promises_1.2.0.1 fansi_1.0.3 ## [25] dbplyr_2.2.1 readxl_1.4.1 km.ci_0.5-6 ## [28] igraph_1.3.5 DBI_1.1.3 htmlwidgets_1.6.1 ## [31] tensorA_0.36.2 googledrive_2.0.0 stats4_4.2.2 ## [34] ellipsis_0.3.2 crosstalk_1.2.0 backports_1.4.1 ## [37] fontLiberation_0.1.0 V8_4.2.2 bookdown_0.31 ## [40] markdown_1.4 RcppParallel_5.1.6 fontBitstreamVera_0.1.1 ## [43] vctrs_0.5.1 abind_1.4-5 cachem_1.0.6 ## [46] withr_2.5.0 checkmate_2.1.0 emmeans_1.8.3 ## [49] xts_0.12.2 prettyunits_1.1.1 svglite_2.1.1 ## [52] crayon_1.5.2 crul_1.3 pkgconfig_2.0.3 ## [55] labeling_0.4.2 nlme_3.1-160 rlang_1.1.1 ## [58] lifecycle_1.0.3 miniUI_0.1.1.1 colourpicker_1.2.0 ## [61] fontquiver_0.2.1 httpcode_0.3.0 extrafontdb_1.0 ## [64] modelr_0.1.10 cellranger_1.1.0 distributional_0.3.1 ## [67] matrixStats_0.63.0 Matrix_1.5-1 loo_2.5.1 ## [70] KMsurv_0.1-5 carData_3.0-5 boot_1.3-28 ## [73] zoo_1.8-11 reprex_2.0.2 base64enc_0.1-3 ## [76] processx_3.8.0 googlesheets4_1.0.1 viridisLite_0.4.1 ## [79] mstate_0.3.2 shinystan_2.6.0 rstatix_0.7.1 ## [82] gridGraphics_0.5-1 ggsignif_0.6.4 scales_1.2.1 ## [85] magrittr_2.0.3 plyr_1.8.8 threejs_0.3.3 ## [88] compiler_4.2.2 rstantools_2.2.0 lme4_1.1-31 ## [91] cli_3.6.0 ps_1.7.2 Brobdingnag_1.2-9 ## [94] MASS_7.3-58.1 tidyselect_1.2.0 stringi_1.7.8 ## [97] textshaping_0.3.6 highr_0.10 yaml_2.3.7 ## [100] askpass_1.1 bridgesampling_1.1-2 survMisc_0.5.6 ## [103] grid_4.2.2 sass_0.4.5 tools_4.2.2 ## [106] timechange_0.1.1 parallel_4.2.2 rstudioapi_0.14 ## [109] uuid_1.1-0 gridExtra_2.3 posterior_1.3.1 ## [112] farver_2.1.1 digest_0.6.31 shiny_1.7.4 ## [115] quadprog_1.5-8 gfonts_0.2.0 car_3.1-1 ## [118] broom_1.0.2 later_1.3.0 httr_1.4.4 ## [121] gdtools_0.3.3 colorspace_2.0-3 rvest_1.0.3 ## [124] fs_1.5.2 splines_4.2.2 yulab.utils_0.0.6 ## [127] statmod_1.5.0 shinythemes_1.2.0 xtable_1.8-4 ## [130] jsonlite_1.8.4 nloptr_2.0.3 rstan_2.26.13 ## [133] R6_2.5.1 pillar_1.9.0 htmltools_0.5.4 ## [136] mime_0.12 glue_1.6.2 fastmap_1.1.0 ## [139] minqa_1.2.5 deSolve_1.34 codetools_0.2-18 ## [142] pkgbuild_1.4.0 mvtnorm_1.1-3 utf8_1.2.2 ## [145] lattice_0.20-45 bslib_0.4.2 numDeriv_2016.8-1.1 ## [148] curl_4.3.3 gtools_3.9.4 officer_0.6.2 ## [151] zip_2.2.2 shinyjs_2.1.0 openssl_2.0.5 ## [154] Rttf2pt1_1.3.8 rmarkdown_2.20 munsell_0.5.0 ## [157] reshape2_1.4.4 gtable_0.3.3 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Cox, D. R. (1972). Regression models and life-tables. J. R. Stat. Soc., 34(2), 187–202. Ellis, S., Snyder-Mackler, N., Ruiz-Lambides, A., Platt, M. L., &amp; Brent, L. J. N. (2019). Deconstructing sociality: The types of social connections that predict longevity in a group-living primate. Proc. Biol. Sci., 286(1917), 20191991. Kurz, A. S. (2021). Applied longitudinal data analysis in brms and the tidyverse (version 0.0.2). https://bookdown.org/content/4253/ Rossi, P. H., Berk, R. A., &amp; Lenihan, K. J. (1980). Money, work and crime: Some experimental results. New York: Academic Press. Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C., Engh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth, R. M., &amp; Cheney, D. L. (2010). Strong and consistent social bonds enhance the longevity of female baboons. Curr. Biol., 20(15), 1359–1361. Swedell, L., Saunders, J., Schreier, A., Davis, B., Tesfaye, T., &amp; Pines, M. (2011). Female “dispersal” in hamadryas baboons: Transfer among social units in a multilevel society. Am. J. Phys. Anthropol., 145(3), 360–370. Thompson, N. A., &amp; Cords, M. (2018). Stronger social bonds do not always predict greater longevity in a gregarious primate. Ecol. Evol., 8(3), 1604–1614. Tung, J., Archie, E. A., Altmann, J., &amp; Alberts, S. C. (2016). Cumulative early life adversity predicts longevity in wild baboons. Nat. Commun., 7. Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 大橋靖雄., 浜田知久馬., &amp; 魚住龍史. (2021). 生存時間解析 第2版 SASによる生物統計. 東京大学出版. 杉本知之. (2021). 生存時間解析. 朝倉書店. 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. 粕谷英一. (2012). 一般化線形モデル. 共立出版. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
