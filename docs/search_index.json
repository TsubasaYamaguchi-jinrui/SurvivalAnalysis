[["index.html", "Event History and Survival Analysis Using R 本稿の目的", " Event History and Survival Analysis Using R Tsubasa Yamaguchi 2023-05-31 本稿の目的 本稿はイベント・ヒストリー分析(event history analysis)または生存時間分析（Survival Analysis）と呼ばれる手法の概要をまとめたものである。また、Rでこうした分析を実行する方法についても解説している。新たに個人的に勉強した内容があれば、随時追加していく。 本稿が主に参考にしたのは参考にしたのは Allison (2014) の”Event History and Survival Analysis, Second Edition”である。 また以下の書籍やサイトも参考にした。 杉本 (2021) 生存時間解析. 朝倉書店 大橋 et al. (2021) 生存時間解析 第2版 SASによる生物統計. 東京大学出版 Kurz (2021) Applied longitudinal data analysis in brms and the tidyverse. Survival Analysis in R 疫学のためのRハンドブック なお、本稿の作成に使用したファイルとRのコードは筆者のGithubですべて閲覧できる。 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. Kurz, A. S. (2021). Applied longitudinal data analysis in brms and the tidyverse (version 0.0.2). https://bookdown.org/content/4253/ 大橋靖雄., 浜田知久馬., &amp; 魚住龍史. (2021). 生存時間解析 第2版 SASによる生物統計. 東京大学出版. 杉本知之. (2021). 生存時間解析. 朝倉書店. "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 生存時間解析の実行と結果の描画には以下のパッケージを使用している。 survivalパッケージ flexsurvパッケージ ehaパッケージ metsパッケージ flexsurvパッケージ survminerパッケージ brmsパッケージ rstanarmパッケージ ## 生存時間分析 library(survival) library(ggsurvfit) library(eha) library(flexsurv) library(brms) library(rstanarm) ## ggplotでの可視化 library(survminer) ## データハンドリング library(tidyverse) library(haven) library(easystats) ## グラフや表関連 library(patchwork) library(flextable) library(ggeffects) library(DT) library(knitr) library(kableExtra) library(stargazer) library(ggsci) library(lemon) library(ggplotify) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) なお、本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham &amp; Grolemund, 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang, 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al., 2021) 出版社サイト References Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. "],["Chapter1.html", "1 はじめに 1.1 イベントヒストリー分析とは何か 1.2 イベント・ヒストリー分析の難しさ 1.3 イベント・ヒストリー分析の種類", " 1 はじめに 1.1 イベントヒストリー分析とは何か イベント・ヒストリーとは、研究対象である「個体や集団で、ある事象が生じた時間的な記録」を意味する。霊長類学では、個体が何歳で死亡したかや、オスが何年群れに在籍したかといったデータがこれに該当する。イベント・ヒストリー分析(event history analysis)または生存時間分析(survival analysis)1は、イベント・ヒステリーを持つデータを用いて、事象の発生パターンや発生の原因を分析する一連の手法である。例えば霊長類の研究では、個体の寿命に影響する要因を調べたり(Ellis et al., 2019; Silk et al., 2010; Thompson &amp; Cords, 2018; Tung et al., 2016)、オスが群れに在籍する確率が時間と共にどう変化するのかを調べたりする(Swedell et al., 2011)ために用いられている。 1.2 イベント・ヒストリー分析の難しさ イベント・ヒストリーを持つデータの分析が難しい要因としては、扱うデータに以下の2つの特殊性があることが多いことが挙げられる。イベント・ヒストリー分析では、これらの困難に対処するため様々な手法が研究されてきた。 1.2.1 打ち切り イベント・ヒステリーを持つデータの特殊性の一つは、打ち切りが存在する点である。 具体例として、 Rossi et al. (1980) のデータを見ていこう。この研究では、432名の服役囚が出所後12ヶ月間に再逮捕されるかどうかを調べ、それに年齢や人種、学歴、配偶状態などの要因が影響しているかを調べようとしている。変数の詳細は、こちらを参照。 Rossi &lt;- read_csv(&quot;data/Rossi.csv&quot;) Rossi %&gt;% head(20) %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 実際にデータからランダムに抽出した20人が再逮捕されたかどうかを見ていこう(図1.1)。arrestは再逮捕されたかどうかを0/1で、weekは再逮捕された場合出所後何週間目だったかを表している。図からわかるように、12ヶ月(52週)経過後も逮捕されていないデータが数多く存在することが分かる。 Rossi %&gt;% sample_n(20) %&gt;% mutate(id = row_number()) %&gt;% mutate(arrest = as.factor(arrest)) %&gt;% ggplot(aes(x = week, y = id))+ geom_segment(aes(x = 0, xend = week, yend = id, y = id), color = &quot;grey&quot;)+ geom_point(shape = 23, size = 3, aes(fill = arrest))+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1) 図1.1: 服役囚が出所後何週間で逮捕されたか このようなデータは、通常の分析ではデータを扱うのが難しい。なぜなら、再逮捕されなかった服役囚に適切に従属変数2を割り当てることができないからである。彼らは10年たっても再逮捕されなかったかもしれないし、出所後13ヶ月に再逮捕されていたかもしれないが、このデータから知ることは不可能である。彼らに一律に同じ値を割り振っても（例えば期間の最大値である1年を割り振る）、彼らのデータを除外してもデータに大きなバイアスがかかってしまう。 このように、測定値が不完全にしかわからないデータを打ち切りデータという。打ち切りには、上記のように(1)調査終了時点ではまだイベントが起きていない場合と、(2)何らかの事情(e.g., 予期せぬ死、消息不明など)で調査期間の途中でその個体のデータが追跡できなくなっている場合(= 脱落)の2種類が存在する。 1.2.2 時間依存共変量 もう一つの特殊性は、対象の期間中に独立変数の値が変化する場合があることである（＝時間依存共変量）。 例えば、先ほどの例でも対象の12ヶ月の間に仕事の有無が変化していた(emp1~emp52)。こうした場合、回帰モデルに1ヶ月ごとの仕事の有無（e.g., 1ヶ月目の仕事の有無、2ヶ月目の仕事の有無、…）をすべて独立変数として入れることはできるが、この方法では出所後12ヶ月以内に再逮捕された服役囚に対して独立変数を割り振れないところが出てくる。なぜなら、出所後3ヶ月で再逮捕されたとすると、その服役囚の4ヶ月目以降の仕事のデータはないからである。 1.3 イベント・ヒストリー分析の種類 イベント・ヒストリー分析の手法は以下のような点を基準に分類される。本稿では、まず単純なモデルの説明から始め、徐々に難しいモデルの説明へ移る。 1.3.1 繰り返しの有無 生物学で扱うことの多い「死」という事象は一個体に一度しか生じないが、転職や結婚といった事象を扱う場合、これらは個人の一生において何度も発生する可能性がある。繰り返しの阿辻賞を扱う際にはより複雑な分析モデルが必要になる。 1.3.2 単一の事象と複数の事象 例えば生物の生死を扱うとき、多くの場合では死亡のタイプ（e.g., 死因など）を区別せず単一の死亡として扱う。しかし、死亡のタイプを分けて分析を行うことも可能である。このような複数の事象を扱うためには、単一な事象を扱う分析よりも複雑なモデルが必要である。 1.3.3 パラメトリック法とノンパラメトリック法 分析には、事象の発生時間の分布（どのような時間間隔で事象が発生するか）に仮定を置かないノンパラメトリックな分析と、特定の分布族（e.g., 指数分布、ワイブル分布など）を仮定するパラメトリックな分析がある。また、これら2つを結合したCoxの比例ハザードモデルは事象の発生時間に特定の分布を仮定しないが、線形関数に基づく回帰モデルであるというという点でセミパラメトリックな手法であるといえる。 1.3.4 離散時間と連続時間 事象の発生時間が正確に記録できている場合は「連続時間」モデルといわれる。通常は、時間の測定単位が小さい場合は（時間、分、秒）、連続時間として扱ってよい。一方、時間の測定単位が大きい場合（月、年）は「離散時間」モデルで扱うのが適している。実際の分析では離散時間モデルの方が理解するのが容易である。 References Ellis, S., Snyder-Mackler, N., Ruiz-Lambides, A., Platt, M. L., &amp; Brent, L. J. N. (2019). Deconstructing sociality: The types of social connections that predict longevity in a group-living primate. Proc. Biol. Sci., 286(1917), 20191991. Rossi, P. H., Berk, R. A., &amp; Lenihan, K. J. (1980). Money, work and crime: Some experimental results. New York: Academic Press. Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C., Engh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth, R. M., &amp; Cheney, D. L. (2010). Strong and consistent social bonds enhance the longevity of female baboons. Curr. Biol., 20(15), 1359–1361. Swedell, L., Saunders, J., Schreier, A., Davis, B., Tesfaye, T., &amp; Pines, M. (2011). Female “dispersal” in hamadryas baboons: Transfer among social units in a multilevel society. Am. J. Phys. Anthropol., 145(3), 360–370. Thompson, N. A., &amp; Cords, M. (2018). Stronger social bonds do not always predict greater longevity in a gregarious primate. Ecol. Evol., 8(3), 1604–1614. Tung, J., Archie, E. A., Altmann, J., &amp; Alberts, S. C. (2016). Cumulative early life adversity predicts longevity in wild baboons. Nat. Commun., 7. このような分析手法は様々な分野で発展してきたため、分野ごとに呼ばれ方が異なる。例えば生物学では動物の寿命を扱うことが多いため「生存時間分析」、工学の分野では機械の故障を扱うことが多いため「故障時間分析」などと呼ばれる。「イベント・ヒストリー分析」という呼び方は、こうした様々な分野で発展した分析手法の包括的な呼称である。↩︎ 従属変数、独立変数がわからない場合はこちらを参照。↩︎ "],["Chapter2.html", "2 離散時間モデル 2.1 離散時間モデルの例 2.2 離散時間ハザード 2.3 ロジスティック回帰モデル 2.4 モデルの推定 2.5 Rでの実装 2.6 尤度比検定 2.7 離散時間ロジスティック回帰モデルの注意点 2.8 打ち切りデータの扱い 2.9 離散時間モデルと連続時間モデル", " 2 離散時間モデル 本章では、繰り返しのない単一の事象を離散時間モデルで分析する方法を概観する。 2.1 離散時間モデルの例 ここでは具体例として、1950年代後半から60年代前半に博士号を取得した生化学者301人(助教として勤務経験あり)が准教授に昇進するのに要する年数を記録したデータを使用する。データはdataフォルダにある(rank.dta)。dta形式のファイルは、havenパッケージのread_dta()で読み込める。 library(haven) rank &lt;- read_dta(&quot;data/rank.dta&quot;) データの先頭10行を取り出すと以下のようになっている。変数の説明は以下の通り。 ここでは、独立変数を用いて1年ごとの昇進の条件付き確率を回帰モデルを用いて推定することを目的とする。 従属変数にかかわる変数 - dur: 助教としての勤続年数 - promo: 助教への昇進の有無 独立変数(非時間依存変数) - undgrad: 対象者の出身学部の選抜の厳しさの尺度 - phdprest: 博士号を取得した大学の威信の尺度 - phdmed: 医学博士の有無 独立変数(時間依存変数) - prest: 勤務している大学の威信の尺度 - arts: 勤続年数ごとの累積発表論文数 - cits: 勤続年数ごとの論文の累積被引用回数 そのほか jobtime: 職場を変わった場合、何年目に変わったか rank %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 准教授への昇進時期の分布は以下のようになる(表2.1)。なお、リスク集合(risk set)とは、各時点で事象を経験する可能性のある個体の集まり、ハザード率(hazard rate)とは、ある時点でリスク集合に入っている個体がその時点で事象を経験する条件付き確率である(i.e., この表では昇進人数/リスク集合の大きさ)。 打ち切りは、25人については10年たっても准教授に昇進できていないために生じているが、それ以外については大学を離れたために生じている。 rank %&gt;% group_by(dur) %&gt;% summarise(昇進人数 = sum(promo), 打ち切り数 = sum(promo == &quot;0&quot;)) %&gt;% rename(勤続年数 = dur) %&gt;% ungroup() -&gt; hyou1 hyou1 %&gt;% mutate(勤続年数 = 勤続年数+1) %&gt;% mutate(N = 昇進人数 + 打ち切り数) %&gt;% mutate(sum = cumsum(N)) -&gt; hyou1_b hyou1 %&gt;% left_join(hyou1_b %&gt;% select(勤続年数, sum)) %&gt;% replace_na(list(sum = 0)) %&gt;% mutate(リスク集合の大きさ = sum(昇進人数 + 打ち切り数) - sum) %&gt;% select(-sum) %&gt;% mutate(推定されたハザード率 = 昇進人数/リスク集合の大きさ) %&gt;% kable(align = &quot;c&quot;, caption = &quot;准教授への昇進時期の分布&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.1: 准教授への昇進時期の分布 勤続年数 昇進人数 打ち切り数 リスク集合の大きさ 推定されたハザード率 1 1 1 301 0.0033223 2 1 6 299 0.0033445 3 17 12 292 0.0582192 4 42 10 263 0.1596958 5 53 9 211 0.2511848 6 46 7 149 0.3087248 7 31 6 96 0.3229167 8 15 2 59 0.2542373 9 7 6 42 0.1666667 10 4 25 29 0.1379310 2.2 離散時間ハザード イベント・ヒストリー分析では、上でも説明した「リスク集合」と「ハザード率」の二つが重要な概念である。分析ではハザード率を従属変数として、それぞれの独立変数がハザード率に与える影響を分析していく。 2.3 ロジスティック回帰モデル 離散時間モデルでは、ロジット変換3を利用することでハザード関数\\(P(t)\\)を以下のようにあらわす。なお、\\(x_1\\)は非時間依存変数を、\\(x_2(t)\\)は時間依存変数を表す。また、\\(t\\)は勤続年数を表す。\\(b_1\\)と\\(b_2\\)は偏回帰係数と呼ぶ。ロジット変換を施すことで、右辺がどのような値も取っても\\(P(t)\\)が0から1の範囲に収まる。 \\[ \\begin{equation} log\\biggl(\\frac{P(t)}{1-P(t)}\\biggl) = b_0 + b_1x_1 + b_2x_2(t) + b_3t + b_4t^2 \\tag{2.1} \\end{equation} \\] 2.4 モデルの推定 次に、データを基にパラメータ(\\(b_1から b_4\\))を推定する。推定は基本的に最尤法を用いて行う。これは、実際に観察された値が得られる確率が最大になるようにパラメータを推定する方法である。 実際の推定手順は以下のようになる。 各個体がリスク集合に入っている期間をある時間単位で分け(今回は1年)、その1単位ごと(= 人年ごと)に事象の発生を記録していく。 各個体は各単位ごとに(この場合は1年ごとに)昇進した場合は従属変数に1を、してない場合は0を割り当てられる。 データセットを作成し、最尤法を用いてロジスティック回帰モデルのパラメータを推定する。 2.5 Rでの実装 2.5.1 データの加工 それでは、Rで実際にモデルのパラメータを推定してみる。分析をするためには、データフレームを縦長にする必要がある。具体的には、発表論文数(art1art10)と被引用数(cit1cit10)をそれぞれ一列にする必要がある。 rank %&gt;% ## 個体IDの列を作成 rowid_to_column(var = &quot;id&quot;) %&gt;% ## 勤続年数ごとの論文数を一列に pivot_longer(cols = art1:art10, names_to = &quot;art&quot;, values_to = &quot;art_n&quot;) %&gt;% ## 欠損値を除く filter(!is.na(art_n)) %&gt;% arrange(id) %&gt;% ## 行番号を作る rowid_to_column(&quot;rowid&quot;) %&gt;% select(-(cit1:cit10), -art) -&gt; rank2 rank %&gt;% ## 個体IDの列を作成 rowid_to_column(var = &quot;id&quot;) %&gt;% ## 勤続年数ごとの引用数を一列に pivot_longer(cols = cit1:cit10, names_to = &quot;cit&quot;, values_to = &quot;cit_n&quot;) %&gt;% ## 欠損値を除く filter(!is.na(cit_n)) %&gt;% arrange(id) %&gt;% ## 行番号を作る rowid_to_column(&quot;rowid&quot;) %&gt;% select(cit_n, rowid) -&gt; rank3 ## 結合 rank2 %&gt;% inner_join(rank3, by = &quot;rowid&quot;) %&gt;% arrange(id) %&gt;% group_by(id) %&gt;% ## 個体ごとに勤続年数の列を作成 mutate(year = row_number()) %&gt;% ## 変数promoが昇進のあった年のみ1をとるようにする ungroup() %&gt;% mutate(promo = ifelse(year &lt; dur,0,promo)) %&gt;% ## jobtimeの欠損値を0に replace_na(list(jobtime = 0)) %&gt;% ## 大学威信度の列を作成 mutate(jobpres = ifelse(year &lt; jobtime, prest1, prest2)) %&gt;% select(-prest1, -prest2)-&gt; rank4 できたデータシートは以下の通り。 datatable(rank4, options = list(scrollX = 100), rownames = FALSE) 2.5.2 分析 それでは、実際に分析する。分析には一般化線形モデルによる分析ができるglm()関数を用いる。 まずは1つ目のモデルとして、勤続年数を入れない線形モデルを考えてみる。 mod1 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n, data = rank4, family = binomial(link = &quot;logit&quot;)) 結果は以下の通り(表2.2)。 model_parameters(mod1) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod1の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.2: mod1の結果 Parameter Coefficient 95%CI SE z p (Intercept) -2.9636747 [-3.80, -2.15} 0.4210727 -7.0383926 0.0000000 undgrad 0.1802769 [0.06, 0.30} 0.0607534 2.9673535 0.0030038 phdmed -0.2650547 [-0.58, 0.05} 0.1614778 -1.6414308 0.1007080 phdprest -0.0029980 [-0.18, 0.17} 0.0886335 -0.0338249 0.9730168 jobpres -0.2535299 [-0.46, -0.05} 0.1054517 -2.4042272 0.0162067 art_n 0.1270934 [0.10, 0.16} 0.0165769 7.6669053 0.0000000 cit_n -0.0014547 [-0.00, 0.00} 0.0012590 -1.1554230 0.2479173 2つ目のモデルとして、勤続年数とその二乗を説明変数に入れたモデルを考える。 mod2 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + year + I(year^2), data = rank4, family = &quot;binomial&quot;) 結果は以下の通り(表2.3)。 model_parameters(mod2) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod2の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.3: mod2の結果 Parameter Coefficient 95%CI SE z p (Intercept) -8.4846678 [-10.07, -7.02} 0.7756586 -10.9386630 0.0000000 undgrad 0.1939331 [0.07, 0.32} 0.0635127 3.0534551 0.0022622 phdmed -0.2356943 [-0.57, 0.10} 0.1717631 -1.3722061 0.1699993 phdprest 0.0270565 [-0.16, 0.21} 0.0931669 0.2904086 0.7715036 jobpres -0.2535406 [-0.48, -0.03} 0.1138113 -2.2277268 0.0258987 art_n 0.0733840 [0.04, 0.11} 0.0181374 4.0459977 0.0000521 cit_n 0.0001255 [-0.00, 0.00} 0.0013125 0.0956291 0.9238152 year 2.0818890 [1.65, 2.56} 0.2337665 8.9058484 0.0000000 I(year^2) -0.1585829 [-0.20, -0.12} 0.0203027 -7.8109434 0.0000000 2つのモデルを比較すると以下の通り。 stargazer(mod1, mod2, type = &quot;text&quot;) ## ## ============================================== ## Dependent variable: ## ---------------------------- ## promo ## (1) (2) ## ---------------------------------------------- ## undgrad 0.180*** 0.194*** ## (0.061) (0.064) ## ## phdmed -0.265 -0.236 ## (0.161) (0.172) ## ## phdprest -0.003 0.027 ## (0.089) (0.093) ## ## jobpres -0.254** -0.254** ## (0.105) (0.114) ## ## art_n 0.127*** 0.073*** ## (0.017) (0.018) ## ## cit_n -0.001 0.0001 ## (0.001) (0.001) ## ## year 2.082*** ## (0.234) ## ## I(year2) -0.159*** ## (0.020) ## ## Constant -2.964*** -8.485*** ## (0.421) (0.776) ## ## ---------------------------------------------- ## Observations 1,741 1,741 ## Log Likelihood -595.566 -506.013 ## Akaike Inf. Crit. 1,205.132 1,030.025 ## ============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 2.5.3 結果の解釈 モデル1(mod1)では(表2.2)、3つの独立変数が有意に准教授への昇進のハザード率に影響していることが分かる(undgrad、jobpres、art_n)。具体的には、より選抜度合いの高い大学を卒業した生化学者とより多くの論文を発表した生化学者はハザード率が高い。一方で、より威信度の高い大学で現在働いている生化学者ほどハザード率は低い。 各変数が1増加したときに、准教授に昇進するオッズ比(\\(\\frac{P(t)}{1-P(t)}\\))がどの程度増加するかを計算すると(これは、\\(e^{偏回帰係数}\\)で求まる。式(2.1)を参照)、以下のようになる。すなわち、「学部選抜度(undgrad)」が1増えるとオッズ比が約1.2倍に、「累積論文発表数(art_n)」が1増えるとオッズ比が約1.14倍になる。一方、「勤務先の大学の威信度(jobpres)」が1増加すると、オッズ比は0.78倍に減少する。 model_parameters(mod1) %&gt;% data.frame() %&gt;% select(Parameter, Coefficient) %&gt;% mutate(odds = exp(Coefficient)) ## Parameter Coefficient odds ## 1 (Intercept) -2.963674661 0.05162885 ## 2 undgrad 0.180276920 1.19754894 ## 3 phdmed -0.265054700 0.76716399 ## 4 phdprest -0.002998022 0.99700647 ## 5 jobpres -0.253529874 0.77605656 ## 6 art_n 0.127093447 1.13552312 ## 7 cit_n -0.001454692 0.99854637 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.1)。曲線はモデルに基づく回帰曲線を、塗りつぶし部分は95%信頼区間を表す。 fit_mod1_a &lt;- ggpredict(mod1, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod1_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit1_a fit_mod1_b &lt;- ggpredict(mod1, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod1_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit1_b p_fit1_a + p_fit1_b 図2.1: モデル1の推定結果 モデル2も結果自体は大きく変わらないが、勤続年数とその二乗が有意に影響していることが分かる。また、「累積論文発表数(art_n)」の偏回帰係数が大幅に小さくなっており、オッズ比も1.14倍から1.08倍に減少している。 model_parameters(mod2) %&gt;% data.frame() %&gt;% select(Parameter, Coefficient) %&gt;% mutate(odds = exp(Coefficient)) ## Parameter Coefficient odds ## 1 (Intercept) -8.4846678008 0.000206612 ## 2 undgrad 0.1939331150 1.214015081 ## 3 phdmed -0.2356943107 0.790022138 ## 4 phdprest 0.0270564703 1.027425820 ## 5 jobpres -0.2535405982 0.776048238 ## 6 art_n 0.0733840049 1.076143702 ## 7 cit_n 0.0001255168 1.000125525 ## 8 year 2.0818890246 8.019603843 ## 9 I(year^2) -0.1585829127 0.853352207 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.2)。左図の傾きが図2.1に比べて緩やかになっており、図からもモデル1との違いが読み取れる。 fit_mod2_a &lt;- ggpredict(mod2, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod2_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit2_a fit_mod2_b &lt;- ggpredict(mod2, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod2_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit2_b p_fit2_a + p_fit2_b 図2.2: モデル2の推定結果 2.6 尤度比検定 あるモデルが別のモデルの「入れ子」構造(一方のモデルが他方のモデルの独立変数をすべて含む)であるとき、尤度比検定によってどちらの方が適合度が高いか検定を行うことができる。2つのモデルの対数尤度の差の2倍が\\(\\chi^2\\)分布に近似できることを利用して帰無仮説検定を行うことが多い4。 Rでは以下のように行う。結果を見ると、モデル2の方が有意に適合度が高いことが分かる。 このような検定は、本稿で以後出てくるモデルやパラメータの検定にも応用可能である。 anova(mod1,mod2, test = &quot;Chisq&quot;) ## Analysis of Deviance Table ## ## Model 1: promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n ## Model 2: promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + ## year + I(year^2) ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 1734 1191.1 ## 2 1732 1012.0 2 179.11 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.7 離散時間ロジスティック回帰モデルの注意点 上記のモデルにはいくつか注意点がある。 一個体が複数の事象を経験する場合は、事象の回数の影響を修正する必要がある。 ロバスト推定による標準誤差を求めたり、一般化推定式やランダム(変量)効果モデルを用いたりする。 区切る時間単位を適切に設定する必要がある。 今回は、准教授の昇進が各年度の初めに行われるため、1年ごとにデータを区切ることは適切であった。これを1日ごとに区切るとデータが膨大になってしまうし、５年ごとに区切ると多くの情報が失われてしまう。分析対象の事象に応じて、適切に区切る時間単位を適切に設定する必要がある。 代替手法 式(2.1)は独立変数のハザード率に対する影響を検討する最も知られた方法だが、以下の「補対数対数モデル」も代替手法として有用である。このモデルでも、右辺がどのような値をとろうと\\(P(t)\\)は0から1に収まる。 \\[ \\begin{equation} log[-log(1-P(t))] = b_0 + b_1x_1 + b_2x_2(t) + b_3t + b_4t^2 \\tag{2.2} \\end{equation} \\] Rでは、以下のように実装できる。 mod3 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + year + I(year^2), data = rank4, family = binomial(link = &quot;cloglog&quot;)) 結果は以下の通り(表2.4)。ロジスティック回帰モデルと結果は大きく変わらない。特にP地だけに着目する場合はどちらのモデルを選んでも決定的な差はない。 model_parameters(mod3) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod3の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.4: mod3の結果 Parameter Coefficient 95%CI SE z p (Intercept) -7.9961202 [-9.40, -6.69} 0.6943534 -11.5159220 0.0000000 undgrad 0.1694896 [0.06, 0.28} 0.0548959 3.0874751 0.0020186 phdmed -0.2153786 [-0.50, 0.08} 0.1469985 -1.4651751 0.1428732 phdprest 0.0100102 [-0.15, 0.17} 0.0806278 0.1241530 0.9011941 jobpres -0.1934044 [-0.38, -0.01} 0.0967829 -1.9983313 0.0456808 art_n 0.0623539 [0.03, 0.09} 0.0142864 4.3645723 0.0000127 cit_n -0.0004238 [-0.00, 0.00} 0.0010398 -0.4075788 0.6835830 year 1.9223437 [1.53, 2.36} 0.2128381 9.0319539 0.0000000 I(year^2) -0.1469834 [-0.19, -0.11} 0.0184860 -7.9510496 0.0000000 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.3)。 fit_mod3_a &lt;- ggpredict(mod3, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod3_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit3_a fit_mod3_b &lt;- ggpredict(mod3, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod3_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit3_b p_fit3_a + p_fit3_b 図2.3: モデル3の推定結果 2.8 打ち切りデータの扱い 今回のデータでは打ち切りは以下の2通りで生じており、これらは「右側打ち切り(right censoring)」と呼ばれ、最後に対象が観察された時点で事象がまだ発生していないことによるものである。 10年経ってもまだ准教授に昇進していない(= 固定打ち切り(fixed censoring))) 打ち切りの時点は全ての個体で同じ。 准教授昇進前に大学を辞めた(= ランダムな打ち切り(random censoring)) 打ち切りの時点は個体によって異なる。脂肪や転居による追跡の終了などが理由。ただし、「ランダム」とは打ち切りのタイミングが変数と一切関係ないという意味でない点に注意。 2の場合、ほぼすべてのイベント・ヒストリー分析では打ち切りが生じた時間は「無情報」であると仮定している。すなわち、特定の時点である個体に打ち切りが生じても、その個体のハザード率には何の要因も影響していないことを仮定している。この仮定は、今回の例では昇進の可能性の低い研究者ほど大学を辞める傾向があるのであれば妥当ではない。おそらく何人かは准教授に昇進できずに雇用期間が終了したことが打ち切りの原因になっていたと考えられる。 しかし、今のところこの仮定を緩めて分析する方法はなく、ほとんどの研究者はこの問題に目をつぶって分析を行うしかない。そのため、研究デザインの段階でランダムでない打ち切りを最小限にするために可能な限りあらゆることを行う必要がある。 2.9 離散時間モデルと連続時間モデル 一般的に、離散時間モデルは後述する連続時間モデルと極めて似た結果をもたらすことが多い。実際、式(2.1)の離散時間モデルは、時間の単位を小さくするにつれて第4章で見る比例ハザードモデルに近づく。したがって、離散時間モデルと連続時間モデルのいずれを用いるかは一般的に計算にかかる手間と簡便さを考慮して判断する。時間依存の独立変数がない場合、しばしば以降の2つの章で説明する連続時間モデルを使う方が簡単である。他方、時間依存の独立変数があるならば、いずれのモデルでも手間や簡便さは変わらない。 References 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 粕谷英一. (2012). 一般化線形モデル. 共立出版. ロジット変換がわからない方はこちら。 ↩︎ 対数尤度や尤度比検定の詳細については、 粕谷 (2012) や 久保 (2012) を参照。パラメトリックブーストラップ法を用いたより正確な検定を行うこともできる(久保, 2012)。↩︎ "],["Chapter3.html", "3 連続時間を用いたパラメトリックな手法 3.1 連続時間ハザード率 3.2 パラメトリックな比例ハザードモデル 3.3 加速時間ハザードモデル 3.4 Rでの実装 3.5 適合度の評価 3.6 観察されない異質性の原因 3.7 なぜパラメトリックモデルを用いるのか", " 3 連続時間を用いたパラメトリックな手法 前章(2)の離散時間モデルは汎用性が高いが、イベント・ヒストリー分析では連続時間モデルが使われることが多い。本章では、事象が起きた時点が正確に記録されているデータに対して一般的に使われるパラメトリックな手法を解説する。この方法では、推定されるパラメータを除いて、モデルに含まれる値の分布の型がはっきり仮定される。 3.1 連続時間ハザード率 連続時間モデルでは、時点\\(t\\)で事象を経験する可能性のある個体が、時点\\(t\\)から\\(t+s\\)までの間に事象を経験する確率\\(P(t,t+s)\\)を考える。なお、\\(t=1\\)のとき、これは離散時間のハザード率と同じになる。 この確率を\\(s\\)で割り、\\(s\\)を0に限りなく近づけたときの極限値が連続時間のハザード率になる(式(3.1))。この値は、1より大きな値をとることもあるが負にはならない。 \\[ h(t) = \\lim_{s \\to 0} \\frac{P(t,t+s)}{s} \\tag{3.1} \\] ハザード関数\\(h(t)\\)の形によって連続時間のイベント・ヒストリー分析のタイプが分類できる。 3.2 パラメトリックな比例ハザードモデル 3.2.1 モデルの分類 パラメトリックな分析には、「比例ハザードモデル(proportional hazards model)」と「加速時間ハザードモデル(accelerated failure time model)」の2種類があるが、本節では前者について解説する。 比例ハザードモデルは、ハザード関数が時間と独立変数によってどのように規定されるかによって、以下の3つに分類できる。なお、いずれのモデルでもパラメータの推定は最尤法で行う。 3.2.1.1 指数回帰モデル 最もわかりやすい分析は、\\(h(t)\\)を独立変数の線形関数にすることである(式(3.2))。左辺で\\(log\\)をとっているのは、線形関数が0より小さくならないようにするためである。\\(x_1\\)と\\(x_2\\)は非時間依存の独立変数を、\\(b_0\\)~\\(b_2\\)は推定されるパラメータを表す。なかでも\\(b_1\\)と\\(b_2\\)は偏回帰係数である。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 \\tag{3.2} \\] この式ではハザード関数は時間に依存しない(= 時間に対して一定)。このようなモデルでは通常事象が発生するまでの時間として指数分布5を仮定するので、「指数回帰モデル」といわれる。指数分布の確率密度関数は1つのパラメータ\\(\\lambda\\)を用いて以下のように表せる。ハザード率は一定の値\\(\\lambda\\)で与えられる。 \\[ f(t) = \\lambda e^{-\\lambda t} \\;\\; (t \\geq 0) \\tag{3.3} \\] 3.2.1.2 ゴンぺルツ回帰モデル 一般的に、ハザード率が時間を通して一定であると仮定するのは現実的でない。例えば生物の死を考えると、老化するほど死亡する確率は増大するはずである。そこで、指数回帰モデルの仮定を緩め、ハザード率の対数(log)が時間と共に直線的に増加/現象すると仮定するモデルを考える(式(3.4))。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + ct \\tag{3.4} \\] このようなモデルでは通常事象が発生するまでの時間としてゴンぺルツ分布6を仮定するので、「ゴンぺルツ回帰モデル」といわれる。ゴンぺルツ分布の確率密度関数は２つのパラメータ\\(a\\)と\\(b\\)を用いて以下のように表せる。ハザード率は\\(ae^{bt}\\)で与えられる。 \\[ f(t) = a exp(at - \\frac{a}{b}e^{bt} + \\frac{a}{b}) \\;\\;(t \\geq 0) \\tag{3.5} \\] 3.2.1.3 ワイブル回帰モデル あるいは、ハザード率の対数が時間の対数と共に直線的に増加/減少するモデルを考えることもできる(式(3.6))。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + clog(t) \\tag{3.6} \\] このようなモデルでは通常事象が発生するまでの時間としてワイブル分布7を仮定するので、「ワイブル回帰モデル」といわれる。ワイブル分布の確率密度関数は２つのパラメータ\\(a\\)と\\(b\\)を用いて以下のように表せる。ハザード率は\\(\\frac{a}{b^a} t^{a-1}\\)で与えられる。なお、式からわかるように指数分布はワイブル分布で\\(a=1\\)のときである(\\(\\lambda = 1/b\\))。 \\[ f(t) =\\frac{a}{b} \\biggl(\\frac{t}{b}\\biggl)^{a-1} exp\\biggl(-\\biggl(\\frac{t}{b}\\biggl)^a\\biggl) \\;\\;(t \\geq 0) \\tag{3.7} \\] 3.2.2 注意点 時間と独立変数の間の交互作用がない \\(x_1\\)と\\(x_2\\)の効果(\\(b_1\\)と\\(b_2\\))は全ての時点で同じである。 ワイブル回帰モデルもゴンぺ留津回帰モデルも時間に対して単調増加/減少である ハザード率と時間の関係がU字型や逆U字型になることはない。これは、実際の分析では使いにくい場合がある。なお、第??でこの制約のないモデルを検討する。 誤差項がない ただし、実際に事象が発生するまでの時間とモデルで推定される時間には誤差が含まれるので、決定論的なモデルではない。 3.2.3 Rでの実装 3.2.3.1 データの読み込み まず、分析に用いる第1章で触れた服役囚の再販データを読み込む。このデータでは、432人の元服役囚の内、ランダムに選ばれた半分は経済的支援を受け、残りの半分は対照群として支援を受けなかった。変数の説明は以下の通り。なお、時間依存的な変数は本章では扱わず、次章で扱う。 従属変数にかかわる変数 - week: 出所後の経過週数 - arrest: 再犯の有無 独立変数(非時間依存変数) - age: 年齢 - race: 黒人か否か(1/0) - mar: 婚姻の有無(1/0) - prio: 前科の数 - paro: 仮釈放か否か(1/0) - wexp: 過去の就業経験の有無(1/0) - fin: 経済的支援の有無(1/0) 独立変数(時間依存変数) - work: 週ごとの就業状態 recid &lt;- read_dta(&quot;data/recid.dta&quot;) recid %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 3.2.3.2 分析の実行 ehaパッケージのphreg関数を用いる。従属変数としては、期間中に事象を経験したかの変数(arrest)と、事象を経験した場合はその時間を、しなかった場合は打ち切りの時間を示す変数(week)を入れる必要がある。 以下のように実行できる。指数分布はワイブル分布で\\(a=1\\)のときなので、dist = \"weibullでshape = 1としてあげればよい。 ## 指数回帰モデル mod_exp &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;, shape = 1) ## ゴンぺルツ回帰モデル mod_gom &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;gompertz&quot;) ## ワイブル回帰モデル mod_wei &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) 結果は以下の通りである。Coefは偏回帰係数の推定値を、Exp(Coef)は偏回帰係数を指数変換したもの(\\(e^{偏回帰係数}\\))を、se(Coef)は偏回帰係数の標準誤差を表している。ゴンぺルツモデルとワイブルモデルの結果では、shapeは確率密度関数(式(3.5)と式(3.7))のパラメータ\\(a\\)の、scale`はパラメータ\\(b\\)の推定値である。 ## 指数回帰モデル mod_exp ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;weibull&quot;, shape = 1) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.366 0.693 0.191 0.055 ## age 24.765 -0.056 0.946 0.022 0.011 ## race 0.872 0.305 1.357 0.308 0.322 ## wexp 0.596 -0.147 0.864 0.212 0.488 ## mar 0.132 -0.427 0.652 0.381 0.263 ## paro 0.622 -0.083 0.921 0.196 0.673 ## prio 2.841 0.086 1.089 0.028 0.002 ## ## log(scale) 4.051 0.586 0.000 ## ## Shape is fixed at 1 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -686.37 ## LR test statistic 31.22 ## Degrees of freedom 7 ## Overall p-value 5.65729e-05 ## ゴンぺルツ回帰モデル mod_gom ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;gompertz&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.381 0.683 0.191 0.046 ## age 24.765 -0.057 0.944 0.022 0.009 ## race 0.872 0.313 1.367 0.308 0.310 ## wexp 0.596 -0.148 0.862 0.212 0.485 ## mar 0.132 -0.435 0.648 0.382 0.255 ## paro 0.622 -0.082 0.921 0.196 0.674 ## prio 2.841 0.092 1.096 0.029 0.001 ## ## log(scale) 3.894 0.311 0.000 ## log(shape) -0.676 0.816 0.408 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -681.14 ## LR test statistic 33.35 ## Degrees of freedom 7 ## Overall p-value 2.27754e-05 ## ワイブル回帰モデル mod_wei ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;weibull&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.382 0.682 0.191 0.046 ## age 24.765 -0.057 0.944 0.022 0.009 ## race 0.872 0.316 1.371 0.308 0.306 ## wexp 0.596 -0.150 0.861 0.212 0.481 ## mar 0.132 -0.437 0.646 0.382 0.253 ## paro 0.622 -0.083 0.921 0.196 0.673 ## prio 2.841 0.092 1.097 0.029 0.001 ## ## log(scale) 3.990 0.419 0.000 ## log(shape) 0.339 0.089 0.000 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -679.92 ## LR test statistic 33.42 ## Degrees of freedom 7 ## Overall p-value 2.2149e-05 3つのモデルから推定されたハザード関数を描画したのが図3.1である。定義通り、指数回帰モデルでは時間に依らずハザード率が一定であることが分かる。なお、これらは全ての独立変数を平均値にしたときのものであり、以後本稿で示されるハザード関数はいずれも同様である。 as.ggplot(~plot(mod_exp, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;exponential model&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_gom, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Gompertz model&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_wei, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Weibull model&quot;, ylim = c(0,0.03))) 図3.1: モデルから推定されたハザード関数 なお、推定された生存曲線(= 時間の経過とともに再犯をしていない元服役囚の数がどのように減っていくかを表したもの)は以下のようになる(図3.2)。ハザード関数と同様に、これらは全ての独立変数を平均値にしたときのものである。 as.ggplot(~plot(mod_exp, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;exponential model&quot;))+ as.ggplot(~plot(mod_gom, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;Gompertz model&quot;))+ as.ggplot(~plot(mod_wei, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;Weibull model&quot;)) 図3.2: モデルから推定された生存曲線 各モデルの偏回帰係数の推定値を比較したものが以下の表である(表3.1)。３つのモデルの推定結果はほとんど変わらない。いずれのモデルでも有意な影響を持っていたのはageとprioであり、finはワイブル回帰モデルのみで有意になった。 偏回帰係数は、ほかの変数の影響を統制したうえでその独立変数が1増加したときにハザード率の対数(式(3.2) ~ 式(3.6)を思い出してほしい)がどの程度増加するかを表している。例えば指数回帰モデルでは、表3.1の偏回帰係数の推定値(Coef(exp))より、他の変数の影響をコントロールしたときに年齢(age)が1歳上がるとハザード率の対数が0.056低下する。より直感的に理解するためには、偏回帰係数を指数変換すればよい(Exp(Coef_exp))。これは、ハザード比と呼ばれ、独立変数が1増加したときにハザード率の比がどの程度変化するかを示している。例えば、経済的援助がある場合(fin = 1)のハザード率は、ない場合(fin = 0)に比べると0.693倍になる。 tibble(Covariate = mod_exp$covar, &quot;Coef(exp)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_exp))[1:7], &quot;Exp(Coef_exp)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_exp)))[1:7], &quot;Coef(gom)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_gom))[1:7], &quot;Exp(Coef_gom)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_gom)))[1:7], &quot;Coef(wei)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_wei))[1:7], &quot;Exp(Coef_wei)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_wei))[1:7])) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;指数分布&quot;,&quot;ゴンぺルツ&quot;, &quot;ワイブル&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-1a0e7682{}.cl-1a063760{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1a0a5bba{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1a0a70fa{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1a0a7104{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1a0a7105{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表3.1: 各モデルの推定値の比較 指数分布ゴンぺルツワイブルCovariateCoef(exp)Exp(Coef_exp)Coef(gom)Exp(Coef_gom)Coef(wei)Exp(Coef_wei)fin-0.3660.693-0.3810.683-0.3820.682age-0.0560.946-0.0570.944-0.0570.944race0.3051.3570.3131.3670.3161.371wexp-0.1470.864-0.1480.862-0.1500.861mar-0.4270.652-0.4350.648-0.4370.646paro-0.0830.921-0.0820.921-0.0830.921prio0.0861.0890.0921.0960.0921.097 指数回帰モデルはワイブル回帰モデルの特殊な場合(\\(a=1\\)の場合)なので、これらのモデルは尤度比検定で適合度を比較することができる。anova()関数はphregクラスには適用できないようだが、自分で対数尤度を求めることで計算することはできる。以下の自作関数8を用いて尤度比検定を行うと、ワイブル回帰モデルの方が有意に適合度が高い。すなわち、ハザード率が時間によって変化すると考える方がより妥当だと考えられる。 anova.phreg &lt;- function(...){ phreg.models &lt;- list(...) log.liks &lt;- NULL n.parameters &lt;- NULL for(i in 1:length(phreg.models)){ log.liks &lt;- c( log.liks, phreg.models[[i]]$loglik[2] ) n.parameters &lt;- c( n.parameters, nrow(phreg.models[[i]]$var) ) } deviance.models &lt;- -2 * log.liks Df &lt;- n.parameters[-1] - n.parameters[-length(log.liks)] lrs &lt;- deviance.models[-length(log.liks)] - deviance.models[-1] p.values &lt;- 1 - pchisq(lrs, Df) lr.test &lt;- cbind(&quot;deviance&quot; = lrs, Df, p.values) lr.test &lt;- rbind(c(NA, NA, NA), lr.test) output &lt;- cbind(&quot;Log likelihood&quot; = log.liks, n.parameters, lr.test) Call &lt;- match.call() # 以下3行は返値の行列に各モデルの名前をつけるための操作だが、 Call$k &lt;- NULL # 訳も分からず AIC.logLik() を真似ているだけなので、 rownames(output) &lt;- as.character(Call[-1L]) # おかしなことをやっているかも return(output) } anova.phreg(mod_exp, mod_wei) ## Log likelihood n.parameters deviance Df p.values ## mod_exp -686.3659 8 NA NA NA ## mod_wei -679.9166 9 12.89875 1 0.000328801 3.3 加速時間ハザードモデル 3.3.1 モデルの概要 加速時間ハザードモデルは、\\(T\\)を事象が発生するまでの時間とするとき、次のように書くことができる。なお、\\(u\\)は誤差項であり、独立変数とは統計的に独立で均一の分散\\(\\sigma^2\\)をもつ。このモデルは、従属変数を\\(logT\\)とする通常のモデルと同じである。 \\[ logT = b_0 + b_1x_1 + b_2x_2 + u \\tag{3.8} \\] モデルでは誤差項\\(u\\)の分布にとしては、正規分布、対数ガンマ分布、ロジスティック分布、極値分布など様々な分布が仮定される。これらの分布を仮定するとき、\\(T\\)はそれぞれ対数正規分布、ガンマ分布、対数ロジスティック分布、ワイブル分布になる(表3.2)。 tibble(&quot;uの分布&quot; = c(&quot;正規分布&quot;,&quot;対数ガンマ分布&quot;,&quot;ロジスティック分布&quot;,&quot;極値分布&quot;), &quot;Tの分布&quot; = c(&quot;対数正規分布&quot;,&quot;ガンマ分布&quot;,&quot;対数ロジスティック分布&quot;,&quot;ワイブル分布&quot;)) %&gt;% kable(caption = &quot;uの分布とTの分布の対応&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.2: uの分布とTの分布の対応 uの分布 Tの分布 正規分布 対数正規分布 対数ガンマ分布 ガンマ分布 ロジスティック分布 対数ロジスティック分布 極値分布 ワイブル分布 加速ハザードモデルでは従属変数を\\(logT\\)ではなくハザード率になるように書き換えることもできるが、複雑な式になる傾向がある。比例ハザードモデルと異なり、対数ロジスティックモデルと対数正規モデルではハザード率は非単調関数(= 時間の経過とともに柔軟に増えたり減ったりする)である。パラメータの推定値は最尤法によって求められる。 3.4 Rでの実装 ここでは、Allison (2014) に倣って再犯データにガンマ分布モデルを当てはめる。分析にはflexsurvパッケージのflexsurvreg()関数を用いる。このパッケージは比例ハザードモデルも含め様々なパラメトリックモデルに対応している。 以下のようにモデリングできる。methodで採用推定を行うアルゴリズムを指定でき、「Nelder-Mead法」「BFGS法」「L-BFGS法」などを選べる。今回はL-BFGS法を用いる mod_gam &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;gamma&quot;, method = &quot;L-BFGS-B&quot;) 結果は以下の通り。比例ハザードモデルと同様に、ageとprioが5%水準で有意な影響を持った(95%信頼区間が0にまたがっていない)。 mod_gam ## Call: ## flexsurvreg(formula = Surv(week, arrest) ~ fin + age + race + ## wexp + mar + paro + prio, data = recid, dist = &quot;gamma&quot;, method = &quot;L-BFGS-B&quot;) ## ## Estimates: ## data mean est L95% U95% se exp(est) L95% ## shape NA 1.51810 1.21665 1.89424 0.17145 NA NA ## rate NA 0.02684 0.01127 0.06392 0.01188 NA NA ## fin 0.50000 -0.28265 -0.56177 -0.00353 0.14241 0.75378 0.57020 ## age 24.59722 -0.03890 -0.07036 -0.00745 0.01605 0.96184 0.93206 ## race 0.87731 0.23924 -0.20559 0.68408 0.22696 1.27029 0.81417 ## wexp 0.57176 -0.13353 -0.43936 0.17229 0.15604 0.87500 0.64445 ## mar 0.12269 -0.34183 -0.88623 0.20257 0.27776 0.71047 0.41221 ## paro 0.61806 -0.05718 -0.34191 0.22756 0.14527 0.94443 0.71041 ## prio 2.98380 0.06740 0.02453 0.11027 0.02187 1.06973 1.02483 ## U95% ## shape NA ## rate NA ## fin 0.99647 ## age 0.99258 ## race 1.98194 ## wexp 1.18802 ## mar 1.22455 ## paro 1.25553 ## prio 1.11658 ## ## N = 432, Events: 114, Censored: 318 ## Total time at risk: 19809 ## Log-likelihood = -680.0054, df = 9 ## AIC = 1378.011 注意が必要なのは、生存時間分析でよく使われる統計ソフト(StataやSAS)とは偏回帰係数の推定値の正負が逆になっている点である。推定値の正負を逆転させ、指数回帰モデルとワイブル回帰モデルの結果と比較したのが表3.3である。指数回帰モデルやワイブル回帰モデルとガンマ分布モデルの偏回帰係数の正負が逆になるのは、前者がハザード率を従属変数にしているのに対し、後者は事象が起きるまでの時間\\(T\\)を従属変数にしているからである。ハザード率が低いほど\\(T\\)は大きくなるので、偏回帰係数の符号は逆になる。 tibble(Covariate = mod_exp$covar, &quot;Coef(exp)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_exp))[1:7], &quot;Exp(Coef_exp)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_exp)))[1:7], &quot;Coef(wei)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_wei))[1:7], &quot;Exp(Coef_wei)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_wei))[1:7]), &quot;Coef(gam)&quot; = sprintf(&quot;%.3f&quot;,-coef(mod_gam))[3:9], &quot;Exp(Coef_gam)&quot; = sprintf(&quot;%.3f&quot;,exp(-coef(mod_gam)))[3:9]) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;指数分布&quot;,&quot;ワイブル&quot;,&quot;ガンマ&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較2&quot;) .cl-4cc144aa{}.cl-4cba6978{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4cbd64fc{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4cbd7ad2{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cbd7ad3{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cbd7adc{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表3.3: 各モデルの推定値の比較2 指数分布ワイブルガンマCovariateCoef(exp)Exp(Coef_exp)Coef(wei)Exp(Coef_wei)Coef(gam)Exp(Coef_gam)fin-0.3660.693-0.3820.6820.2831.327age-0.0560.946-0.0570.9440.0391.040race0.3051.3570.3161.371-0.2390.787wexp-0.1470.864-0.1500.8610.1341.143mar-0.4270.652-0.4370.6460.3421.408paro-0.0830.921-0.0830.9210.0571.059prio0.0861.0890.0921.097-0.0670.935 ガンマ分布モデルでは、指数変換されたExp(Coef_gam)は事象が起きるまでの時間のとして解釈できる。例えば、経済的支援(fin)の偏回帰係数を指数変換した値は1.327だが、これは経済的支援を受けた元服役囚の方がそうでない元服役囚よりも再犯までの時間が32.7%長くなることを表す。 ガンマ分布以外の分布のモデルはehaパッケージのaftreg()関数か、ガンマ分布と同様にflexsurvreg()関数で実行できる。aftreg()の方がStataなどと符号が同じなので使いやすそう？ ## 対数正規分布 mod_lnorm &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;lognormal&quot;) mod_lnorm2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;lognormal&quot;) ## 対数ロジスティックモデル mod_llog &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;loglogistic&quot;) mod_llog2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;llogis&quot;) ## ワイブル分布 mod_wei_acc &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) mod_wei_acc2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) ## flexsurvreg関数で比例ハザードモデルのワイブル回帰モデルをおこなうときは、`dist = &quot;weibullPH&quot;`とする。 モデルから推定されたハザード関数は以下のようになる(図3.3)。 as.ggplot(~plot(mod_lnorm, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log normal&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_llog, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log logistic&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_wei_acc, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Weibull model (AFT)&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03))) 図3.3: モデルから推定されたハザード関数 3.5 適合度の評価 たくさんのモデルがあるが、どのモデルが最も妥当なモデルといえるだろうか?以下では、まったく同じデータを使用しているモデルに限ってその比較方法を見ていく。 1つの目の方法としては、推定されたモデルの対数尤度(= 推定したモデルから観測データが得られる確率の対数)を比較することである。対数尤度は大まかにいえば、推定したモデルが観測データにどの程度当てはまっているかを表す。対数尤度は通常負の値をとるので-2をかけて比較することが多く、小さいほど当てはまりがよい。これはモデルの逸脱度と呼ばれる。 表3.4は各モデルの逸脱度(対数尤度の-2倍)を表したものである。表からわかるように、ワイブル回帰モデルが最も当てはまりが良いが、対数ロジスティックモデルやガンマ分布モデルとの差は大きくない。前述したように、アルモデルが別のモデルの特殊なケースであり、一方が他方の「入れ子構造」になっている場合は尤度比検定で適合度の検定を行うこともできる。 tibble(model = c(&quot;ガンマ分布&quot;, &quot;対数正規分布&quot;, &quot;対数ロジスティック分布&quot;, &quot;ワイブル回帰&quot;, &quot;ゴンぺルツ回帰&quot;, &quot;指数回帰&quot;), 逸脱度 = c(-2*mod_gam$loglik,-2*mod_lnorm$loglik[[2]], -2*mod_llog$loglik[[2]], -2*mod_wei$loglik[[2]], -2*mod_gom$loglik[[2]],-2*mod_exp$loglik[[2]])) %&gt;% kable(caption = &quot;各モデルの逸脱度&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.4: 各モデルの逸脱度 model 逸脱度 ガンマ分布 1360.011 対数正規分布 1366.469 対数ロジスティック分布 1359.877 ワイブル回帰 1359.833 ゴンぺルツ回帰 1362.279 指数回帰 1372.732 対数尤度を適合度の指標として用いる問題点は、推定するパラメータの数が多ければ多いほど対数尤度が高くなってしまうことである9。そこで、その特性を修正するためにパラメータ数による影響を取り除いたものがAIC(赤池情報量規準)やBIC(ベイズ情報量規準)である。なお、\\(L\\)はモデルの対数尤度を、\\(k\\)はパラメータ数を、\\(n\\)はデータ数を表す。\\(log(n)\\)は通常2より大きいので、BICのほうがよりパラメータの数の影響を強く修正している。これらいずれもは予測の良さを重視した指標で、いずれも小さいほど予測がいいことを表す。 \\[ \\begin{align} AIC &amp;= -2log(L) + 2k\\\\ BIC &amp;= -2log(L) +klog(n) \\end{align} \\] AICとBICは以下の自作関数で容易に求められる。 AICreg &lt;- function(mod, k = 2){ if(class(mod) == &quot;flexsurvreg&quot;){ loglik &lt;- mod_gam$loglik n_parameters &lt;- mod$npars AIC &lt;- -2*loglik + k*n_parameters }else{ loglik &lt;- mod$loglik[[2]] n_parameters &lt;- nrow(mod$var) AIC &lt;- -2*loglik + k*n_parameters } return(AIC) } BICreg &lt;- function(mod){ if(class(mod) == &quot;flexsurvreg&quot;){ loglik &lt;- mod_gam$loglik n_parameters &lt;- mod$npars N = nrow(mod$data$Y) BIC &lt;- -2*loglik + n_parameters*log(N) }else{ loglik &lt;- mod$loglik[[2]] n_parameters &lt;- nrow(mod$var) N = mod$n BIC &lt;- -2*loglik + n_parameters*log(N) } return(BIC) } 各モデルのAICとBICを記したのが表3.5である。いずれにおいても、ワイブル回帰モデルの適合度が最も高く、その次に対数ロジスティックモデルの適合度が高いことが分かる。 list_mod &lt;- list(mod_gam, mod_lnorm, mod_llog, mod_wei, mod_gom, mod_exp) tibble(model = c(&quot;ガンマ分布&quot;, &quot;対数正規分布&quot;, &quot;対数ロジスティック分布&quot;, &quot;ワイブル回帰&quot;, &quot;ゴンぺルツ回帰&quot;, &quot;指数回帰&quot;), AIC = map_dbl(list_mod, AICreg), BIC = map_dbl(list_mod, BICreg)) %&gt;% kable(caption = &quot;各モデルのAICとBIC&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.5: 各モデルのAICとBIC model AIC BIC ガンマ分布 1378.011 1414.627 対数正規分布 1384.469 1421.085 対数ロジスティック分布 1377.877 1414.493 ワイブル回帰 1377.833 1414.449 ゴンぺルツ回帰 1380.279 1416.895 指数回帰 1388.732 1421.279 両者のモデルから推定されるハザード率を再度図示すると以下のようになる。ワイブル回帰モデルはハザード率が単調増加なのに対し、対数ロジスティックモデルは途中まではハザード率が上昇するものの、その後低下していることが分かる。今回のデータの期間(52週)はハザード率が減少に転じるほど十分に長くはなかったため、ワイブル回帰モデルの方が適合度が高くなったのかもしれない。 as.ggplot(~plot(mod_wei, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;weibull&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_llog, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log logistic&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03))) 3.6 観察されない異質性の原因 個体のハザード率が期間を通して一定であっても、独立変数では説明しきれない個体間の異質性によって、時間とともにハザード率が減少する傾向があることが知られている。これは、一般的にハザード率が高い個体は早い段階で事象を経験してリスク集合から抜けていくため、時間が経過するにつれてハザード率の低い個体がリスク集合に残りやすい傾向があるためである。このとき、ハザード率が時間の減少と共に本当に減少しているのか、それとも個体の異質性によってハザード率が低下しているのかを区別するのは難しい10。このように、一般に時間がハザード率に与える影響を検討する際には十分な注意が必要である。 個体の異質性に対処する最も良い方法は、個体の異質性をもたらす要因を独立変数としてモデルに明示的に入れることである。しかし、こうした要因をすべて測定することは現実的ではない。この問題を解決するため、異質性の原因を誤差項に含めるパラメトリックなモデル(= frailty model)が提案されている。例えば、ランダムな誤差項を持つワイブル回帰モデルは以下のようにs定式化できる(式(3.9))。理論的には、これによって時間がハザード率に与える影響と、個体の異質性による影響を区別することができる。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + clog(t) + e \\tag{3.9} \\] 通常、誤差項\\(e\\)にどのような分布を仮定するかで偏回帰係数の推定値は大きく変わってしまう。一般に、以下の2つの場合を除いてこのモデルを用いることは推奨されない。 分析対象が繰り返し事象を経験する場合 分析対象をいくつかの大きなグループに分けることができ、同じグループに属するすべての個体の\\(e\\)が同じだと仮定できる場合。 3.7 なぜパラメトリックモデルを用いるのか 次章では最も一般的な手法であるコックス比例ハザードモデルを扱うが、パラメトリックモデルはコックス比例ハザードモデルよりも優れた特徴が二つある。ただし、多くのパッケージで時間依存の独立変数を扱うことができないという弱点もある。 「左側打ち切り」と「区間打ち切り」を扱うのが容易 左側打ち切り: すでに事象を経験したが、それがいつか分からない場合 区間打ち切り: 事象が二つの時点の間に発生したことはわかっているが、それがいつか正確にわからない場合 予測値の推定が優れている 次章の発生までの予想時間、事象発生までの時間の中央値や分位点、事象の確率分布などあらゆる推定が可能である。 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 指数分布が分からない方はこちら。↩︎ ゴンぺルツ分布が分からない方はこちら。↩︎ ワイブル分布が分からない方はこちら。↩︎ 自作関数はこちらのサイトを参考にした。↩︎ このあたりの説明やAICについては 久保 (2012) が分かりやすい。↩︎ 他方で、時間の経過とともにハザード率の上昇が観察されたなら、それはかなりの個体で実際にハザード率が時間とともに増加していると考えてよい。↩︎ "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] survminer_0.4.9 ggpubr_0.5.0 ggplotify_0.1.0 flextable_0.9.1 ## [5] flexsurv_2.2.2 eha_2.10.3 ggeffects_1.1.4 rstanarm_2.21.4 ## [9] brms_2.18.0 Rcpp_1.0.9 fontregisterer_0.3 systemfonts_1.0.4 ## [13] extrafont_0.18 lemon_0.4.6 ggsci_2.9 stargazer_5.2.3 ## [17] kableExtra_1.3.4 knitr_1.42 DT_0.27 patchwork_1.1.2 ## [21] data.table_1.14.6 see_0.7.5.5 report_0.5.7.4 parameters_0.20.3 ## [25] performance_0.10.3 modelbased_0.8.6.3 insight_0.19.1.4 effectsize_0.8.3.6 ## [29] datawizard_0.7.1.1 correlation_0.8.4 bayestestR_0.13.1 easystats_0.6.0.8 ## [33] haven_2.5.1 forcats_0.5.2 stringr_1.5.0 dplyr_1.0.10 ## [37] purrr_1.0.0 readr_2.1.3 tidyr_1.2.1 tibble_3.1.8 ## [41] tidyverse_1.3.2 ggplot2_3.4.2 ggsurvfit_0.3.0 survival_3.5-5 ## ## loaded via a namespace (and not attached): ## [1] utf8_1.2.2 tidyselect_1.2.0 lme4_1.1-31 ## [4] htmlwidgets_1.6.1 grid_4.2.2 munsell_0.5.0 ## [7] ragg_1.2.4 codetools_0.2-18 statmod_1.5.0 ## [10] miniUI_0.1.1.1 withr_2.5.0 Brobdingnag_1.2-9 ## [13] colorspace_2.0-3 muhaz_1.2.6.4 highr_0.10 ## [16] uuid_1.1-0 rstudioapi_0.14 stats4_4.2.2 ## [19] ggsignif_0.6.4 officer_0.6.2 Rttf2pt1_1.3.8 ## [22] fontLiberation_0.1.0 bayesplot_1.10.0 labeling_0.4.2 ## [25] emmeans_1.8.3 rstan_2.26.13 KMsurv_0.1-5 ## [28] farver_2.1.1 bridgesampling_1.1-2 coda_0.19-4 ## [31] vctrs_0.5.1 generics_0.1.3 xfun_0.36 ## [34] timechange_0.1.1 fontquiver_0.2.1 R6_2.5.1 ## [37] markdown_1.4 gridGraphics_0.5-1 cachem_1.0.6 ## [40] assertthat_0.2.1 promises_1.2.0.1 scales_1.2.1 ## [43] googlesheets4_1.0.1 gtable_0.3.3 processx_3.8.0 ## [46] rlang_1.1.1 splines_4.2.2 rstatix_0.7.1 ## [49] extrafontdb_1.0 gargle_1.2.1 broom_1.0.2 ## [52] checkmate_2.1.0 inline_0.3.19 yaml_2.3.7 ## [55] reshape2_1.4.4 abind_1.4-5 modelr_0.1.10 ## [58] threejs_0.3.3 crosstalk_1.2.0 backports_1.4.1 ## [61] httpuv_1.6.7 tensorA_0.36.2 tools_4.2.2 ## [64] bookdown_0.31 ellipsis_0.3.2 jquerylib_0.1.4 ## [67] posterior_1.3.1 plyr_1.8.8 base64enc_0.1-3 ## [70] ps_1.7.2 prettyunits_1.1.1 openssl_2.0.5 ## [73] deSolve_1.34 zoo_1.8-11 fs_1.5.2 ## [76] crul_1.3 magrittr_2.0.3 colourpicker_1.2.0 ## [79] reprex_2.0.2 googledrive_2.0.0 mvtnorm_1.1-3 ## [82] matrixStats_0.63.0 hms_1.1.2 shinyjs_2.1.0 ## [85] mime_0.12 evaluate_0.20 xtable_1.8-4 ## [88] shinystan_2.6.0 readxl_1.4.1 gridExtra_2.3 ## [91] rstantools_2.2.0 compiler_4.2.2 fontBitstreamVera_0.1.1 ## [94] V8_4.2.2 crayon_1.5.2 minqa_1.2.5 ## [97] StanHeaders_2.26.13 htmltools_0.5.4 later_1.3.0 ## [100] tzdb_0.3.0 RcppParallel_5.1.6 lubridate_1.9.0 ## [103] DBI_1.1.3 dbplyr_2.2.1 MASS_7.3-58.1 ## [106] boot_1.3-28 car_3.1-1 Matrix_1.5-1 ## [109] cli_3.6.0 quadprog_1.5-8 parallel_4.2.2 ## [112] igraph_1.3.5 km.ci_0.5-6 pkgconfig_2.0.3 ## [115] numDeriv_2016.8-1.1 xml2_1.3.3 dygraphs_1.1.1.6 ## [118] svglite_2.1.1 bslib_0.4.2 webshot_0.5.4 ## [121] estimability_1.4.1 rvest_1.0.3 yulab.utils_0.0.6 ## [124] distributional_0.3.1 callr_3.7.3 digest_0.6.31 ## [127] httpcode_0.3.0 rmarkdown_2.20 cellranger_1.1.0 ## [130] survMisc_0.5.6 gdtools_0.3.3 curl_4.3.3 ## [133] shiny_1.7.4 gtools_3.9.4 nloptr_2.0.3 ## [136] lifecycle_1.0.3 nlme_3.1-160 jsonlite_1.8.4 ## [139] mstate_0.3.2 carData_3.0-5 askpass_1.1 ## [142] viridisLite_0.4.1 fansi_1.0.3 pillar_1.9.0 ## [145] lattice_0.20-45 loo_2.5.1 fastmap_1.1.0 ## [148] httr_1.4.4 pkgbuild_1.4.0 glue_1.6.2 ## [151] xts_0.12.2 zip_2.2.2 shinythemes_1.2.0 ## [154] stringi_1.7.8 sass_0.4.5 textshaping_0.3.6 ## [157] gfonts_0.2.0 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Ellis, S., Snyder-Mackler, N., Ruiz-Lambides, A., Platt, M. L., &amp; Brent, L. J. N. (2019). Deconstructing sociality: The types of social connections that predict longevity in a group-living primate. Proc. Biol. Sci., 286(1917), 20191991. Kurz, A. S. (2021). Applied longitudinal data analysis in brms and the tidyverse (version 0.0.2). https://bookdown.org/content/4253/ Rossi, P. H., Berk, R. A., &amp; Lenihan, K. J. (1980). Money, work and crime: Some experimental results. New York: Academic Press. Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C., Engh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth, R. M., &amp; Cheney, D. L. (2010). Strong and consistent social bonds enhance the longevity of female baboons. Curr. Biol., 20(15), 1359–1361. Swedell, L., Saunders, J., Schreier, A., Davis, B., Tesfaye, T., &amp; Pines, M. (2011). Female “dispersal” in hamadryas baboons: Transfer among social units in a multilevel society. Am. J. Phys. Anthropol., 145(3), 360–370. Thompson, N. A., &amp; Cords, M. (2018). Stronger social bonds do not always predict greater longevity in a gregarious primate. Ecol. Evol., 8(3), 1604–1614. Tung, J., Archie, E. A., Altmann, J., &amp; Alberts, S. C. (2016). Cumulative early life adversity predicts longevity in wild baboons. Nat. Commun., 7. Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 大橋靖雄., 浜田知久馬., &amp; 魚住龍史. (2021). 生存時間解析 第2版 SASによる生物統計. 東京大学出版. 杉本知之. (2021). 生存時間解析. 朝倉書店. 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. 粕谷英一. (2012). 一般化線形モデル. 共立出版. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
