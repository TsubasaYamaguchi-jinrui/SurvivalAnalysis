[["index.html", "Event History and Survival Analysis Using R 本稿の目的", " Event History and Survival Analysis Using R Tsubasa Yamaguchi 2023-05-30 本稿の目的 本稿はイベント・ヒストリー分析(event history analysis)または生存時間分析（Survival Analysis）と呼ばれる手法の概要をまとめたものである。また、Rでこうした分析を実行する方法についても解説している。新たに個人的に勉強した内容があれば、随時追加していく。 本稿が主に参考にしたのは参考にしたのは Allison (2014) の”Event History and Survival Analysis, Second Edition”である。 本稿の作成に使用したファイルとRのコードは筆者のGithubですべて閲覧できる。 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 本稿では、 ## 生存時間分析 library(survival) library(ggsurvfit) ## データハンドリング library(tidyverse) library(haven) library(easystats) library(data.table) ## グラフや表関連 library(patchwork) library(DT) library(knitr) library(kableExtra) library(stargazer) library(ggsci) library(lemon) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) なお、本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham &amp; Grolemund, 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang, 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al., 2021) 出版社サイト References Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. "],["Chapter1.html", "1 はじめに 1.1 イベントヒストリー分析とは何か 1.2 イベント・ヒストリー分析の難しさ 1.3 イベント・ヒストリー分析の種類", " 1 はじめに 1.1 イベントヒストリー分析とは何か イベント・ヒストリーとは、研究対象である「個体や集団で、ある事象が生じた時間的な記録」を意味する。霊長類学では、個体が何歳で死亡したかや、オスが何年群れに在籍したかといったデータがこれに該当する。イベント・ヒストリー分析(event history analysis)または生存時間分析(survival analysis)1は、イベント・ヒステリーを持つデータを用いて、事象の発生パターンや発生の原因を分析する一連の手法である。例えば霊長類の研究では、個体の寿命に影響する要因を調べたり(Ellis et al., 2019; Silk et al., 2010; Thompson &amp; Cords, 2018; Tung et al., 2016)、オスが群れに在籍する確率が時間と共にどう変化するのかを調べたりする(Swedell et al., 2011)ために用いられている。 1.2 イベント・ヒストリー分析の難しさ イベント・ヒストリーを持つデータの分析が難しい要因としては、扱うデータに以下の2つの特殊性があることが多いことが挙げられる。イベント・ヒストリー分析では、これらの困難に対処するため様々な手法が研究されてきた。 1.2.1 打ち切り イベント・ヒステリーを持つデータの特殊性の一つは、打ち切りが存在する点である。 具体例として、 Rossi et al. (1980) のデータを見ていこう。この研究では、432名の服役囚が出所後12ヶ月間に再逮捕されるかどうかを調べ、それに年齢や人種、学歴、配偶状態などの要因が影響しているかを調べようとしている。変数の詳細は、こちらを参照。 Rossi &lt;- read_csv(&quot;data/Rossi.csv&quot;) Rossi %&gt;% head(20) %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 実際にデータからランダムに抽出した20人が再逮捕されたかどうかを見ていこう(図1.1)。arrestは再逮捕されたかどうかを0/1で、weekは再逮捕された場合出所後何週間目だったかを表している。図からわかるように、12ヶ月(52週)経過後も逮捕されていないデータが数多く存在することが分かる。 Rossi %&gt;% sample_n(20) %&gt;% mutate(id = row_number()) %&gt;% mutate(arrest = as.factor(arrest)) %&gt;% ggplot(aes(x = week, y = id))+ geom_segment(aes(x = 0, xend = week, yend = id, y = id), color = &quot;grey&quot;)+ geom_point(shape = 23, size = 3, aes(fill = arrest))+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1) 図1.1: 服役囚が出所後何週間で逮捕されたか このようなデータは、通常の分析ではデータを扱うのが難しい。なぜなら、再逮捕されなかった服役囚に適切に従属変数2を割り当てることができないからである。彼らは10年たっても再逮捕されなかったかもしれないし、出所後13ヶ月に再逮捕されていたかもしれないが、このデータから知ることは不可能である。彼らに一律に同じ値を割り振っても（例えば期間の最大値である1年を割り振る）、彼らのデータを除外してもデータに大きなバイアスがかかってしまう。 このように、測定値が不完全にしかわからないデータを打ち切りデータという。打ち切りには、上記のように(1)調査終了時点ではまだイベントが起きていない場合と、(2)何らかの事情(e.g., 予期せぬ死、消息不明など)で調査期間の途中でその個体のデータが追跡できなくなっている場合(= 脱落)の2種類が存在する。 1.2.2 時間依存共変量 もう一つの特殊性は、対象の期間中に独立変数の値が変化する場合があることである（＝時間依存共変量）。 例えば、先ほどの例でも対象の12ヶ月の間に仕事の有無が変化していた(emp1~emp52)。こうした場合、回帰モデルに1ヶ月ごとの仕事の有無（e.g., 1ヶ月目の仕事の有無、2ヶ月目の仕事の有無、…）をすべて独立変数として入れることはできるが、この方法では出所後12ヶ月以内に再逮捕された服役囚に対して独立変数を割り振れないところが出てくる。なぜなら、出所後3ヶ月で再逮捕されたとすると、その服役囚の4ヶ月目以降の仕事のデータはないからである。 1.3 イベント・ヒストリー分析の種類 イベント・ヒストリー分析の手法は以下のような点を基準に分類される。本稿では、まず単純なモデルの説明から始め、徐々に難しいモデルの説明へ移る。 1.3.1 繰り返しの有無 生物学で扱うことの多い「死」という事象は一個体に一度しか生じないが、転職や結婚といった事象を扱う場合、これらは個人の一生において何度も発生する可能性がある。繰り返しの阿辻賞を扱う際にはより複雑な分析モデルが必要になる。 1.3.2 単一の事象と複数の事象 例えば生物の生死を扱うとき、多くの場合では死亡のタイプ（e.g., 死因など）を区別せず単一の死亡として扱う。しかし、死亡のタイプを分けて分析を行うことも可能である。このような複数の事象を扱うためには、単一な事象を扱う分析よりも複雑なモデルが必要である。 1.3.3 パラメトリック法とノンパラメトリック法 分析には、事象の発生時間の分布（どのような時間間隔で事象が発生するか）に仮定を置かないノンパラメトリックな分析と、特定の分布族（e.g., 指数分布、ワイブル分布など）を仮定するパラメトリックな分析がある。また、これら2つを結合したCoxの比例ハザードモデルは事象の発生時間に特定の分布を仮定しないが、線形関数に基づく回帰モデルであるというという点でセミパラメトリックな手法であるといえる。 1.3.4 離散時間と連続時間 事象の発生時間が正確に記録できている場合は「連続時間」モデルといわれる。通常は、時間の測定単位が小さい場合は（時間、分、秒）、連続時間として扱ってよい。一方、時間の測定単位が大きい場合（月、年）は「離散時間」モデルで扱うのが適している。実際の分析では離散時間モデルの方が理解するのが容易である。 References Ellis, S., Snyder-Mackler, N., Ruiz-Lambides, A., Platt, M. L., &amp; Brent, L. J. N. (2019). Deconstructing sociality: The types of social connections that predict longevity in a group-living primate. Proc. Biol. Sci., 286(1917), 20191991. Rossi, P. H., Berk, R. A., &amp; Lenihan, K. J. (1980). Money, work and crime: Some experimental results. New York: Academic Press. Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C., Engh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth, R. M., &amp; Cheney, D. L. (2010). Strong and consistent social bonds enhance the longevity of female baboons. Curr. Biol., 20(15), 1359–1361. Swedell, L., Saunders, J., Schreier, A., Davis, B., Tesfaye, T., &amp; Pines, M. (2011). Female “dispersal” in hamadryas baboons: Transfer among social units in a multilevel society. Am. J. Phys. Anthropol., 145(3), 360–370. Thompson, N. A., &amp; Cords, M. (2018). Stronger social bonds do not always predict greater longevity in a gregarious primate. Ecol. Evol., 8(3), 1604–1614. Tung, J., Archie, E. A., Altmann, J., &amp; Alberts, S. C. (2016). Cumulative early life adversity predicts longevity in wild baboons. Nat. Commun., 7. このような分析手法は様々な分野で発展してきたため、分野ごとに呼ばれ方が異なる。例えば生物学では動物の寿命を扱うことが多いため「生存時間分析」、工学の分野では機械の故障を扱うことが多いため「故障時間分析」などと呼ばれる。「イベント・ヒストリー分析」という呼び方は、こうした様々な分野で発展した分析手法の包括的な呼称である。↩︎ 従属変数、独立変数がわからない場合はこちらを参照。↩︎ "],["Chapter2.html", "2 離散時間モデル 2.1 離散時間モデルの例 2.2 離散時間ハザード 2.3 ロジスティック回帰モデル 2.4 モデルの推定 2.5 Rでの実装 2.6 尤度比検定 2.7 離散時間ロジスティック回帰モデルの注意点 2.8 打ち切りデータの扱い", " 2 離散時間モデル 本章では、繰り返しのない単一の事象を離散時間モデルで分析する方法を概観する。 2.1 離散時間モデルの例 ここでは具体例として、1950年代後半から60年代前半に博士号を取得した生化学者301人(助教として勤務経験あり)が准教授に昇進するのに要する年数を記録したデータを使用する。データはdataフォルダにある(rank.dta)。dta形式のファイルは、havenパッケージのread_dta()で読み込める。 library(haven) rank &lt;- read_dta(&quot;data/rank.dta&quot;) データの先頭10行を取り出すと以下のようになっている。変数の説明は以下の通り。 ここでは、独立変数を用いて1年ごとの昇進の条件付き確率を回帰モデルを用いて推定することを目的とする。 従属変数にかかわる変数 - dur: 助教としての勤続年数 - promo: 助教への昇進の有無 独立変数(非時間依存変数) undgrad: 対象者の出身学部の選抜の厳しさの尺度 phdprest: 博士号を取得した大学の威信の尺度 phdmed: 医学博士の有無 独立変数(時間依存変数) prest: 勤務している大学の威信の尺度 arts: 勤続年数ごとの累積発表論文数 cits: 勤続年数ごとの論文の累積被引用回数 そのほか jobtime: 職場を変わった場合、何年目に変わったか rank %&gt;% head(10) %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 准教授への昇進時期の分布は以下のようになる(表2.1)。なお、リスク集合(risk set)とは、各時点で事象を経験する可能性のある個体の集まり、ハザード率(hazard rate)とは、ある時点でリスク集合に入っている個体がその時点で事象を経験する条件付き確率である(i.e., この表では昇進人数/リスク集合の大きさ)。 打ち切りは、25人については10年たっても准教授に昇進できていないために生じているが、それ以外については大学を離れたために生じている。 rank %&gt;% group_by(dur) %&gt;% summarise(昇進人数 = sum(promo), 打ち切り数 = sum(promo == &quot;0&quot;)) %&gt;% rename(勤続年数 = dur) %&gt;% ungroup() -&gt; hyou1 hyou1 %&gt;% mutate(勤続年数 = 勤続年数+1) %&gt;% mutate(N = 昇進人数 + 打ち切り数) %&gt;% mutate(sum = cumsum(N)) -&gt; hyou1_b hyou1 %&gt;% left_join(hyou1_b %&gt;% select(勤続年数, sum)) %&gt;% replace_na(list(sum = 0)) %&gt;% mutate(リスク集合の大きさ = sum(昇進人数 + 打ち切り数) - sum) %&gt;% select(-sum) %&gt;% mutate(推定されたハザード率 = 昇進人数/リスク集合の大きさ) %&gt;% kable(align = &quot;c&quot;, caption = &quot;准教授への昇進時期の分布&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.1: 准教授への昇進時期の分布 勤続年数 昇進人数 打ち切り数 リスク集合の大きさ 推定されたハザード率 1 1 1 301 0.0033223 2 1 6 299 0.0033445 3 17 12 292 0.0582192 4 42 10 263 0.1596958 5 53 9 211 0.2511848 6 46 7 149 0.3087248 7 31 6 96 0.3229167 8 15 2 59 0.2542373 9 7 6 42 0.1666667 10 4 25 29 0.1379310 2.2 離散時間ハザード イベント・ヒストリー分析では、上でも説明した「リスク集合」と「ハザード率」の二つが重要な概念である。分析ではハザード率を従属変数として、それぞれの独立変数がハザード率に与える影響を分析していく。 2.3 ロジスティック回帰モデル 離散時間モデルでは、ロジット変換3を利用することでハザード関数\\(P(t)\\)を以下のようにあらわす。なお、\\(x_1\\)は非時間依存変数を、\\(x_2(t)\\)は時間依存変数を表す。また、\\(t\\)は勤続年数を表す。\\(b_1\\)と\\(b_2\\)は偏回帰係数と呼ぶ。ロジット変換を施すことで、右辺がどのような値も取っても\\(P(t)\\)が0から1の範囲に収まる。 \\[ \\begin{equation} log\\biggl(\\frac{P(t)}{1-P(t)}\\biggl) = b_0 + b_1x_1 + b_2x_2(t) + b_3t + b_4t^2 \\tag{2.1} \\end{equation} \\] 2.4 モデルの推定 次に、データを基にパラメータ(\\(b_1から b_4\\))を推定する。推定は基本的に最尤法を用いて行う。これは、実際に観察された値が得られる確率が最大になるようにパラメータを推定する方法である。 実際の推定手順は以下のようになる。 各個体がリスク集合に入っている期間をある時間単位で分け(今回は1年)、その1単位ごと(= 人年ごと)に事象の発生を記録していく。 各個体は各単位ごとに(この場合は1年ごとに)昇進した場合は従属変数に1を、してない場合は0を割り当てられる。 データセットを作成し、最尤法を用いてロジスティック回帰モデルのパラメータを推定する。 2.5 Rでの実装 2.5.1 データの加工 それでは、Rで実際にモデルのパラメータを推定してみる。分析をするためには、データフレームを縦長にする必要がある。具体的には、発表論文数(art1art10)と被引用数(cit1cit10)をそれぞれ一列にする必要がある。 rank %&gt;% ## 個体IDの列を作成 rowid_to_column(var = &quot;id&quot;) %&gt;% ## 勤続年数ごとの論文数を一列に pivot_longer(cols = art1:art10, names_to = &quot;art&quot;, values_to = &quot;art_n&quot;) %&gt;% ## 欠損値を除く filter(!is.na(art_n)) %&gt;% arrange(id) %&gt;% ## 行番号を作る rowid_to_column(&quot;rowid&quot;) %&gt;% select(-(cit1:cit10), -art) -&gt; rank2 rank %&gt;% ## 個体IDの列を作成 rowid_to_column(var = &quot;id&quot;) %&gt;% ## 勤続年数ごとの引用数を一列に pivot_longer(cols = cit1:cit10, names_to = &quot;cit&quot;, values_to = &quot;cit_n&quot;) %&gt;% ## 欠損値を除く filter(!is.na(cit_n)) %&gt;% arrange(id) %&gt;% ## 行番号を作る rowid_to_column(&quot;rowid&quot;) %&gt;% select(cit_n, rowid) -&gt; rank3 ## 結合 rank2 %&gt;% inner_join(rank3, by = &quot;rowid&quot;) %&gt;% arrange(id) %&gt;% group_by(id) %&gt;% ## 個体ごとに勤続年数の列を作成 mutate(year = row_number()) %&gt;% ## 変数promoが昇進のあった年のみ1をとるようにする ungroup() %&gt;% mutate(promo = ifelse(year &lt; dur,0,promo)) %&gt;% ## jobtimeの欠損値を0に replace_na(list(jobtime = 0)) %&gt;% ## 大学威信度の列を作成 mutate(jobpres = ifelse(year &lt; jobtime, prest1, prest2)) %&gt;% select(-prest1, -prest2)-&gt; rank4 できたデータシートは以下の通り。 datatable(rank4, options = list(scrollX = 100), rownames = FALSE) 2.5.2 分析 それでは、実際に分析する。分析には一般化線形モデルによる分析ができるglm()関数を用いる。 まずは1つ目のモデルとして、勤続年数を入れない線形モデルを考えてみる。 mod1 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n, data = rank4, family = binomial(link = &quot;logit&quot;)) 結果は以下の通り(表2.2)。 model_parameters(mod1) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod1の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.2: mod1の結果 Parameter Coefficient 95%CI SE z p (Intercept) -2.9636747 [-3.80, -2.15} 0.4210727 -7.0383926 0.0000000 undgrad 0.1802769 [0.06, 0.30} 0.0607534 2.9673535 0.0030038 phdmed -0.2650547 [-0.58, 0.05} 0.1614778 -1.6414308 0.1007080 phdprest -0.0029980 [-0.18, 0.17} 0.0886335 -0.0338249 0.9730168 jobpres -0.2535299 [-0.46, -0.05} 0.1054517 -2.4042272 0.0162067 art_n 0.1270934 [0.10, 0.16} 0.0165769 7.6669053 0.0000000 cit_n -0.0014547 [-0.00, 0.00} 0.0012590 -1.1554230 0.2479173 2つ目のモデルとして、勤続年数とその二乗を説明変数に入れたモデルを考える。 mod2 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + year + I(year^2), data = rank4, family = &quot;binomial&quot;) 結果は以下の通り(表2.3)。 model_parameters(mod2) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod2の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.3: mod2の結果 Parameter Coefficient 95%CI SE z p (Intercept) -8.4846678 [-10.07, -7.02} 0.7756586 -10.9386630 0.0000000 undgrad 0.1939331 [0.07, 0.32} 0.0635127 3.0534551 0.0022622 phdmed -0.2356943 [-0.57, 0.10} 0.1717631 -1.3722061 0.1699993 phdprest 0.0270565 [-0.16, 0.21} 0.0931669 0.2904086 0.7715036 jobpres -0.2535406 [-0.48, -0.03} 0.1138113 -2.2277268 0.0258987 art_n 0.0733840 [0.04, 0.11} 0.0181374 4.0459977 0.0000521 cit_n 0.0001255 [-0.00, 0.00} 0.0013125 0.0956291 0.9238152 year 2.0818890 [1.65, 2.56} 0.2337665 8.9058484 0.0000000 I(year^2) -0.1585829 [-0.20, -0.12} 0.0203027 -7.8109434 0.0000000 2つのモデルを比較すると以下の通り。 stargazer(mod1, mod2, type = &quot;text&quot;) ## ## ============================================== ## Dependent variable: ## ---------------------------- ## promo ## (1) (2) ## ---------------------------------------------- ## undgrad 0.180*** 0.194*** ## (0.061) (0.064) ## ## phdmed -0.265 -0.236 ## (0.161) (0.172) ## ## phdprest -0.003 0.027 ## (0.089) (0.093) ## ## jobpres -0.254** -0.254** ## (0.105) (0.114) ## ## art_n 0.127*** 0.073*** ## (0.017) (0.018) ## ## cit_n -0.001 0.0001 ## (0.001) (0.001) ## ## year 2.082*** ## (0.234) ## ## I(year2) -0.159*** ## (0.020) ## ## Constant -2.964*** -8.485*** ## (0.421) (0.776) ## ## ---------------------------------------------- ## Observations 1,741 1,741 ## Log Likelihood -595.566 -506.013 ## Akaike Inf. Crit. 1,205.132 1,030.025 ## ============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 2.5.3 結果の解釈 モデル1(mod1)では(表2.2)、3つの独立変数が有意に准教授への昇進のハザード率に影響していることが分かる(undgrad、jobpres、art_n)。具体的には、より選抜度合いの高い大学を卒業した生化学者とより多くの論文を発表した生化学者はハザード率が高い。一方で、より威信度の高い大学で現在働いている生化学者ほどハザード率は低い。 各変数が1増加したときに、准教授に昇進するオッズ比(\\(\\frac{P(t)}{1-P(t)}\\))がどの程度増加するかを計算すると(これは、\\(e^{偏回帰係数}\\)で求まる。式(2.1)を参照)、以下のようになる。すなわち、「学部選抜度(undgrad)」が1増えるとオッズ比が約1.2倍に、「累積論文発表数(art_n)」が1増えるとオッズ比が約1.14倍になる。一方、「勤務先の大学の威信度(jobpres)」が1増加すると、オッズ比は0.78倍に減少する。 model_parameters(mod1) %&gt;% data.frame() %&gt;% select(Parameter, Coefficient) %&gt;% mutate(odds = exp(Coefficient)) ## Parameter Coefficient odds ## 1 (Intercept) -2.963674661 0.05162885 ## 2 undgrad 0.180276920 1.19754894 ## 3 phdmed -0.265054700 0.76716399 ## 4 phdprest -0.002998022 0.99700647 ## 5 jobpres -0.253529874 0.77605656 ## 6 art_n 0.127093447 1.13552312 ## 7 cit_n -0.001454692 0.99854637 モデル2も結果自体は大きく変わらないが、勤続年数とその二乗が有意に影響していることが分かる。また、「累積論文発表数(art_n)」の偏回帰係数が大幅に小さくなっており、オッズ比も1.14倍から1.08倍に減少している。 model_parameters(mod2) %&gt;% data.frame() %&gt;% select(Parameter, Coefficient) %&gt;% mutate(odds = exp(Coefficient)) ## Parameter Coefficient odds ## 1 (Intercept) -8.4846678008 0.000206612 ## 2 undgrad 0.1939331150 1.214015081 ## 3 phdmed -0.2356943107 0.790022138 ## 4 phdprest 0.0270564703 1.027425820 ## 5 jobpres -0.2535405982 0.776048238 ## 6 art_n 0.0733840049 1.076143702 ## 7 cit_n 0.0001255168 1.000125525 ## 8 year 2.0818890246 8.019603843 ## 9 I(year^2) -0.1585829127 0.853352207 2.6 尤度比検定 あるモデルが別のモデルの「入れ子」構造(一方のモデルが他方のモデルの独立変数をすべて含む)であるとき、尤度比検定によってどちらの方が適合度が高いか検定を行うことができる。2つのモデルの対数尤度の差の2倍が\\(\\chi^2\\)分布に近似できることを利用して帰無仮説検定を行うことが多い4。 Rでは以下のように行う。結果を見ると、モデル2の方が有意に適合度が高いことが分かる。 このような検定は、本稿で以後出てくるモデルやパラメータの検定にも応用可能である。 anova(mod1,mod2, test = &quot;Chisq&quot;) ## Analysis of Deviance Table ## ## Model 1: promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n ## Model 2: promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + ## year + I(year^2) ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 1734 1191.1 ## 2 1732 1012.0 2 179.11 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.7 離散時間ロジスティック回帰モデルの注意点 上記のモデルにはいくつか注意点がある。 1.一個体が複数の事象を経験する場合は、事象の回数の影響を修正する必要がある。 ロバスト推定による標準誤差を求めたり、一般化推定式やランダム(変量)効果モデルを用いたりする。 区切る時間単位を適切に設定する必要がある。 今回は、准教授の昇進が各年度の初めに行われるため、1年ごとにデータを区切ることは適切であった。これを1日ごとに区切るとデータが膨大になってしまうし、５年ごとに区切ると多くの情報が失われてしまう。分析対象の事象に応じて、適切に区切る時間単位を適切に設定する必要がある。 代替手法 式(2.1)は独立変数のハザード率に対する影響を検討する最も知られた方法だが、以下の「補対数対数モデル」も代替手法として有用である。このモデルでも、右辺がどのような値をとろうと\\(P(t)\\)は0から1に収まる。 \\[ \\begin{equation} log[-log(1-P(t))] = b_0 + b_1x_1 + b_2x_2(t) + b_3t + b_4t^2 \\tag{2.2} \\end{equation} \\] Rでは、以下のように実装できる。 mod3 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + year + I(year^2), data = rank4, family = binomial(link = &quot;cloglog&quot;)) 結果は以下の通り(2.4)。ロジスティック回帰モデルと結果は大きく変わらない。特にP地だけに着目する場合はどちらのモデルを選んでも決定的な差はない。 model_parameters(mod3) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod3の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.4: mod3の結果 Parameter Coefficient 95%CI SE z p (Intercept) -7.9961202 [-9.40, -6.69} 0.6943534 -11.5159220 0.0000000 undgrad 0.1694896 [0.06, 0.28} 0.0548959 3.0874751 0.0020186 phdmed -0.2153786 [-0.50, 0.08} 0.1469985 -1.4651751 0.1428732 phdprest 0.0100102 [-0.15, 0.17} 0.0806278 0.1241530 0.9011941 jobpres -0.1934044 [-0.38, -0.01} 0.0967829 -1.9983313 0.0456808 art_n 0.0623539 [0.03, 0.09} 0.0142864 4.3645723 0.0000127 cit_n -0.0004238 [-0.00, 0.00} 0.0010398 -0.4075788 0.6835830 year 1.9223437 [1.53, 2.36} 0.2128381 9.0319539 0.0000000 I(year^2) -0.1469834 [-0.19, -0.11} 0.0184860 -7.9510496 0.0000000 2.8 打ち切りデータの扱い References 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 粕谷英一. (2012). 一般化線形モデル. 共立出版. ロジット変換がわからない方はこちら。 ↩︎ 尤度比検定の詳細については、 粕谷 (2012) や 久保 (2012) を参照。パラメトリックブーストラップ法を用いたより正確な検定を行うこともできる(久保, 2012)。↩︎ "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] fontregisterer_0.3 systemfonts_1.0.4 extrafont_0.18 lemon_0.4.6 ## [5] ggsci_2.9 stargazer_5.2.3 kableExtra_1.3.4 knitr_1.42 ## [9] DT_0.27 patchwork_1.1.2 data.table_1.14.6 see_0.7.5.5 ## [13] report_0.5.7.4 parameters_0.20.3 performance_0.10.3 modelbased_0.8.6.3 ## [17] insight_0.19.1.4 effectsize_0.8.3.6 datawizard_0.7.1.1 correlation_0.8.4 ## [21] bayestestR_0.13.1 easystats_0.6.0.8 haven_2.5.1 forcats_0.5.2 ## [25] stringr_1.5.0 dplyr_1.0.10 purrr_1.0.0 readr_2.1.3 ## [29] tidyr_1.2.1 tibble_3.1.8 tidyverse_1.3.2 ggplot2_3.4.2 ## [33] ggsurvfit_0.3.0 survival_3.5-5 ## ## loaded via a namespace (and not attached): ## [1] fs_1.5.2 lubridate_1.9.0 webshot_0.5.4 ## [4] httr_1.4.4 tools_4.2.2 backports_1.4.1 ## [7] bslib_0.4.2 utf8_1.2.2 R6_2.5.1 ## [10] DBI_1.1.3 colorspace_2.0-3 withr_2.5.0 ## [13] gridExtra_2.3 tidyselect_1.2.0 emmeans_1.8.3 ## [16] extrafontdb_1.0 compiler_4.2.2 cli_3.6.0 ## [19] rvest_1.0.3 xml2_1.3.3 bookdown_0.31 ## [22] sass_0.4.5 scales_1.2.1 mvtnorm_1.1-3 ## [25] digest_0.6.31 svglite_2.1.1 rmarkdown_2.20 ## [28] pkgconfig_2.0.3 htmltools_0.5.4 highr_0.10 ## [31] dbplyr_2.2.1 fastmap_1.1.0 htmlwidgets_1.6.1 ## [34] rlang_1.1.1 readxl_1.4.1 rstudioapi_0.14 ## [37] jquerylib_0.1.4 generics_0.1.3 jsonlite_1.8.4 ## [40] googlesheets4_1.0.1 magrittr_2.0.3 Matrix_1.5-1 ## [43] Rcpp_1.0.9 munsell_0.5.0 fansi_1.0.3 ## [46] lifecycle_1.0.3 stringi_1.7.8 yaml_2.3.7 ## [49] MASS_7.3-58.1 plyr_1.8.8 grid_4.2.2 ## [52] crayon_1.5.2 lattice_0.20-45 splines_4.2.2 ## [55] hms_1.1.2 pillar_1.9.0 estimability_1.4.1 ## [58] codetools_0.2-18 reprex_2.0.2 glue_1.6.2 ## [61] evaluate_0.20 modelr_0.1.10 vctrs_0.5.1 ## [64] tzdb_0.3.0 Rttf2pt1_1.3.8 cellranger_1.1.0 ## [67] gtable_0.3.3 assertthat_0.2.1 cachem_1.0.6 ## [70] xfun_0.36 xtable_1.8-4 broom_1.0.2 ## [73] coda_0.19-4 viridisLite_0.4.1 googledrive_2.0.0 ## [76] gargle_1.2.1 timechange_0.1.1 ellipsis_0.3.2 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Ellis, S., Snyder-Mackler, N., Ruiz-Lambides, A., Platt, M. L., &amp; Brent, L. J. N. (2019). Deconstructing sociality: The types of social connections that predict longevity in a group-living primate. Proc. Biol. Sci., 286(1917), 20191991. Rossi, P. H., Berk, R. A., &amp; Lenihan, K. J. (1980). Money, work and crime: Some experimental results. New York: Academic Press. Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C., Engh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth, R. M., &amp; Cheney, D. L. (2010). Strong and consistent social bonds enhance the longevity of female baboons. Curr. Biol., 20(15), 1359–1361. Swedell, L., Saunders, J., Schreier, A., Davis, B., Tesfaye, T., &amp; Pines, M. (2011). Female “dispersal” in hamadryas baboons: Transfer among social units in a multilevel society. Am. J. Phys. Anthropol., 145(3), 360–370. Thompson, N. A., &amp; Cords, M. (2018). Stronger social bonds do not always predict greater longevity in a gregarious primate. Ecol. Evol., 8(3), 1604–1614. Tung, J., Archie, E. A., Altmann, J., &amp; Alberts, S. C. (2016). Cumulative early life adversity predicts longevity in wild baboons. Nat. Commun., 7. Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. 粕谷英一. (2012). 一般化線形モデル. 共立出版. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
