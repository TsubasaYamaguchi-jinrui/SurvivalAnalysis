[["index.html", "Event History and Survival Analysis Using R 本稿の目的", " Event History and Survival Analysis Using R Tsubasa Yamaguchi 2023-06-05 本稿の目的 本稿はイベント・ヒストリー分析(event history analysis)または生存時間分析（Survival Analysis）と呼ばれる手法の概要をまとめたものである。また、Rでこうした分析を実行する方法についても解説している。新たに個人的に勉強した内容があれば、随時追加していく。 本稿が主に参考にしたのは参考にしたのは Allison (2014) の”Event History and Survival Analysis, Second Edition”である。 また以下の書籍やサイトも参考にした。 杉本 (2021) 生存時間解析. 朝倉書店 大橋 et al. (2021) 生存時間解析 第2版 SASによる生物統計. 東京大学出版 Broström (2021) Event History Analysis with R, Second Edition Survival Analysis in R 疫学のためのRハンドブック Prediction Modeling with the Cox model - all about the baseline hazard なお、本稿の作成に使用したファイルとRのコードは筆者のGithubですべて閲覧できる。 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. Broström, G. (2021). Event history analysis with R. CRC Press. 大橋靖雄., 浜田知久馬., &amp; 魚住龍史. (2021). 生存時間解析 第2版 SASによる生物統計. 東京大学出版. 杉本知之. (2021). 生存時間解析. 朝倉書店. "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 生存時間解析の実行と結果の描画には以下のパッケージを使用している。 survivalパッケージ flexsurvパッケージ ehaパッケージ metsパッケージ flexsurvパッケージ ggsurvfitパッケージ survminerパッケージ tidycmprskパッケージ coxmeパッケージ rstanarmパッケージ ## 生存時間分析 library(survival) library(eha) library(flexsurv) library(rstanarm) library(cmprsk) library(coxme) library(MASS) ## ggplotでの可視化 library(survminer) library(ggsurvfit) ## データハンドリング library(tidyverse) library(haven) library(easystats) ## グラフや表関連 library(patchwork) library(flextable) library(ggeffects) library(DT) library(knitr) library(kableExtra) library(stargazer) library(ggsci) library(lemon) library(ggplotify) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) なお、本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham &amp; Grolemund, 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang, 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al., 2021) 出版社サイト References Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. "],["Chapter1.html", "1 はじめに 1.1 イベントヒストリー分析とは何か 1.2 イベント・ヒストリー分析の難しさ 1.3 イベント・ヒストリー分析の種類", " 1 はじめに 1.1 イベントヒストリー分析とは何か イベント・ヒストリーとは、研究対象である「個体や集団で、ある事象が生じた時間的な記録」を意味する。霊長類学では、個体が何歳で死亡したかや、オスが何年群れに在籍したかといったデータがこれに該当する。イベント・ヒストリー分析(event history analysis)または生存時間分析(survival analysis)1は、イベント・ヒステリーを持つデータを用いて、事象の発生パターンや発生の原因を分析する一連の手法である。例えば霊長類の研究では、個体の寿命に影響する要因を調べたり(Ellis et al., 2019; Silk et al., 2010; Thompson &amp; Cords, 2018; Tung et al., 2016)、オスが群れに在籍する確率が時間と共にどう変化するのかを調べたりする(Swedell et al., 2011)ために用いられている。 1.2 イベント・ヒストリー分析の難しさ イベント・ヒストリーを持つデータの分析が難しい要因としては、扱うデータに以下の2つの特殊性があることが多いことが挙げられる。イベント・ヒストリー分析では、これらの困難に対処するため様々な手法が研究されてきた。 1.2.1 打ち切り イベント・ヒステリーを持つデータの特殊性の一つは、打ち切りが存在する点である。 具体例として、 Rossi et al. (1980) のデータを見ていこう。この研究では、432名の服役囚が出所後12ヶ月間に再逮捕されるかどうかを調べ、それに年齢や人種、学歴、配偶状態などの要因が影響しているかを調べようとしている。変数の詳細は、こちらを参照。 Rossi &lt;- read_csv(&quot;data/Rossi.csv&quot;) Rossi %&gt;% head(20) %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 実際にデータからランダムに抽出した20人が再逮捕されたかどうかを見ていこう(図1.1)。arrestは再逮捕されたかどうかを0/1で、weekは再逮捕された場合出所後何週間目だったかを表している。図からわかるように、12ヶ月(52週)経過後も逮捕されていないデータが数多く存在することが分かる。 Rossi %&gt;% sample_n(20) %&gt;% mutate(id = row_number()) %&gt;% mutate(arrest = as.factor(arrest)) %&gt;% ggplot(aes(x = week, y = id))+ geom_segment(aes(x = 0, xend = week, yend = id, y = id), color = &quot;grey&quot;)+ geom_point(shape = 23, size = 3, aes(fill = arrest))+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1) 図1.1: 服役囚が出所後何週間で逮捕されたか このようなデータは、通常の分析ではデータを扱うのが難しい。なぜなら、再逮捕されなかった服役囚に適切に従属変数(応答変数ともいう)2を割り当てることができないからである。彼らは10年たっても再逮捕されなかったかもしれないし、出所後13ヶ月に再逮捕されていたかもしれないが、このデータから知ることは不可能である。彼らに一律に同じ値を割り振っても（例えば期間の最大値である1年を割り振る）、彼らのデータを除外してもデータに大きなバイアスがかかってしまう。 このように、測定値が不完全にしかわからないデータを打ち切りデータという。打ち切りには、上記のように(1)調査終了時点ではまだイベントが起きていない場合と、(2)何らかの事情(e.g., 予期せぬ死、消息不明など)で調査期間の途中でその個体のデータが追跡できなくなっている場合(= 脱落)の2種類が存在する。 1.2.2 時間依存共変量 もう一つの特殊性は、対象の期間中に独立変数(説明変数ともいう)の値が変化する場合があることである（＝時間依存共変量）。 例えば、先ほどの例でも対象の12ヶ月の間に仕事の有無が変化していた(emp1~emp52)。こうした場合、回帰モデルに1ヶ月ごとの仕事の有無（e.g., 1ヶ月目の仕事の有無、2ヶ月目の仕事の有無、…）をすべて独立変数として入れることはできるが、この方法では出所後12ヶ月以内に再逮捕された服役囚に対して独立変数を割り振れないところが出てくる。なぜなら、出所後3ヶ月で再逮捕されたとすると、その服役囚の4ヶ月目以降の仕事のデータはないからである。 1.3 イベント・ヒストリー分析の種類 イベント・ヒストリー分析の手法は以下のような点を基準に分類される。本稿では、まず単純なモデルの説明から始め、徐々に難しいモデルの説明へ移る。 1.3.1 繰り返しの有無 生物学で扱うことの多い「死」という事象は一個体に一度しか生じないが、転職や結婚といった事象を扱う場合、これらは個人の一生において何度も発生する可能性がある。繰り返しの阿辻賞を扱う際にはより複雑な分析モデルが必要になる。 1.3.2 単一の事象と複数の事象 例えば生物の生死を扱うとき、多くの場合では死亡のタイプ（e.g., 死因など）を区別せず単一の死亡として扱う。しかし、死亡のタイプを分けて分析を行うことも可能である。このような複数の事象を扱うためには、単一な事象を扱う分析よりも複雑なモデルが必要である。 1.3.3 パラメトリック法とノンパラメトリック法 分析には、事象の発生時間の分布（どのような時間間隔で事象が発生するか）に仮定を置かないノンパラメトリックな分析と、特定の分布族（e.g., 指数分布、ワイブル分布など）を仮定するパラメトリックな分析がある。また、これら2つを結合したCoxの比例ハザードモデルは事象の発生時間に特定の分布を仮定しないが、線形関数に基づく回帰モデルであるというという点でセミパラメトリックな手法であるといえる。 1.3.4 離散時間と連続時間 事象の発生時間が正確に記録できている場合は「連続時間」モデルといわれる。通常は、時間の測定単位が小さい場合は（時間、分、秒）、連続時間として扱ってよい。一方、時間の測定単位が大きい場合（月、年）は「離散時間」モデルで扱うのが適している。実際の分析では離散時間モデルの方が理解するのが容易である。 References Ellis, S., Snyder-Mackler, N., Ruiz-Lambides, A., Platt, M. L., &amp; Brent, L. J. N. (2019). Deconstructing sociality: The types of social connections that predict longevity in a group-living primate. Proc. Biol. Sci., 286(1917), 20191991. Rossi, P. H., Berk, R. A., &amp; Lenihan, K. J. (1980). Money, work and crime: Some experimental results. New York: Academic Press. Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C., Engh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth, R. M., &amp; Cheney, D. L. (2010). Strong and consistent social bonds enhance the longevity of female baboons. Curr. Biol., 20(15), 1359–1361. Swedell, L., Saunders, J., Schreier, A., Davis, B., Tesfaye, T., &amp; Pines, M. (2011). Female “dispersal” in hamadryas baboons: Transfer among social units in a multilevel society. Am. J. Phys. Anthropol., 145(3), 360–370. Thompson, N. A., &amp; Cords, M. (2018). Stronger social bonds do not always predict greater longevity in a gregarious primate. Ecol. Evol., 8(3), 1604–1614. Tung, J., Archie, E. A., Altmann, J., &amp; Alberts, S. C. (2016). Cumulative early life adversity predicts longevity in wild baboons. Nat. Commun., 7. このような分析手法は様々な分野で発展してきたため、分野ごとに呼ばれ方が異なる。例えば生物学では動物の寿命を扱うことが多いため「生存時間分析」、工学の分野では機械の故障を扱うことが多いため「故障時間分析」などと呼ばれる。「イベント・ヒストリー分析」という呼び方は、こうした様々な分野で発展した分析手法の包括的な呼称である。↩︎ 従属変数、独立変数がわからない場合はこちらを参照。↩︎ "],["Chapter2.html", "2 パラメトリックな離散時間モデル 2.1 離散時間モデルの例 2.2 離散時間ハザード 2.3 ロジスティック回帰モデル 2.4 モデルの推定 2.5 Rでの実装 2.6 尤度比検定 2.7 離散時間ロジスティック回帰モデルの注意点 2.8 打ち切りデータの扱い 2.9 離散時間モデルと連続時間モデル", " 2 パラメトリックな離散時間モデル 本章では、繰り返しのない単一の事象を離散時間モデルで分析するパラメトリックな方法を概観する。 2.1 離散時間モデルの例 ここでは具体例として、1950年代後半から60年代前半に博士号を取得した生化学者301人(助教として勤務経験あり)が准教授に昇進するのに要する年数を記録したデータを使用する。データはdataフォルダにある(rank.dta)。dta形式のファイルは、havenパッケージのread_dta()で読み込める。 library(haven) rank &lt;- read_dta(&quot;data/rank.dta&quot;) データの先頭10行を取り出すと以下のようになっている。変数の説明は以下の通り。 ここでは、独立変数を用いて1年ごとの昇進の条件付き確率を回帰モデルを用いて推定することを目的とする。 従属変数にかかわる変数 - dur: 助教としての勤続年数 - promo: 助教への昇進の有無 独立変数(非時間依存変数) - undgrad: 対象者の出身学部の選抜の厳しさの尺度 - phdprest: 博士号を取得した大学の威信の尺度 - phdmed: 医学博士の有無 独立変数(時間依存変数) - prest: 勤務している大学の威信の尺度 - arts: 勤続年数ごとの累積発表論文数 - cits: 勤続年数ごとの論文の累積被引用回数 そのほか jobtime: 職場を変わった場合、何年目に変わったか rank %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 准教授への昇進時期の分布は以下のようになる(表2.1)。なお、リスク集合(risk set)とは、各時点で事象を経験する可能性のある個体の集まり、ハザード率(hazard rate)とは、ある時点でリスク集合に入っている個体がその時点で事象を経験する条件付き確率である(i.e., この表では昇進人数/リスク集合の大きさ)。 打ち切りは、25人については10年たっても准教授に昇進できていないために生じているが、それ以外については大学を離れたために生じている。 rank %&gt;% group_by(dur) %&gt;% summarise(昇進人数 = sum(promo), 打ち切り数 = sum(promo == &quot;0&quot;)) %&gt;% rename(勤続年数 = dur) %&gt;% ungroup() -&gt; hyou1 hyou1 %&gt;% mutate(勤続年数 = 勤続年数+1) %&gt;% mutate(N = 昇進人数 + 打ち切り数) %&gt;% mutate(sum = cumsum(N)) -&gt; hyou1_b hyou1 %&gt;% left_join(hyou1_b %&gt;% select(勤続年数, sum)) %&gt;% replace_na(list(sum = 0)) %&gt;% mutate(リスク集合の大きさ = sum(昇進人数 + 打ち切り数) - sum) %&gt;% select(-sum) %&gt;% mutate(推定されたハザード率 = 昇進人数/リスク集合の大きさ) %&gt;% kable(align = &quot;c&quot;, caption = &quot;准教授への昇進時期の分布&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.1: 准教授への昇進時期の分布 勤続年数 昇進人数 打ち切り数 リスク集合の大きさ 推定されたハザード率 1 1 1 301 0.0033223 2 1 6 299 0.0033445 3 17 12 292 0.0582192 4 42 10 263 0.1596958 5 53 9 211 0.2511848 6 46 7 149 0.3087248 7 31 6 96 0.3229167 8 15 2 59 0.2542373 9 7 6 42 0.1666667 10 4 25 29 0.1379310 2.2 離散時間ハザード イベント・ヒストリー分析では、上でも説明した「リスク集合」と「ハザード率」の二つが重要な概念である。分析ではハザード率を従属変数として、それぞれの独立変数がハザード率に与える影響を分析していく。 2.3 ロジスティック回帰モデル 離散時間モデルでは、ロジット変換3を利用することでハザード関数\\(P(t)\\)を以下のようにあらわす。なお、\\(x_1\\)は非時間依存変数を、\\(x_2(t)\\)は時間依存変数を表す。また、\\(t\\)は勤続年数を表す。\\(b_1\\)と\\(b_2\\)は偏回帰係数と呼ぶ。ロジット変換を施すことで、右辺がどのような値も取っても\\(P(t)\\)が0から1の範囲に収まる。 \\[ \\begin{equation} log\\biggl(\\frac{P(t)}{1-P(t)}\\biggl) = b_0 + b_1x_1 + b_2x_2(t) + b_3t + b_4t^2 \\tag{2.1} \\end{equation} \\] 2.4 モデルの推定 次に、データを基にパラメータ(\\(b_1から b_4\\))を推定する。推定は基本的に最尤法を用いて行う。これは、実際に観察された値が得られる確率が最大になるようにパラメータを推定する方法である。 実際の推定手順は以下のようになる。 各個体がリスク集合に入っている期間をある時間単位で分け(今回は1年)、その1単位ごと(= 人年ごと)に事象の発生を記録していく。 各個体は各単位ごとに(この場合は1年ごとに)昇進した場合は従属変数に1を、してない場合は0を割り当てられる。 データセットを作成し、最尤法を用いてロジスティック回帰モデルのパラメータを推定する。 2.5 Rでの実装 2.5.1 データの加工 それでは、Rで実際にモデルのパラメータを推定してみる。分析をするためには、データフレームを縦長にする必要がある。具体的には、発表論文数(art1art10)と被引用数(cit1cit10)をそれぞれ一列にする必要がある。 rank %&gt;% ## 個体IDの列を作成 rowid_to_column(var = &quot;id&quot;) %&gt;% ## 勤続年数ごとの論文数を一列に pivot_longer(cols = art1:art10, names_to = &quot;art&quot;, values_to = &quot;art_n&quot;) %&gt;% ## 欠損値を除く filter(!is.na(art_n)) %&gt;% arrange(id) %&gt;% ## 行番号を作る rowid_to_column(&quot;rowid&quot;) %&gt;% select(-(cit1:cit10), -art) -&gt; rank2 rank %&gt;% ## 個体IDの列を作成 rowid_to_column(var = &quot;id&quot;) %&gt;% ## 勤続年数ごとの引用数を一列に pivot_longer(cols = cit1:cit10, names_to = &quot;cit&quot;, values_to = &quot;cit_n&quot;) %&gt;% ## 欠損値を除く filter(!is.na(cit_n)) %&gt;% arrange(id) %&gt;% ## 行番号を作る rowid_to_column(&quot;rowid&quot;) %&gt;% select(cit_n, rowid) -&gt; rank3 ## 結合 rank2 %&gt;% inner_join(rank3, by = &quot;rowid&quot;) %&gt;% arrange(id) %&gt;% group_by(id) %&gt;% ## 個体ごとに勤続年数の列を作成 mutate(year = row_number()) %&gt;% ## 変数promoが昇進のあった年のみ1をとるようにする ungroup() %&gt;% mutate(promo = ifelse(year &lt; dur,0,promo)) %&gt;% ## jobtimeの欠損値を0に replace_na(list(jobtime = 0)) %&gt;% ## 大学威信度の列を作成 mutate(jobpres = ifelse(year &lt; jobtime, prest1, prest2)) %&gt;% select(-prest1, -prest2)-&gt; rank4 できたデータシートは以下の通り。 datatable(rank4, options = list(scrollX = 100), rownames = FALSE) 2.5.2 分析 それでは、実際に分析する。分析には一般化線形モデルによる分析ができるglm()関数を用いる。 まずは1つ目のモデルとして、勤続年数を入れない線形モデルを考えてみる。 mod1 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n, data = rank4, family = binomial(link = &quot;logit&quot;)) 結果は以下の通り(表2.2)。 model_parameters(mod1) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod1の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.2: mod1の結果 Parameter Coefficient 95%CI SE z p (Intercept) -2.9636747 [-3.80, -2.15} 0.4210727 -7.0383926 0.0000000 undgrad 0.1802769 [0.06, 0.30} 0.0607534 2.9673535 0.0030038 phdmed -0.2650547 [-0.58, 0.05} 0.1614778 -1.6414308 0.1007080 phdprest -0.0029980 [-0.18, 0.17} 0.0886335 -0.0338249 0.9730168 jobpres -0.2535299 [-0.46, -0.05} 0.1054517 -2.4042272 0.0162067 art_n 0.1270934 [0.10, 0.16} 0.0165769 7.6669053 0.0000000 cit_n -0.0014547 [-0.00, 0.00} 0.0012590 -1.1554230 0.2479173 2つ目のモデルとして、勤続年数とその二乗を説明変数に入れたモデルを考える。 mod2 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + year + I(year^2), data = rank4, family = &quot;binomial&quot;) 結果は以下の通り(表2.3)。 model_parameters(mod2) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod2の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.3: mod2の結果 Parameter Coefficient 95%CI SE z p (Intercept) -8.4846678 [-10.07, -7.02} 0.7756586 -10.9386630 0.0000000 undgrad 0.1939331 [0.07, 0.32} 0.0635127 3.0534551 0.0022622 phdmed -0.2356943 [-0.57, 0.10} 0.1717631 -1.3722061 0.1699993 phdprest 0.0270565 [-0.16, 0.21} 0.0931669 0.2904086 0.7715036 jobpres -0.2535406 [-0.48, -0.03} 0.1138113 -2.2277268 0.0258987 art_n 0.0733840 [0.04, 0.11} 0.0181374 4.0459977 0.0000521 cit_n 0.0001255 [-0.00, 0.00} 0.0013125 0.0956291 0.9238152 year 2.0818890 [1.65, 2.56} 0.2337665 8.9058484 0.0000000 I(year^2) -0.1585829 [-0.20, -0.12} 0.0203027 -7.8109434 0.0000000 2つのモデルを比較すると以下の通り。 stargazer(mod1, mod2, type = &quot;text&quot;) ## ## ============================================== ## Dependent variable: ## ---------------------------- ## promo ## (1) (2) ## ---------------------------------------------- ## undgrad 0.180*** 0.194*** ## (0.061) (0.064) ## ## phdmed -0.265 -0.236 ## (0.161) (0.172) ## ## phdprest -0.003 0.027 ## (0.089) (0.093) ## ## jobpres -0.254** -0.254** ## (0.105) (0.114) ## ## art_n 0.127*** 0.073*** ## (0.017) (0.018) ## ## cit_n -0.001 0.0001 ## (0.001) (0.001) ## ## year 2.082*** ## (0.234) ## ## I(year2) -0.159*** ## (0.020) ## ## Constant -2.964*** -8.485*** ## (0.421) (0.776) ## ## ---------------------------------------------- ## Observations 1,741 1,741 ## Log Likelihood -595.566 -506.013 ## Akaike Inf. Crit. 1,205.132 1,030.025 ## ============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 2.5.3 結果の解釈 モデル1(mod1)では(表2.2)、3つの独立変数が有意に准教授への昇進のハザード率に影響していることが分かる(undgrad、jobpres、art_n)。具体的には、より選抜度合いの高い大学を卒業した生化学者とより多くの論文を発表した生化学者はハザード率が高い。一方で、より威信度の高い大学で現在働いている生化学者ほどハザード率は低い。 各変数が1増加したときに、准教授に昇進するオッズ比(\\(\\frac{P(t)}{1-P(t)}\\))がどの程度増加するかを計算すると(これは、\\(e^{偏回帰係数}\\)で求まる。式(2.1)を参照)、以下のようになる。すなわち、「学部選抜度(undgrad)」が1増えるとオッズ比が約1.2倍に、「累積論文発表数(art_n)」が1増えるとオッズ比が約1.14倍になる。一方、「勤務先の大学の威信度(jobpres)」が1増加すると、オッズ比は0.78倍に減少する。 model_parameters(mod1) %&gt;% data.frame() %&gt;% select(Parameter, Coefficient) %&gt;% mutate(odds = exp(Coefficient)) ## Parameter Coefficient odds ## 1 (Intercept) -2.963674661 0.05162885 ## 2 undgrad 0.180276920 1.19754894 ## 3 phdmed -0.265054700 0.76716399 ## 4 phdprest -0.002998022 0.99700647 ## 5 jobpres -0.253529874 0.77605656 ## 6 art_n 0.127093447 1.13552312 ## 7 cit_n -0.001454692 0.99854637 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.1)。曲線はモデルに基づく回帰曲線を、塗りつぶし部分は95%信頼区間を表す。 fit_mod1_a &lt;- ggpredict(mod1, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod1_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit1_a fit_mod1_b &lt;- ggpredict(mod1, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod1_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit1_b p_fit1_a + p_fit1_b 図2.1: モデル1の推定結果 モデル2も結果自体は大きく変わらないが、勤続年数とその二乗が有意に影響していることが分かる。また、「累積論文発表数(art_n)」の偏回帰係数が大幅に小さくなっており、オッズ比も1.14倍から1.08倍に減少している。 model_parameters(mod2) %&gt;% data.frame() %&gt;% select(Parameter, Coefficient) %&gt;% mutate(odds = exp(Coefficient)) ## Parameter Coefficient odds ## 1 (Intercept) -8.4846678008 0.000206612 ## 2 undgrad 0.1939331150 1.214015081 ## 3 phdmed -0.2356943107 0.790022138 ## 4 phdprest 0.0270564703 1.027425820 ## 5 jobpres -0.2535405982 0.776048238 ## 6 art_n 0.0733840049 1.076143702 ## 7 cit_n 0.0001255168 1.000125525 ## 8 year 2.0818890246 8.019603843 ## 9 I(year^2) -0.1585829127 0.853352207 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.2)。左図の傾きが図2.1に比べて緩やかになっており、図からもモデル1との違いが読み取れる。 fit_mod2_a &lt;- ggpredict(mod2, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod2_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit2_a fit_mod2_b &lt;- ggpredict(mod2, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod2_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit2_b p_fit2_a + p_fit2_b 図2.2: モデル2の推定結果 2.6 尤度比検定 あるモデルが別のモデルの「入れ子」構造(一方のモデルが他方のモデルの独立変数をすべて含む)であるとき、尤度比検定によってどちらの方が適合度が高いか検定を行うことができる。2つのモデルの対数尤度の差の2倍が\\(\\chi^2\\)分布に近似できることを利用して帰無仮説検定を行うことが多い4。 Rでは以下のように行う。結果を見ると、モデル2の方が有意に適合度が高いことが分かる。 このような検定は、本稿で以後出てくるモデルやパラメータの検定にも応用可能である。 anova(mod1,mod2, test = &quot;Chisq&quot;) ## Analysis of Deviance Table ## ## Model 1: promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n ## Model 2: promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + ## year + I(year^2) ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 1734 1191.1 ## 2 1732 1012.0 2 179.11 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.7 離散時間ロジスティック回帰モデルの注意点 上記のモデルにはいくつか注意点がある。 一個体が複数の事象を経験する場合は、事象の回数の影響を修正する必要がある。 ロバスト推定による標準誤差を求めたり、一般化推定式やランダム(変量)効果モデルを用いたりする。 区切る時間単位を適切に設定する必要がある。 今回は、准教授の昇進が各年度の初めに行われるため、1年ごとにデータを区切ることは適切であった。これを1日ごとに区切るとデータが膨大になってしまうし、５年ごとに区切ると多くの情報が失われてしまう。分析対象の事象に応じて、適切に区切る時間単位を適切に設定する必要がある。 代替手法 式(2.1)は独立変数のハザード率に対する影響を検討する最も知られた方法だが、以下の「補対数対数モデル」も代替手法として有用である。このモデルでも、右辺がどのような値をとろうと\\(P(t)\\)は0から1に収まる。 \\[ \\begin{equation} log[-log(1-P(t))] = b_0 + b_1x_1 + b_2x_2(t) + b_3t + b_4t^2 \\tag{2.2} \\end{equation} \\] Rでは、以下のように実装できる。 mod3 &lt;- glm(promo ~ undgrad + phdmed + phdprest + jobpres + art_n + cit_n + year + I(year^2), data = rank4, family = binomial(link = &quot;cloglog&quot;)) 結果は以下の通り(表2.4)。ロジスティック回帰モデルと結果は大きく変わらない。特にP値だけに着目する場合はどちらのモデルを選んでも決定的な差はない。 model_parameters(mod3) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% select(-df_error, -CI_low, -CI_high, -CI) %&gt;% select(Parameter, Coefficient, `95%CI`, everything()) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod3の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表2.4: mod3の結果 Parameter Coefficient 95%CI SE z p (Intercept) -7.9961202 [-9.40, -6.69} 0.6943534 -11.5159220 0.0000000 undgrad 0.1694896 [0.06, 0.28} 0.0548959 3.0874751 0.0020186 phdmed -0.2153786 [-0.50, 0.08} 0.1469985 -1.4651751 0.1428732 phdprest 0.0100102 [-0.15, 0.17} 0.0806278 0.1241530 0.9011941 jobpres -0.1934044 [-0.38, -0.01} 0.0967829 -1.9983313 0.0456808 art_n 0.0623539 [0.03, 0.09} 0.0142864 4.3645723 0.0000127 cit_n -0.0004238 [-0.00, 0.00} 0.0010398 -0.4075788 0.6835830 year 1.9223437 [1.53, 2.36} 0.2128381 9.0319539 0.0000000 I(year^2) -0.1469834 [-0.19, -0.11} 0.0184860 -7.9510496 0.0000000 undgradとart_n、jobpresについて結果を図示すると以下のようになる(図2.3)。 fit_mod3_a &lt;- ggpredict(mod3, terms = c(&quot;art_n[0:50, by = 0.1]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod3_a %&gt;% data.frame() %&gt;% rename(art_n = x, undgrad = group) %&gt;% ggplot(aes(x = art_n, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit3_a fit_mod3_b &lt;- ggpredict(mod3, terms = c(&quot;jobpres[0:5, by = 0.01]&quot;, &quot;undgrad[1:7,by = 3]&quot;)) fit_mod3_b %&gt;% data.frame() %&gt;% rename(jobpres = x, undgrad = group) %&gt;% ggplot(aes(x = jobpres, y = predicted))+ geom_line(aes(color = undgrad), linewidth = 1)+ geom_ribbon(aes(fill = undgrad, ymin = conf.low, ymax = conf.high), alpha = 0.2)+ labs(y = &quot;ハ\\nザ\\nǀ\\nド\\n率&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, axis.title.y = element_text(angle = 0, vjust = 0.5))+ scale_color_nejm()+ scale_fill_nejm() -&gt; p_fit3_b p_fit3_a + p_fit3_b 図2.3: モデル3の推定結果 2.8 打ち切りデータの扱い 今回のデータでは打ち切りは以下の2通りで生じており、これらは「右側打ち切り(right censoring)」と呼ばれ、最後に対象が観察された時点で事象がまだ発生していないことによるものである。 10年経ってもまだ准教授に昇進していない(= 固定打ち切り(fixed censoring))) 打ち切りの時点は全ての個体で同じ。 准教授昇進前に大学を辞めた(= ランダムな打ち切り(random censoring)) 打ち切りの時点は個体によって異なる。脂肪や転居による追跡の終了などが理由。ただし、「ランダム」とは打ち切りのタイミングが変数と一切関係ないという意味でない点に注意。 2の場合、ほぼすべてのイベント・ヒストリー分析では打ち切りが生じた時間は「無情報」であると仮定している。すなわち、特定の時点である個体に打ち切りが生じても、その個体のハザード率には何の要因も影響していないことを仮定している。この仮定は、今回の例では昇進の可能性の低い研究者ほど大学を辞める傾向があるのであれば妥当ではない。おそらく何人かは准教授に昇進できずに雇用期間が終了したことが打ち切りの原因になっていたと考えられる。 しかし、今のところこの仮定を緩めて分析する方法はなく、ほとんどの研究者はこの問題に目をつぶって分析を行うしかない。そのため、研究デザインの段階でランダムでない打ち切りを最小限にするために可能な限りあらゆることを行う必要がある。 2.9 離散時間モデルと連続時間モデル 一般的に、離散時間モデルは後述する連続時間モデルと極めて似た結果をもたらすことが多い。実際、式(2.1)の離散時間モデルは、時間の単位を小さくするにつれて第4章で見る比例ハザードモデルに近づく。したがって、離散時間モデルと連続時間モデルのいずれを用いるかは一般的に計算にかかる手間と簡便さを考慮して判断する。時間依存の独立変数がない場合、しばしば以降の2つの章で説明する連続時間モデルを使う方が簡単である。他方、時間依存の独立変数があるならば、いずれのモデルでも手間や簡便さは変わらない。 References 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 粕谷英一. (2012). 一般化線形モデル. 共立出版. ロジット変換がわからない方はこちら。 ↩︎ 対数尤度や尤度比検定の詳細については、 粕谷 (2012) や 久保 (2012) を参照。パラメトリックブーストラップ法を用いたより正確な検定を行うこともできる(久保, 2012)。↩︎ "],["Chapter3.html", "3 連続時間を用いたパラメトリックな手法 3.1 連続時間ハザード率 3.2 パラメトリックな比例ハザードモデル 3.3 加速時間ハザードモデル 3.4 適合度の評価 3.5 観察されない異質性の原因 3.6 なぜパラメトリックモデルを用いるのか", " 3 連続時間を用いたパラメトリックな手法 前章(2)の離散時間モデルは汎用性が高いが、イベント・ヒストリー分析では連続時間モデルが使われることが多い。本章では、事象が起きた時点が正確に記録されているデータに対して一般的に使われるパラメトリックな手法を解説する。この方法では、推定されるパラメータを除いて、モデルに含まれる値の分布の型がはっきり仮定される。 3.1 連続時間ハザード率 連続時間モデルでは、時点\\(t\\)で事象を経験する可能性のある個体が、時点\\(t\\)から\\(t+s\\)までの間に事象を経験する確率\\(P(t,t+s)\\)を考える。なお、\\(t=1\\)のとき、これは離散時間のハザード率と同じになる。 この確率を\\(s\\)で割り、\\(s\\)を0に限りなく近づけたときの極限値が連続時間のハザード率になる(式(3.1))。この値は、1より大きな値をとることもあるが負にはならない。 \\[ h(t) = \\lim_{s \\to 0} \\frac{P(t,t+s)}{s} \\tag{3.1} \\] ハザード関数\\(h(t)\\)の形によって連続時間のイベント・ヒストリー分析のタイプが分類できる。 3.2 パラメトリックな比例ハザードモデル 3.2.1 モデルの分類 パラメトリックな分析には、「比例ハザードモデル(proportional hazards model)」と「加速時間ハザードモデル(accelerated failure time model)」の2種類があるが、本節では前者について解説する。 比例ハザードモデルは、ハザード関数が時間と独立変数によってどのように規定されるかによって、以下の3つに分類できる。なお、いずれのモデルでもパラメータの推定は最尤法で行う。 3.2.1.1 指数回帰モデル 最もわかりやすい分析は、\\(h(t)\\)を独立変数の線形関数にすることである(式(3.2))。左辺で\\(log\\)をとっているのは、線形関数が0より小さくならないようにするためである。\\(x_1\\)と\\(x_2\\)は非時間依存の独立変数を、\\(b_0\\)~\\(b_2\\)は推定されるパラメータを表す。なかでも\\(b_1\\)と\\(b_2\\)は偏回帰係数である。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 \\tag{3.2} \\] この式ではハザード関数は時間に依存しない(= 時間に対して一定)。このようなモデルでは通常事象が発生するまでの時間として指数分布5を仮定するので、「指数回帰モデル」といわれる。指数分布の確率密度関数は1つのパラメータ\\(\\lambda\\)を用いて以下のように表せる。ハザード率は一定の値\\(\\lambda\\)で与えられる。 \\[ f(t) = \\lambda e^{-\\lambda t} \\;\\; (t \\geq 0) \\tag{3.3} \\] 3.2.1.2 ゴンぺルツ回帰モデル 一般的に、ハザード率が時間を通して一定であると仮定するのは現実的でない。例えば生物の死を考えると、老化するほど死亡する確率は増大するはずである。そこで、指数回帰モデルの仮定を緩め、ハザード率の対数(log)が時間と共に直線的に増加/現象すると仮定するモデルを考える(式(3.4))。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + ct \\tag{3.4} \\] このようなモデルでは通常事象が発生するまでの時間としてゴンぺルツ分布6を仮定するので、「ゴンぺルツ回帰モデル」といわれる。ゴンぺルツ分布の確率密度関数は２つのパラメータ\\(a\\)と\\(b\\)を用いて以下のように表せる。ハザード率は\\(ae^{bt}\\)で与えられる。 \\[ f(t) = a exp(at - \\frac{a}{b}e^{bt} + \\frac{a}{b}) \\;\\;(t \\geq 0) \\tag{3.5} \\] 3.2.1.3 ワイブル回帰モデル あるいは、ハザード率の対数が時間の対数と共に直線的に増加/減少するモデルを考えることもできる(式(3.6))。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + clog(t) \\tag{3.6} \\] このようなモデルでは通常事象が発生するまでの時間としてワイブル分布7を仮定するので、「ワイブル回帰モデル」といわれる。ワイブル分布の確率密度関数は２つのパラメータ\\(a\\)と\\(b\\)を用いて以下のように表せる。ハザード率は\\(\\frac{a}{b^a} t^{a-1}\\)で与えられる。なお、式からわかるように指数分布はワイブル分布で\\(a=1\\)のときである(\\(\\lambda = 1/b\\))。 \\[ f(t) =\\frac{a}{b} \\biggl(\\frac{t}{b}\\biggl)^{a-1} exp\\biggl(-\\biggl(\\frac{t}{b}\\biggl)^a\\biggl) \\;\\;(t \\geq 0) \\tag{3.7} \\] 3.2.2 注意点 時間と独立変数の間の交互作用がない \\(x_1\\)と\\(x_2\\)の効果(\\(b_1\\)と\\(b_2\\))は全ての時点で同じである。 ワイブル回帰モデルもゴンぺルツ回帰モデルも時間に対して単調増加/減少である ハザード率と時間の関係がU字型や逆U字型になることはない。これは、実際の分析では使いにくい場合がある。なお、次節(3.3)でこの制約のないモデルを検討する。 誤差項がない ただし、実際に事象が発生するまでの時間とモデルで推定される時間には誤差が含まれるので、決定論的なモデルではない。 3.2.3 Rでの実装 3.2.3.1 データの読み込み まず、分析に用いる第1章で触れた服役囚の再販データを読み込む。このデータでは、432人の元服役囚の内、ランダムに選ばれた半分は経済的支援を受け、残りの半分は対照群として支援を受けなかった。変数の説明は以下の通り。なお、時間依存的な変数は本章では扱わず、次章で扱う。 従属変数にかかわる変数 - week: 出所後の経過週数 - arrest: 再犯の有無 独立変数(非時間依存変数) - age: 年齢 - race: 黒人か否か(1/0) - mar: 婚姻の有無(1/0) - prio: 前科の数 - paro: 仮釈放か否か(1/0) - wexp: 過去の就業経験の有無(1/0) - fin: 経済的支援の有無(1/0) 独立変数(時間依存変数) - work: 週ごとの就業状態 recid &lt;- read_dta(&quot;data/recid.dta&quot;) recid %&gt;% datatable(options = list(scrollX = 100), rownames = FALSE) 3.2.3.2 分析の実行 ehaパッケージのphreg関数を用いる。従属変数としては、期間中に事象を経験したかの変数(arrest)と、事象を経験した場合はその時間を、しなかった場合は打ち切りの時間を示す変数(week)を入れる必要がある。 以下のように実行できる。指数分布はワイブル分布で\\(a=1\\)のときなので、dist = \"weibullでshape = 1としてあげればよい。 ## 指数回帰モデル mod_exp &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;, shape = 1) ## ゴンぺルツ回帰モデル mod_gom &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;gompertz&quot;) ## ワイブル回帰モデル mod_wei &lt;- phreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) 結果は以下の通りである。Coefは偏回帰係数の推定値を、Exp(Coef)は偏回帰係数を指数変換したもの(\\(e^{偏回帰係数}\\))を、se(Coef)は偏回帰係数の標準誤差を表している。ゴンぺルツモデルとワイブルモデルの結果では、shapeは確率密度関数(式(3.5)と式(3.7))のパラメータ\\(a\\)の、scale`はパラメータ\\(b\\)の推定値である。 ## 指数回帰モデル mod_exp ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;weibull&quot;, shape = 1) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.366 0.693 0.191 0.055 ## age 24.765 -0.056 0.946 0.022 0.011 ## race 0.872 0.305 1.357 0.308 0.322 ## wexp 0.596 -0.147 0.864 0.212 0.488 ## mar 0.132 -0.427 0.652 0.381 0.263 ## paro 0.622 -0.083 0.921 0.196 0.673 ## prio 2.841 0.086 1.089 0.028 0.002 ## ## log(scale) 4.051 0.586 0.000 ## ## Shape is fixed at 1 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -686.37 ## LR test statistic 31.22 ## Degrees of freedom 7 ## Overall p-value 5.65729e-05 ## ゴンぺルツ回帰モデル mod_gom ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;gompertz&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.381 0.683 0.191 0.046 ## age 24.765 -0.057 0.944 0.022 0.009 ## race 0.872 0.313 1.367 0.308 0.310 ## wexp 0.596 -0.148 0.862 0.212 0.485 ## mar 0.132 -0.435 0.648 0.382 0.255 ## paro 0.622 -0.082 0.921 0.196 0.674 ## prio 2.841 0.092 1.096 0.029 0.001 ## ## log(scale) 3.894 0.311 0.000 ## log(shape) -0.676 0.816 0.408 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -681.14 ## LR test statistic 33.35 ## Degrees of freedom 7 ## Overall p-value 2.27754e-05 ## ワイブル回帰モデル mod_wei ## Call: ## phreg(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid, dist = &quot;weibull&quot;) ## ## Covariate W.mean Coef Exp(Coef) se(Coef) Wald p ## fin 0.511 -0.382 0.682 0.191 0.046 ## age 24.765 -0.057 0.944 0.022 0.009 ## race 0.872 0.316 1.371 0.308 0.306 ## wexp 0.596 -0.150 0.861 0.212 0.481 ## mar 0.132 -0.437 0.646 0.382 0.253 ## paro 0.622 -0.083 0.921 0.196 0.673 ## prio 2.841 0.092 1.097 0.029 0.001 ## ## log(scale) 3.990 0.419 0.000 ## log(shape) 0.339 0.089 0.000 ## ## Events 114 ## Total time at risk 19809 ## Max. log. likelihood -679.92 ## LR test statistic 33.42 ## Degrees of freedom 7 ## Overall p-value 2.2149e-05 3つのモデルから推定されたハザード関数を描画したのが図3.1である。定義通り、指数回帰モデルでは時間に依らずハザード率が一定であることが分かる。なお、これらは全ての独立変数を平均値にしたときのものであり、以後本稿で示されるハザード関数はいずれも同様である。 as.ggplot(~plot(mod_exp, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;exponential model&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_gom, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Gompertz model&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_wei, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Weibull model&quot;, ylim = c(0,0.03))) 図3.1: モデルから推定されたハザード関数 なお、推定された生存曲線(= 時間の経過とともに再犯をしていない元服役囚の数がどのように減っていくかを表したもの)は以下のようになる(図3.2)。ハザード関数と同様に、これらは全ての独立変数を平均値にしたときのものである。 as.ggplot(~plot(mod_exp, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;exponential model&quot;))+ as.ggplot(~plot(mod_gom, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;Gompertz model&quot;))+ as.ggplot(~plot(mod_wei, fn = &quot;sur&quot;, xlab = &quot;week&quot;, ylab = &quot;survival rate&quot;, main = &quot;Weibull model&quot;)) 図3.2: モデルから推定された生存曲線 各モデルの偏回帰係数の推定値を比較したものが以下の表である(表3.1)。３つのモデルの推定結果はほとんど変わらない。いずれのモデルでも有意な影響を持っていたのはageとprioであり、finはワイブル回帰モデルのみで有意になった。 偏回帰係数は、ほかの変数の影響を統制したうえでその独立変数が1増加したときにハザード率の対数(式(3.2) ~ 式(3.6)を思い出してほしい)がどの程度増加するかを表している。例えば指数回帰モデルでは、表3.1の偏回帰係数の推定値(Coef(exp))より、他の変数の影響をコントロールしたときに年齢(age)が1歳上がるとハザード率の対数が0.056低下する。より直感的に理解するためには、偏回帰係数を指数変換すればよい(Exp(Coef_exp))。これは、ハザード比と呼ばれ、独立変数が1増加したときにハザード率の比がどの程度変化するかを示している。例えば、経済的援助がある場合(fin = 1)のハザード率は、ない場合(fin = 0)に比べると0.693倍になる。 tibble(Covariate = mod_exp$covar, &quot;Coef(exp)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_exp))[1:7], &quot;Exp(Coef_exp)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_exp)))[1:7], &quot;Coef(gom)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_gom))[1:7], &quot;Exp(Coef_gom)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_gom)))[1:7], &quot;Coef(wei)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_wei))[1:7], &quot;Exp(Coef_wei)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_wei))[1:7])) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;指数分布&quot;,&quot;ゴンぺルツ&quot;, &quot;ワイブル&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-1a0e7682{}.cl-1a063760{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1a0a5bba{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1a0a70fa{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1a0a7104{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1a0a7105{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表3.1: 各モデルの推定値の比較 指数分布ゴンぺルツワイブルCovariateCoef(exp)Exp(Coef_exp)Coef(gom)Exp(Coef_gom)Coef(wei)Exp(Coef_wei)fin-0.3660.693-0.3810.683-0.3820.682age-0.0560.946-0.0570.944-0.0570.944race0.3051.3570.3131.3670.3161.371wexp-0.1470.864-0.1480.862-0.1500.861mar-0.4270.652-0.4350.648-0.4370.646paro-0.0830.921-0.0820.921-0.0830.921prio0.0861.0890.0921.0960.0921.097 指数回帰モデルはワイブル回帰モデルの特殊な場合(\\(a=1\\)の場合)なので、これらのモデルは尤度比検定で適合度を比較することができる。anova()関数はphregクラスには適用できないようだが、自分で対数尤度を求めることで計算することはできる。以下の自作関数8を用いて尤度比検定を行うと、ワイブル回帰モデルの方が有意に適合度が高い。すなわち、ハザード率が時間によって変化すると考える方がより妥当だと考えられる。 anova.phreg &lt;- function(...){ phreg.models &lt;- list(...) log.liks &lt;- NULL n.parameters &lt;- NULL for(i in 1:length(phreg.models)){ log.liks &lt;- c( log.liks, phreg.models[[i]]$loglik[2] ) n.parameters &lt;- c( n.parameters, nrow(phreg.models[[i]]$var) ) } deviance.models &lt;- -2 * log.liks Df &lt;- n.parameters[-1] - n.parameters[-length(log.liks)] lrs &lt;- deviance.models[-length(log.liks)] - deviance.models[-1] p.values &lt;- 1 - pchisq(lrs, Df) lr.test &lt;- cbind(&quot;deviance&quot; = lrs, Df, p.values) lr.test &lt;- rbind(c(NA, NA, NA), lr.test) output &lt;- cbind(&quot;Log likelihood&quot; = log.liks, n.parameters, lr.test) Call &lt;- match.call() # 以下3行は返値の行列に各モデルの名前をつけるための操作だが、 Call$k &lt;- NULL # 訳も分からず AIC.logLik() を真似ているだけなので、 rownames(output) &lt;- as.character(Call[-1L]) # おかしなことをやっているかも return(output) } anova.phreg(mod_exp, mod_wei) ## Log likelihood n.parameters deviance Df p.values ## mod_exp -686.3659 8 NA NA NA ## mod_wei -679.9166 9 12.89875 1 0.000328801 3.3 加速時間ハザードモデル 3.3.1 モデルの概要 加速時間ハザードモデルは、\\(T\\)を事象が発生するまでの時間とするとき、次のように書くことができる。なお、\\(u\\)は誤差項であり、独立変数とは統計的に独立で均一の分散\\(\\sigma^2\\)をもつ。このモデルは、従属変数を\\(logT\\)とする通常のモデルと同じである。 \\[ logT = b_0 + b_1x_1 + b_2x_2 + u \\tag{3.8} \\] モデルでは誤差項\\(u\\)の分布にとしては、正規分布、対数ガンマ分布、ロジスティック分布、極値分布など様々な分布が仮定される。これらの分布を仮定するとき、\\(T\\)はそれぞれ対数正規分布、ガンマ分布、対数ロジスティック分布、ワイブル分布になる(表3.2)。 tibble(&quot;uの分布&quot; = c(&quot;正規分布&quot;,&quot;対数ガンマ分布&quot;,&quot;ロジスティック分布&quot;,&quot;極値分布&quot;), &quot;Tの分布&quot; = c(&quot;対数正規分布&quot;,&quot;ガンマ分布&quot;,&quot;対数ロジスティック分布&quot;,&quot;ワイブル分布&quot;)) %&gt;% kable(caption = &quot;uの分布とTの分布の対応&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.2: uの分布とTの分布の対応 uの分布 Tの分布 正規分布 対数正規分布 対数ガンマ分布 ガンマ分布 ロジスティック分布 対数ロジスティック分布 極値分布 ワイブル分布 加速ハザードモデルでは従属変数を\\(logT\\)ではなくハザード率になるように書き換えることもできるが、複雑な式になる傾向がある。比例ハザードモデルと異なり、対数ロジスティックモデルと対数正規モデルではハザード率は非単調関数(= 時間の経過とともに柔軟に増えたり減ったりする)である。パラメータの推定値は最尤法によって求められる。 3.3.2 Rでの実装 ここでは、Allison (2014) に倣って再犯データにガンマ分布モデルを当てはめる。分析にはflexsurvパッケージのflexsurvreg()関数を用いる。このパッケージは比例ハザードモデルも含め様々なパラメトリックモデルに対応している。 以下のようにモデリングできる。methodで採用推定を行うアルゴリズムを指定でき、「Nelder-Mead法」「BFGS法」「L-BFGS法」などを選べる。今回はL-BFGS法を用いる mod_gam &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;gamma&quot;, method = &quot;L-BFGS-B&quot;) 結果は以下の通り。比例ハザードモデルと同様に、ageとprioが5%水準で有意な影響を持った(95%信頼区間が0にまたがっていない)。 mod_gam ## Call: ## flexsurvreg(formula = Surv(week, arrest) ~ fin + age + race + ## wexp + mar + paro + prio, data = recid, dist = &quot;gamma&quot;, method = &quot;L-BFGS-B&quot;) ## ## Estimates: ## data mean est L95% U95% se exp(est) L95% ## shape NA 1.51810 1.21665 1.89424 0.17145 NA NA ## rate NA 0.02684 0.01127 0.06392 0.01188 NA NA ## fin 0.50000 -0.28265 -0.56177 -0.00353 0.14241 0.75378 0.57020 ## age 24.59722 -0.03890 -0.07036 -0.00745 0.01605 0.96184 0.93206 ## race 0.87731 0.23924 -0.20559 0.68408 0.22696 1.27029 0.81417 ## wexp 0.57176 -0.13353 -0.43936 0.17229 0.15604 0.87500 0.64445 ## mar 0.12269 -0.34183 -0.88623 0.20257 0.27776 0.71047 0.41221 ## paro 0.61806 -0.05718 -0.34191 0.22756 0.14527 0.94443 0.71041 ## prio 2.98380 0.06740 0.02453 0.11027 0.02187 1.06973 1.02483 ## U95% ## shape NA ## rate NA ## fin 0.99647 ## age 0.99258 ## race 1.98194 ## wexp 1.18802 ## mar 1.22455 ## paro 1.25553 ## prio 1.11658 ## ## N = 432, Events: 114, Censored: 318 ## Total time at risk: 19809 ## Log-likelihood = -680.0054, df = 9 ## AIC = 1378.011 注意が必要なのは、生存時間分析でよく使われる統計ソフト(StataやSAS)とは偏回帰係数の推定値の正負が逆になっている点である。推定値の正負を逆転させ、指数回帰モデルとワイブル回帰モデルの結果と比較したのが表3.3である。指数回帰モデルやワイブル回帰モデルとガンマ分布モデルの偏回帰係数の正負が逆になるのは、前者がハザード率を従属変数にしているのに対し、後者は事象が起きるまでの時間\\(T\\)を従属変数にしているからである。ハザード率が低いほど\\(T\\)は大きくなるので、偏回帰係数の符号は逆になる。 tibble(Covariate = mod_exp$covar, &quot;Coef(exp)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_exp))[1:7], &quot;Exp(Coef_exp)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_exp)))[1:7], &quot;Coef(wei)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_wei))[1:7], &quot;Exp(Coef_wei)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_wei))[1:7]), &quot;Coef(gam)&quot; = sprintf(&quot;%.3f&quot;,-coef(mod_gam))[3:9], &quot;Exp(Coef_gam)&quot; = sprintf(&quot;%.3f&quot;,exp(-coef(mod_gam)))[3:9]) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;指数分布&quot;,&quot;ワイブル&quot;,&quot;ガンマ&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較2&quot;) .cl-4cc144aa{}.cl-4cba6978{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4cbd64fc{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4cbd7ad2{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cbd7ad3{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4cbd7adc{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表3.3: 各モデルの推定値の比較2 指数分布ワイブルガンマCovariateCoef(exp)Exp(Coef_exp)Coef(wei)Exp(Coef_wei)Coef(gam)Exp(Coef_gam)fin-0.3660.693-0.3820.6820.2831.327age-0.0560.946-0.0570.9440.0391.040race0.3051.3570.3161.371-0.2390.787wexp-0.1470.864-0.1500.8610.1341.143mar-0.4270.652-0.4370.6460.3421.408paro-0.0830.921-0.0830.9210.0571.059prio0.0861.0890.0921.097-0.0670.935 ガンマ分布モデルでは、指数変換されたExp(Coef_gam)は事象が起きるまでの時間のとして解釈できる。例えば、経済的支援(fin)の偏回帰係数を指数変換した値は1.327だが、これは経済的支援を受けた元服役囚の方がそうでない元服役囚よりも再犯までの時間が32.7%長くなることを表す。 ガンマ分布以外の分布のモデルはehaパッケージのaftreg()関数か、ガンマ分布と同様にflexsurvreg()関数で実行できる。aftreg()の方がStataなどと符号が同じなので使いやすそう？ ## 対数正規分布 mod_lnorm &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;lognormal&quot;) mod_lnorm2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;lognormal&quot;) ## 対数ロジスティックモデル mod_llog &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;loglogistic&quot;) mod_llog2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;llogis&quot;) ## ワイブル分布 mod_wei_acc &lt;- aftreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) mod_wei_acc2 &lt;- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = &quot;weibull&quot;) ## flexsurvreg関数で比例ハザードモデルのワイブル回帰モデルをおこなうときは、`dist = &quot;weibullPH&quot;`とする。 モデルから推定されたハザード関数は以下のようになる(図3.3)。 as.ggplot(~plot(mod_lnorm, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log normal&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_llog, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log logistic&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_wei_acc, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;Weibull model (AFT)&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03))) 図3.3: モデルから推定されたハザード関数 3.4 適合度の評価 たくさんのモデルがあるが、どのモデルが最も妥当なモデルといえるだろうか?以下では、まったく同じデータを使用しているモデルに限ってその比較方法を見ていく。 1つの目の方法としては、推定されたモデルの対数尤度(= 推定したモデルから観測データが得られる確率の対数)を比較することである。対数尤度は大まかにいえば、推定したモデルが観測データにどの程度当てはまっているかを表す。対数尤度は通常負の値をとるので-2をかけて比較することが多く、小さいほど当てはまりがよい。これはモデルの逸脱度と呼ばれる。 表3.4は各モデルの逸脱度(対数尤度の-2倍)を表したものである。表からわかるように、ワイブル回帰モデルが最も当てはまりが良いが、対数ロジスティックモデルやガンマ分布モデルとの差は大きくない。前述したように、アルモデルが別のモデルの特殊なケースであり、一方が他方の「入れ子構造」になっている場合は尤度比検定で適合度の検定を行うこともできる。 tibble(model = c(&quot;ガンマ分布&quot;, &quot;対数正規分布&quot;, &quot;対数ロジスティック分布&quot;, &quot;ワイブル回帰&quot;, &quot;ゴンぺルツ回帰&quot;, &quot;指数回帰&quot;), 逸脱度 = c(-2*mod_gam$loglik,-2*mod_lnorm$loglik[[2]], -2*mod_llog$loglik[[2]], -2*mod_wei$loglik[[2]], -2*mod_gom$loglik[[2]],-2*mod_exp$loglik[[2]])) %&gt;% kable(caption = &quot;各モデルの逸脱度&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.4: 各モデルの逸脱度 model 逸脱度 ガンマ分布 1360.011 対数正規分布 1366.469 対数ロジスティック分布 1359.877 ワイブル回帰 1359.833 ゴンぺルツ回帰 1362.279 指数回帰 1372.732 対数尤度を適合度の指標として用いる問題点は、推定するパラメータの数が多ければ多いほど対数尤度が高くなってしまうことである9。そこで、その特性を修正するためにパラメータ数による影響を取り除いたものがAIC(赤池情報量規準)やBIC(ベイズ情報量規準)である。なお、\\(L\\)はモデルの対数尤度を、\\(k\\)はパラメータ数を、\\(n\\)はデータ数を表す。\\(log(n)\\)は通常2より大きいので、BICのほうがよりパラメータの数の影響を強く修正している。これらいずれもは予測の良さを重視した指標で、いずれも小さいほど予測がいいことを表す。 \\[ \\begin{align} AIC &amp;= -2log(L) + 2k\\\\ BIC &amp;= -2log(L) +klog(n) \\end{align} \\] AICとBICは以下の自作関数で容易に求められる。 AICreg &lt;- function(mod, k = 2){ if(class(mod) == &quot;flexsurvreg&quot;){ loglik &lt;- mod_gam$loglik n_parameters &lt;- mod$npars AIC &lt;- -2*loglik + k*n_parameters }else{ loglik &lt;- mod$loglik[[2]] n_parameters &lt;- nrow(mod$var) AIC &lt;- -2*loglik + k*n_parameters } return(AIC) } BICreg &lt;- function(mod){ if(class(mod) == &quot;flexsurvreg&quot;){ loglik &lt;- mod_gam$loglik n_parameters &lt;- mod$npars N = nrow(mod$data$Y) BIC &lt;- -2*loglik + n_parameters*log(N) }else{ loglik &lt;- mod$loglik[[2]] n_parameters &lt;- nrow(mod$var) N = mod$n BIC &lt;- -2*loglik + n_parameters*log(N) } return(BIC) } 各モデルのAICとBICを記したのが表3.5である。いずれにおいても、ワイブル回帰モデルの適合度が最も高く、その次に対数ロジスティックモデルの適合度が高いことが分かる。 list_mod &lt;- list(mod_gam, mod_lnorm, mod_llog, mod_wei, mod_gom, mod_exp) tibble(model = c(&quot;ガンマ分布&quot;, &quot;対数正規分布&quot;, &quot;対数ロジスティック分布&quot;, &quot;ワイブル回帰&quot;, &quot;ゴンぺルツ回帰&quot;, &quot;指数回帰&quot;), AIC = map_dbl(list_mod, AICreg), BIC = map_dbl(list_mod, BICreg)) %&gt;% kable(caption = &quot;各モデルのAICとBIC&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表3.5: 各モデルのAICとBIC model AIC BIC ガンマ分布 1378.011 1414.627 対数正規分布 1384.469 1421.085 対数ロジスティック分布 1377.877 1414.493 ワイブル回帰 1377.833 1414.449 ゴンぺルツ回帰 1380.279 1416.895 指数回帰 1388.732 1421.279 両者のモデルから推定されるハザード率を再度図示すると以下のようになる。ワイブル回帰モデルはハザード率が単調増加なのに対し、対数ロジスティックモデルは途中まではハザード率が上昇するものの、その後低下していることが分かる。今回のデータの期間(52週)はハザード率が減少に転じるほど十分に長くはなかったため、ワイブル回帰モデルの方が適合度が高くなったのかもしれない。 as.ggplot(~plot(mod_wei, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;weibull&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03)))+ as.ggplot(~plot(mod_llog, fn = &quot;haz&quot;, xlab = &quot;week&quot;, ylab = &quot;hazard rate&quot;, main = &quot;log logistic&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;, ylim = c(0,0.03))) 3.5 観察されない異質性の原因 個体のハザード率が期間を通して一定であっても、独立変数では説明しきれない個体間の異質性によって、時間とともにハザード率が減少する傾向があることが知られている。これは、一般的にハザード率が高い個体は早い段階で事象を経験してリスク集合から抜けていくため、時間が経過するにつれてハザード率の低い個体がリスク集合に残りやすい傾向があるためである。このとき、ハザード率が時間の減少と共に本当に減少しているのか、それとも個体の異質性によってハザード率が低下しているのかを区別するのは難しい10。このように、一般に時間がハザード率に与える影響を検討する際には十分な注意が必要である。 個体の異質性に対処する最も良い方法は、個体の異質性をもたらす要因を独立変数としてモデルに明示的に入れることである。しかし、こうした要因をすべて測定することは現実的ではない。この問題を解決するため、異質性の原因を誤差項に含めるパラメトリックなモデル(= frailty model)が提案されている。例えば、ランダムな誤差項を持つワイブル回帰モデルは以下のように定式化できる(式(3.9))。理論的には、これによって時間がハザード率に与える影響と、個体の異質性による影響を区別することができる。 \\[ log(h(t)) = b_0 + b_1x_1 + b_2x_2 + clog(t) + e \\tag{3.9} \\] 通常、誤差項\\(e\\)にどのような分布を仮定するかで偏回帰係数の推定値は大きく変わってしまう。一般に、以下の2つの場合を除いてこのモデルを用いることは推奨されない。 分析対象が繰り返し事象を経験する場合 分析対象をいくつかの大きなグループに分けることができ、同じグループに属するすべての個体の\\(e\\)が同じだと仮定できる場合。 3.6 なぜパラメトリックモデルを用いるのか 次章では最も一般的な手法であるコックス比例ハザードモデルを扱うが、パラメトリックモデルはコックス比例ハザードモデルよりも優れた特徴が二つある。ただし、多くのパッケージで時間依存の独立変数を扱うことができないという弱点もある。 「左側打ち切り」と「区間打ち切り」を扱うのが容易 左側打ち切り: すでに事象を経験したが、それがいつか分からない場合 区間打ち切り: 事象が二つの時点の間に発生したことはわかっているが、それがいつか正確にわからない場合 予測値の推定が優れている 次章の発生までの予想時間、事象発生までの時間の中央値や分位点、事象の確率分布などあらゆる推定が可能である。 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 指数分布が分からない方はこちら。↩︎ ゴンぺルツ分布が分からない方はこちら。↩︎ ワイブル分布が分からない方はこちら。↩︎ 自作関数はこちらのサイトを参考にした。↩︎ このあたりの説明やAICについては 久保 (2012) が分かりやすい。↩︎ 他方で、時間の経過とともにハザード率の上昇が観察されたなら、それはかなりの個体で実際にハザード率が時間とともに増加していると考えてよい。↩︎ "],["Chapter4.html", "4 コックス回帰モデル 4.1 比例ハザードモデル 4.2 時間に依存する独立変数を含むコックス回帰 4.3 比例ハザード性の仮定の検討と修正 4.4 観測期間の選択 4.5 コックス・モデルによる予測", " 4 コックス回帰モデル 前章(3)で解説したパラメトリックモデルは非常に有効である一方で以下の2点の欠点もあった。 最も適切な分布を決めなくてはならず、それがしばしば難しい 時間依存的な独立変数を使うことができない コックスの比例ハザードモデル(Cox, 1972) (コックス回帰モデル)はこうした欠点をどちらも解決してくれる優れた分析手法である。 4.1 比例ハザードモデル 4.1.1 モデルの概要 コックス回帰モデルはこれまで説明したパラメトリックな比例ハザードモデルを一般化したものといえる。ひとまず、非時間依存な独立変数2つを持つモデルを考えると、比例ハザードモデルは以下のように書ける(式(4.1))。ここで、\\(a(t)\\)は時間の関数であり、どんな形でもよい。この形を一定の形に決める必要がないので、このモデルはしばしば「セミパラメトリック」なモデルと呼ばれる11。 \\[ log(h(t)) = a(t) + b_1x_1 + b_2x_2 \\tag{4.1} \\] 任意の時間\\(t\\)に対して、個体\\(i\\)と\\(j\\)のハザード比(\\(h_i(t)/h_j(t)\\))の値が一定なので比例ハザードモデルといわれている。個体Aのハザード率を\\(h_A(t)\\)、個体\\(B\\)のハザード率を\\(h_B(t)\\)とするとき、式(4.1)より以下のように導ける。このように、ハザード比は\\(t\\)に依らず一定になる。 \\[ \\begin{align} \\frac{h_A(t)}{h_B(t)} &amp;= \\frac{exp(a(t) + b_1x_{1A} + b_2x_{2A})}{exp(a(t) + b_1x_{1A} + b_2x_{2B})}\\\\ &amp;= \\frac{e^{a(t)} \\times e^{b_1} \\times e^{x_{1A}} \\times e^{b_2} \\times e^{x_{2A}}}{e^{a(t)} \\times e^{b_1} \\times e^{x_{1B}} \\times e^{b_2} \\times e^{x_{2B}}}\\\\ &amp;= \\frac{e^{x_{1A}+x_{2A}}}{e^{x_{1B}+x_{2B}}} \\end{align} \\] 第3章のパラメトリックなモデルはコックス回帰モデルの特殊例である。\\(a(t)\\)が定数なら指数分布モデル、\\(a(t) = ct\\)ならワイブル回帰モデルになる。\\(a(t)\\)はいかなる形も取れるので、例えば以下のような4次の多項式にすることもできる(式(4.2))。 \\[ a(t) = a_0 + a_1t + a_2t^2 + a_3t^3 + a_4t^4 \\tag{4.2} \\] 4.1.2 部分尤度法 コックス回帰モデルでは部分尤度法と呼ばれる方法でパラメータの推定を行う。この方法では、尤度関数を偏回帰係数(\\(b_1,b_2\\))のみを含む部分と偏回帰係数と関数\\(a(t)\\)の両方を含む部分に分解し、前者のみに着目して通常のパラメータ推定を行う。つまり、時間\\(t\\)に依存する部分を無視して偏回帰係数のみを推定できるのである。部分尤度法では正確な事象の発生時間ではなく、事象の発生順序のみに基づいて推定が行われるため、時間を二乗したり整数倍しても推定結果は変わらない。詳しい解説は Allison (2014) を参照。 4.1.3 Rによる実装 第3章で分析した元服役囚の再犯データにコックス回帰モデルを当てはめる。分析には、survivalパッケージのcoxph()関数を使用する。 mod_cox &lt;- coxph(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid) 結果は以下の通り。係数の推定値自体はワイブル回帰モデルとほとんど変わらない(表3.3参照)。指数変換された標準偏回帰係数はパラメトリックなモデルと同様にハザード比として解釈できる。例えば、経済的支援を受けた元服役囚は受けてない元服役囚よりも再犯の可能性が約32%低下することが分かる。 mod_cox ## Call: ## coxph(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = recid) ## ## coef exp(coef) se(coef) z p ## fin -0.37942 0.68426 0.19138 -1.983 0.04742 ## age -0.05744 0.94418 0.02200 -2.611 0.00903 ## race 0.31390 1.36875 0.30799 1.019 0.30812 ## wexp -0.14980 0.86088 0.21222 -0.706 0.48029 ## mar -0.43370 0.64810 0.38187 -1.136 0.25606 ## paro -0.08487 0.91863 0.19576 -0.434 0.66461 ## prio 0.09150 1.09581 0.02865 3.194 0.00140 ## ## Likelihood ratio test=33.27 on 7 df, p=2.362e-05 ## n= 432, number of events= 114 survminerパッケージのggforest()関数で結果を図示することもできる(図4.1)。推定されたハザード比と95%信頼区間、検定結果が示されている。 ggforest(mod_cox) 図4.1: mod_coxで推定されたハザード比 4.2 時間に依存する独立変数を含むコックス回帰 4.2.1 モデルの概要 コックス回帰モデルは時間依存的な独立変数を含むモデルに拡張できる(式(4.3))。 \\[ log(h(t)) = a(t) + b_1x_1 + b_2x_2(t) \\tag{4.3} \\] 独立変数の値の変化とそれがハザード率に与える影響の間にタイムラグがある場合は、例えば以下のように1週間前の値を独立変数にするようにモデリングすることもできる(式(4.4))。 \\[ log(h(t)) = a(t) + b_1x_1 + b_2x_2(t-1) \\tag{4.4} \\] 4.2.2 Rでの実装 再犯データのモデルの独立変数に、各週の就業状況(work)を加えてモデリングを行う。Rで分析を行う際には、それぞれの人の各週のデータすべてが1行ずつあるようなデータフレームを作成する必要がある。 recid %&gt;% rownames_to_column(var = &quot;id&quot;) %&gt;% ### 就業状態を一列に pivot_longer(cols = work1:work52, names_to = &quot;work_week&quot;, values_to = &quot;work&quot;, values_drop_na = TRUE) %&gt;% arrange(id) %&gt;% group_by(id) %&gt;% ## 各行データの観察開始時点 mutate(start = 1:n() -1) %&gt;% ## 各行データの観察終了時点(何週目か) mutate(stop = 1:n()) %&gt;% ## 再犯があった州のarrestのみを1にして、そのほかは0にする mutate(arrest = ifelse(arrest == 1 &amp; week == stop,1,0)) %&gt;% ##1週前の就業状態 mutate(worklag = lag(work,1))-&gt; recid_long それでは、時間依存変数を含んだコックス回帰モデルを実行する。まずは式(4.3)のモデルを推定する。従属変数は、Surv(start, stop, arrest)となる点に注意。 mod_cox_ti &lt;- coxph(Surv(start, stop, arrest) ~ fin + age + race + wexp + mar + paro + prio + work, data = recid_long) 結果は以下の通り。 mod_cox_ti ## Call: ## coxph(formula = Surv(start, stop, arrest) ~ fin + age + race + ## wexp + mar + paro + prio + work, data = recid_long) ## ## coef exp(coef) se(coef) z p ## fin -0.35672 0.69997 0.19113 -1.866 0.06198 ## age -0.04634 0.95472 0.02174 -2.132 0.03301 ## race 0.33866 1.40306 0.30960 1.094 0.27402 ## wexp -0.02555 0.97477 0.21142 -0.121 0.90380 ## mar -0.29375 0.74546 0.38303 -0.767 0.44314 ## paro -0.06421 0.93781 0.19468 -0.330 0.74156 ## prio 0.08514 1.08887 0.02896 2.940 0.00328 ## work -1.32832 0.26492 0.25072 -5.298 1.17e-07 ## ## Likelihood ratio test=68.65 on 8 df, p=9.114e-12 ## n= 19809, number of events= 114 ggforest()関数によって図示した結果が図4.2である。 ggforest(mod_cox_ti) 図4.2: mod_coxで推定されたハザード比 続いて、式(4.4)のモデルを推定する。workの代わりにworklagを説明変数に入れる。 mod_cox_tlag &lt;- coxph(Surv(start, stop, arrest) ~ fin + age + race + wexp + mar + paro + prio + worklag, data = recid_long) 結果は以下の通り。 mod_cox_tlag ## Call: ## coxph(formula = Surv(start, stop, arrest) ~ fin + age + race + ## wexp + mar + paro + prio + worklag, data = recid_long) ## ## coef exp(coef) se(coef) z p ## fin -0.35130 0.70377 0.19181 -1.831 0.067035 ## age -0.04977 0.95144 0.02189 -2.274 0.022969 ## race 0.32147 1.37915 0.30912 1.040 0.298369 ## wexp -0.04764 0.95348 0.21323 -0.223 0.823207 ## mar -0.34476 0.70839 0.38322 -0.900 0.368310 ## paro -0.04710 0.95399 0.19630 -0.240 0.810375 ## prio 0.09199 1.09635 0.02880 3.194 0.001402 ## worklag -0.78689 0.45526 0.21808 -3.608 0.000308 ## ## Likelihood ratio test=47.16 on 8 df, p=1.43e-07 ## n= 19377, number of events= 113 ## (432 observations deleted due to missingness) ggforest()関数によって図示した結果が図4.3である。 ggforest(mod_cox_tlag) 図4.3: mod_coxで推定されたハザード比 4.2.3 モデルの比較 推定した3つのモデルの推定値をまとめたものが表4.1である。推定結果自体は非常によく似ているが、先ほどの検定結果を見ると経済的支援の効果は時間依存変数を含まない基本モデルのみで有意になっている。また、時間依存変数の就業状態(workまたはworklag)が他の変数よりも大きな影響を与えていたことも分かった。、2つ目のモデルのハザード比(Exp(Coef) = 0.265)をみると就業している元服役囚の再犯率が就業していない服役囚の26.5%であると推定された。 ただし、この結果のみでは就業状態が再犯に影響したのか、再犯が就業状態に影響したのかはわからない。そこで、就業状態に1週間のラグがあるモデル3の結果を見ると、2つ目のモデルより効果量は減少するものの、依然として大きな影響を及ぼしていることが分かる。モデル3のハザード比(Exp(Coef) = 0.455)から、就業状態にある元服役囚はそうでない元服役囚に比べて翌週の再犯率が約54.5%低いことが分かる。このように、タイムラグを持つ変数を用いることで再犯が就業状態に影響する可能性を除外することができる。 tibble(Covariate = rownames(mod_cox_ti$coefficients %&gt;% data.frame()), &quot;Coef(basic)&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_cox))[1:7],NA), &quot;Exp(Coef_basic)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_cox)))[1:7],NA), &quot;Coef(ti)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_cox_ti))[1:8], &quot;Exp(Coef_ti)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_ti)))[1:8], &quot;Coef(tlag)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_cox_tlag))[1:8], &quot;Exp(Coef_tlag)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_tlag))[1:8])) %&gt;% mutate(Covariate = ifelse(str_detect(Covariate,&quot;work&quot;),&quot;work/worklag&quot;,Covariate)) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;基本モデル&quot;,&quot;時間依存独立変数\\nあり&quot;, &quot;タイムラグのある\\n時間独立変数あり&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-8b5576bc{}.cl-8b4e85d2{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-8b5193da{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-8b51a8de{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-8b51a8df{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-8b51a8e8{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表4.1: 各モデルの推定値の比較 基本モデル時間依存独立変数ありタイムラグのある時間独立変数ありCovariateCoef(basic)Exp(Coef_basic)Coef(ti)Exp(Coef_ti)Coef(tlag)Exp(Coef_tlag)fin-0.3790.684-0.3570.700-0.3510.704age-0.0570.944-0.0460.955-0.0500.951race0.3141.3690.3391.4030.3211.379wexp-0.1500.861-0.0260.975-0.0480.953mar-0.4340.648-0.2940.745-0.3450.708paro-0.0850.919-0.0640.938-0.0470.954prio0.0911.0960.0851.0890.0921.096work/worklag-1.3280.265-0.7870.455 4.2.4 データに欠損がある場合の補完と加工 時間依存独立変数があるモデルの推定をするとき、ある時点で事象が発生した場合、その時点で事象を経験しうるすべての個体について時間依存変数の値が分かっていなければいけない。例えば、\\(t =10\\)で事象が発生し、その時点で15人が事象を経験する可能性がある(= リスク集合にいる)場合、15人全員について\\(t=10\\)時点の時間依存変数が分かっていなければいけない。そのため、事象の発生が日単位で測定されているにもかかわらず、時間依存変数の値が1週間ごとにしか測定されていないといったことがあるとき、問題が生じることになる。 このような場合、特定の方法で事象が発生した時点の独立変数の値を補完して代入する必要がある。いろいろな方法があるが、最も安全なものは直前に観察された値を使用する方法である。保管によって必要な代入ができたら、次に分析のためにデータを加工する必要がある。加工方法には以下の2つがあるが、統計ソフトではいずれかを使用している(Rはエピソード分割法)。どちらも選べるならば後者の方が望ましい。 4.2.4.1 プログラミング・ステートメント法(programming statements method) この方法を使用するには、データをワイド形式にする必要がある。すなわち、今回の例では各週の就業状態が1列ずつになるようにする必要がある。 4.2.4.2 エピソード分割法(episode splitting method) この方法のデータは先ほど加工したrecid_longのようにロング形式で問題ない。それぞれの個体が複数の行を持ち、各行のデータについて観察し始めた時点(start)と観察が終了した時点(stop)を記した列を作る。また独立変数が変化するたびに行を変えるか、もしくは独立変数の変化に関係なく小さな時間間隔ごとに行を変える(どちらでも問題ない)。例えばrecid_longでは各個体が1週間ごとに1行ずつのデータを持つ。 recid_long %&gt;% head(50) %&gt;% datatable(options = list(scrollX = 20)) 4.3 比例ハザード性の仮定の検討と修正 4.3.1 シェーンフィールド残差を用いた検討 コックス回帰モデルの仮定として、どの時点でも2個体のハザード比が一定であるとする「比例ハザード性」があった。この仮定が満たされないときはどのようなときだろうか? ハザード比が一定になるのは、ハザード率の対数に対して各独立変数の影響が全ての時点で同じときである。そのため、時間と独立変数に交互作用があるときはハザード率の比は一定にならない。式(4.5)はその一例である。この式で独立変数\\(x\\)がハザード率の対数に与える影響は\\(b + ct\\)なので、時間と共に増加/減少する。 \\[ log(h(t)) = a(t) + bx + cxt \\tag{4.5} \\] 比例ハザード性を検討する方法はいくつかあるが、最も簡便なものはシェーンフィールド残差を用いる方法である。子の残差は独立変数の一つ一つに対して研鑽され、比例ハザード性が満たされるならば時間、あるいは時間の関数と相関がない。 Rでシェーンフィールド残差を調べるためには、以下のようなコードを実行する。ここでは、2つ目のモデル(mod_cox_ti)について分析を行う。chisqの列には「相関係数が0である」を帰無仮説とする検定を行った際のカイ二乗値が、pにはp値が示されている。年齢(age)はp値が0.05を下回っており、比例ハザード性の仮定を満たしていない可能性が示唆された。一番下には「全ての相関係数が0である」を帰無仮説とする包括的検定(GLOBAL)が行われており、これも5%水準で有意である。 cox.zph(mod_cox_ti, transform = &quot;identity&quot;) ## chisq df p ## fin 0.0143 1 0.905 ## age 6.5021 1 0.011 ## race 1.9489 1 0.163 ## wexp 3.5032 1 0.061 ## mar 0.8508 1 0.356 ## paro 0.0118 1 0.913 ## prio 0.3363 1 0.562 ## work 0.1972 1 0.657 ## GLOBAL 17.1128 8 0.029 survminerパッケージのggcoxzphをもちいて視覚的に仮定をチェックすることもできる(図4.4)。 ggcoxzph(cox.zph(mod_cox_ti, transform = &quot;identity&quot;) ) 図4.4: 各独立変数の比例ハザード性のチェック なお、比例ハザード性が満たされるためには実際は時間そのものだけではなく、時間の関数(時間の対数や順位、および事象が発生した時間の累積分布関数の推定値など)とも無相関である必要である。Rでは、時間の順位と、Kaplan-meiyer法による生存確率の推定値(後述)との相関も調べることができる。結果はほとんど変わらない。 ## 時間 cox.zph(mod_cox_ti, transform = &quot;rank&quot;) ## chisq df p ## fin 0.0181 1 0.8929 ## age 6.7334 1 0.0095 ## race 1.9342 1 0.1643 ## wexp 3.3284 1 0.0681 ## mar 0.8976 1 0.3434 ## paro 0.0166 1 0.8975 ## prio 0.2838 1 0.5942 ## work 0.1756 1 0.6752 ## GLOBAL 17.1526 8 0.0286 ## 生存確率の推定値 cox.zph(mod_cox_ti, transform = &quot;km&quot;) ## chisq df p ## fin 9.58e-04 1 0.975 ## age 5.89e+00 1 0.015 ## race 1.87e+00 1 0.171 ## wexp 3.83e+00 1 0.050 ## mar 8.29e-01 1 0.363 ## paro 5.64e-03 1 0.940 ## prio 4.27e-01 1 0.514 ## work 2.50e-01 1 0.617 ## GLOBAL 1.66e+01 8 0.034 4.3.2 仮定が満たされないときの修正 4.3.2.1 時間との交互作用をモデルに加える 仮定が満たされないときの解決策の一つは独立変数と時間の交互作用を含んだ式(4.5)のようなモデルを推定することである。コックス回帰モデルのすばらしさは、このように比例ハザード性を持たないモデルを柔軟に修正できる点である。ここでは、p値が0.1以下だった年齢(age)と過去の就業経験(wexp)について各データポイント時点の週(stop)との交互作用を入れたモデルを検討する。 mod_cox_int &lt;- coxph(Surv(start, stop, arrest) ~ fin + age + race + wexp + mar + paro + prio + work + age:stop + wexp:stop, data = recid_long) 結果は以下の通りである。いずれの交互作用も有意な影響を持っていることが分かる。 mod_cox_int ## Call: ## coxph(formula = Surv(start, stop, arrest) ~ fin + age + race + ## wexp + mar + paro + prio + work + age:stop + wexp:stop, data = recid_long) ## ## coef exp(coef) se(coef) z p ## fin -0.361738 0.696465 0.190891 -1.895 0.058093 ## age 0.085368 1.089118 0.040598 2.103 0.035484 ## race 0.305627 1.357476 0.309442 0.988 0.323313 ## wexp -1.209155 0.298449 0.481342 -2.512 0.012003 ## mar -0.233974 0.791382 0.383910 -0.609 0.542226 ## paro -0.063033 0.938913 0.194910 -0.323 0.746398 ## prio 0.080920 1.084284 0.028951 2.795 0.005188 ## work -1.318052 0.267656 0.251332 -5.244 1.57e-07 ## age:stop -0.005091 0.994922 0.001541 -3.304 0.000952 ## wexp:stop 0.041276 1.042139 0.014512 2.844 0.004451 ## ## Likelihood ratio test=83.62 on 10 df, p=9.751e-14 ## n= 19809, number of events= 114 交互作用項については、一般化線形モデルなどと同様に解釈することができる12。式(4.5)を書き換えると以下のように書ける。 \\[ log(h(t)) = a(t) + (b+ct)x \\] ここからわかるように、独立変数\\(x\\)が1増えると、ハザード関数の対数は\\(b+ct\\)増える。つまり、\\(x\\)の「効果」は時間の線形関数になっていて、\\(t=0\\)のときは\\(b\\)でそこから時間が１単位増えるごとに効果が\\(c\\)ずつ増えていくということになる。例えば先ほどの推定結果から、就業経験の有無の効果は\\(-1.21 + 0.041 \\times t\\)となり、効果が1週ごとに\\(0.041\\)ずつ増加することが分かる。表4.2は、出所時の年齢(age)と就業経験の有無(wexp)の効果が時間がたつにつれてどのように変化すると推定されたかを示している。例えばwexpについては、出所直後は就業経験があるとない場合に比べてハザード率が29.8%になることが分かるが、50週後にはむしろ就業経験があるとない場合に比べてハザード比が235%上昇することが分かり、このような効果の逆転は30週くらいで起こっていることが分かる。 tibble(t = seq(0,50,10), `偏回帰係数\\n(b + ct)` = sprintf(&quot;%.3f&quot;,mod_cox_int$coefficients[[2]] + mod_cox_int$coefficients[[9]]*t), `Exp(b+ct)` = sprintf(&quot;%.3f&quot;, exp(mod_cox_int$coefficients[[2]] + mod_cox_int$coefficients[[9]]*t)), `偏回帰係数\\n(b + ct) ` = sprintf(&quot;%.3f&quot;, mod_cox_int$coefficients[[4]] + mod_cox_int$coefficients[[10]]*t), `Exp(b+ct) ` = sprintf(&quot;%.3f&quot;, exp(mod_cox_int$coefficients[[4]] + mod_cox_int$coefficients[[10]]*t))) %&gt;% rename(`出所して\\nからの週(t)` = t) %&gt;% flextable() %&gt;% width(width = 2/2) %&gt;% add_header_row(colwidth = c(1,2,2), values = c(&quot;&quot;,&quot;出所時の年齢&quot;,&quot;就業経験の有無&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;モデルから推定された交互作用項を含む偏回帰係数&quot;) .cl-9b607fe8{}.cl-9b59de40{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9b5c95d6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9b5cae2c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9b5cae36{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9b5cae37{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表4.2: モデルから推定された交互作用項を含む偏回帰係数 出所時の年齢就業経験の有無出所してからの週(t)偏回帰係数(b + ct)Exp(b+ct)偏回帰係数(b + ct) Exp(b+ct) 00.0851.089-1.2090.298100.0341.035-0.7960.45120-0.0160.984-0.3840.68130-0.0670.9350.0291.03040-0.1180.8880.4421.55650-0.1690.8440.8552.350 交互作用モデルでは、全ての独立変数についてモデルのシェーンフィールド残差と時間の相関がなくなっていることが分かる。 cox.zph(mod_cox_int) ## chisq df p ## fin 0.0290 1 0.86 ## age 2.4002 1 0.12 ## race 1.5400 1 0.21 ## wexp 2.6158 1 0.11 ## mar 0.6847 1 0.41 ## paro 0.1608 1 0.69 ## prio 0.0111 1 0.92 ## work 0.2701 1 0.60 ## age:stop 0.4199 1 0.52 ## wexp:stop 1.5229 1 0.22 ## GLOBAL 6.6780 10 0.76 交互作用モデルの欠点は、交互作用項をパラメトリックな特定の形で定式化する必要がある点である。ただし、これまで時間と独立変数は一次の線形関係にあるとしていたが、代わりに時間の二乗や対数変換した時間をモデルに含めることも可能である。 4.3.2.2 層化(stratification) もう一つの方法が層化という方法で、就業経験のような離散的な変数が比例ハザード性を満たさないときに使える。 例えば就業経験について層化を行うとすると、就業経験のある元服役囚のデータのみを含むモデルと、就業経験のない元服役囚のデータのみを含むモデルの2つを考える。いずれも同じ偏回帰係数を持つが、時間の関数の形が異なる。時間tにおける就業経験の効果は\\(a_1(t) - a_2(t)\\)であり、いかなる制約も比例ハザード性も仮定していない。しかし、部分尤度法を用いる以上これを推定することはできない。 \\[ \\begin{aligned} 就業経験あり: log(h(t)) &amp;= a_1(t) + b_1x_1 + b_2x_2 + ...\\\\ 就業経験なし: log(h(t)) &amp;= a_2(t) + b_1x_1 + b_2x_2 + ... \\end{aligned} \\] 層化モデルは、Rで以下のように実行できる。 mod_cox_str &lt;- coxph(Surv(start, stop, arrest) ~ fin + age + race + mar + paro + prio + work + strata(wexp), data = recid_long) 結果は以下の通り。層化したことで、就業経験の偏回帰係数がなくなる。このように、層化するとその独立変数の効果は推定できなくなる。 mod_cox_str ## Call: ## coxph(formula = Surv(start, stop, arrest) ~ fin + age + race + ## mar + paro + prio + work + strata(wexp), data = recid_long) ## ## coef exp(coef) se(coef) z p ## fin -0.35910 0.69831 0.19121 -1.878 0.06038 ## age -0.04766 0.95346 0.02192 -2.174 0.02969 ## race 0.34453 1.41133 0.30963 1.113 0.26583 ## mar -0.30368 0.73810 0.38355 -0.792 0.42850 ## paro -0.06255 0.93937 0.19477 -0.321 0.74811 ## prio 0.08419 1.08784 0.02905 2.898 0.00375 ## work -1.32825 0.26494 0.25091 -5.294 1.2e-07 ## ## Likelihood ratio test=59.08 on 7 df, p=2.307e-10 ## n= 19809, number of events= 114 交互作用モデルと層化モデルの偏回帰係数を比較したのが表4.3である。推定結果に少し違いがみられる。 tibble(Covariate = rownames(mod_cox_int$coefficients %&gt;% data.frame()), &quot;Coef(int)&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_cox_int))[1:10]), &quot;Exp(Coef_int)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_int)))[1:10]), &quot;Coef(str)&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_cox_str))[1:3], &quot;-&quot;,sprintf(&quot;%.3f&quot;,coef(mod_cox_str))[4:7],NA,NA), &quot;Exp(Coef_str)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_str)))[1:3], &quot;-&quot;, sprintf(&quot;%.3f&quot;,exp(coef(mod_cox_str)))[4:7],NA,NA)) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2), values = c(&quot;&quot;,&quot;時間との交互作用モデル&quot;,&quot;層化モデル&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-889ff0d2{}.cl-88993e9a{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-889c17b4{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-889c2d80{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-889c2d81{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-889c2d8a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表4.3: 各モデルの推定値の比較 時間との交互作用モデル層化モデルCovariateCoef(int)Exp(Coef_int)Coef(str)Exp(Coef_str)fin-0.3620.696-0.3590.698age0.0851.089-0.0480.953race0.3061.3570.3451.411wexp-1.2090.298--mar-0.2340.791-0.3040.738paro-0.0630.939-0.0630.939prio0.0811.0840.0841.088work-1.3180.268-1.3280.265age:stop-0.0050.995wexp:stop0.0411.042 4.4 観測期間の選択 今回の例では出所した日を観測の起点とするので比較的明確であるが、なかには観測時間の起点がそれほど明確でないデータもある。例えば、今回の再犯データでも個人の年齢や暦上の時間を観測時間の単位とすることも可能である。いずれにしても部分尤度法による推定は行えるが、重要な点はその観測時間の単位が妥当かを考えることである。例えばハザード率が強く年齢に依存しており、そのほかの時間単位にあまり依存していないと考えられるのであれば、年齢を観測時間の単位にすることは適切である。 理論的にはハザード率が二つ以上の時間に依存するモデルを定式化することはできるが、一般に大きなサンプルサイズや特殊な条件が必要である。このような方法が困難な場合は、異なる時間の単位を明示的に独立変数に含めるのが妥当である。今回も年齢(age)を独立変数に含めた。 4.5 コックス・モデルによる予測 第3章で見たように、予測という観点で見るとパラメトリックなモデルが最も優れており、予測が非常に簡単である。一方で、コックス回帰モデルでも限定的であるが予測を行うことはできる。 コックス回帰を用いて主に予測できるのは生存関数(= 時間の経過とともに事象が生じていない確率がどのように変化するかを表す関数)であり、実際に観察された時間の範囲について行える。詳しい推定方法は 杉本 (2021) などにあるが、モデル式の\\(a(t)\\)の部分(通常はそれを対数変換した基準ハザード関数)をノンパラメトリックな方法を用いて推定することが多いようだ。Rで基準ハザード関数がどのように推定されているかについては、こちらのサイトを参照。 生存関数には独立変数の値を指定することができ、これは実際に観測された値でなくても問題ない。例えば、1つ目のモデル(mod_cox)で、経済的支援を受けており、出所時の年齢21歳、黒人で未婚、仮釈放として出所し、就業経験があり、過去に有罪判決を4回受けている人について予測される生存確率は以下のようになる。 survfit(mod_cox, newdata = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4), ## 信頼区間の範囲 conf.int = 0.95) %&gt;% summary(times = c(seq(0,50,5),52)) ## Call: survfit(formula = mod_cox, newdata = tibble(fin = 1, age = 21, ## race = 1, wexp = 1, mar = 0, paro = 1, prio = 4), conf.int = 0.95) ## ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 0 432 0 1.000 0.0000 1.000 1.000 ## 5 428 5 0.989 0.0053 0.979 1.000 ## 10 418 10 0.967 0.0105 0.947 0.988 ## 15 409 10 0.945 0.0151 0.916 0.975 ## 20 397 15 0.911 0.0216 0.869 0.954 ## 25 384 11 0.886 0.0262 0.836 0.939 ## 30 374 9 0.865 0.0298 0.809 0.925 ## 35 365 11 0.839 0.0341 0.775 0.909 ## 40 351 14 0.806 0.0394 0.732 0.887 ## 45 339 10 0.782 0.0430 0.702 0.871 ## 50 325 15 0.746 0.0482 0.658 0.847 ## 52 322 4 0.737 0.0495 0.646 0.840 作図にはsurveminerパッケージのggsurvplot()関数とggsurvfitパッケージのggsurvfit()関数が有用である。結果をggplotオブジェクトとして出力してくれるので、グラフの修飾が容易である。作り方の詳細はパッケージのウェブページを参考にされたし。上記と同じ条件で予測した生存関数を図示したものが図4.5である。なお、塗りつぶし部分は95%信頼区間である。 predict_cox &lt;- survfit(mod_cox, newdata = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4), ## 信頼区間の範囲 conf.int = 0.95) ## ggsurvplot ggsurvplot(predict_cox, data = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4), ## 色 palette = &quot;black&quot;, ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, ggtheme = theme_bw()) -&gt; p1 p1$plot + labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ ggtitle(&quot;ggsurvplot()&quot;)+ theme_bw(base_size = 16)+ theme(legend.position = &quot;none&quot;)+ coord_cartesian(ylim = c(0.64556,1))+ scale_y_continuous(breaks = seq(0.65,1,0.05)) -&gt; p1 ## ggsurvfit ggsurvfit(predict_cox)+ add_confidence_interval()+ labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ ggtitle(&quot;ggsurfit()&quot;)+ theme_bw(base_size = 16)+ scale_y_continuous(breaks = seq(0,1,0.05)) -&gt; p2 p1 + p2 図4.5: モデルから推定された生存曲線 なお、何も指定しない場合、survfit()関数は連続変数は平均値で、二値変数は0で中心化した値を当てはめて予測を行う(図4.6)。 mod_cox$means ## fin age race wexp mar paro prio ## 0.000000 24.597222 0.000000 0.000000 0.000000 0.000000 2.983796 predict_cox2 &lt;- survfit(mod_cox, ## 信頼区間の範囲 conf.int = 0.95) ## ggsurvplot ggsurvplot(predict_cox2, data = recid, ## 色 palette = &quot;black&quot;, ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, ggtheme = theme_bw()) -&gt; p3 p3$plot + labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ theme_bw(base_size = 16)+ theme(legend.position = &quot;none&quot;)+ coord_cartesian(ylim = c(0.64556,1))+ scale_y_continuous(breaks = seq(0.65,1,0.05)) 図4.6: 独立変数を指定しないときにモデルから推定された生存曲線 複数の値を当てはめて生存関数を予測することもできる(図4.7)。ここでは、前科の数prioが0,5,10回のときの予測を行う。 predict_cox3 &lt;- survfit(mod_cox, newdata = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = c(0,5,10)), ## 信頼区間の範囲 conf.int = 0.95) ## ggsurvplot ggsurvplot(predict_cox3, data = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = c(0,5,10)), ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, legend.title = &quot;prio&quot;, legend.labs = c(&quot;0&quot;,&quot;5&quot;,&quot;10&quot;), ggtheme = theme_bw()) -&gt; p4 p4$plot + scale_color_nejm()+ scale_fill_nejm()+ labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ theme_bw(base_size = 16)+ theme(legend.position = &quot;top&quot;)+ coord_cartesian(ylim = c(0.4,1))+ scale_y_continuous(breaks = seq(0,1,0.2)) 図4.7: 独立変数を指定しないときにモデルから推定された生存曲線 時間依存独立変数を持つ場合も同様に予測することができる(図4.8)。 predict_cox_ti &lt;- survfit(mod_cox_ti, newdata = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4, work = c(0,1)), ## 信頼区間の範囲 conf.int = 0.95) ## ggsurvplot ggsurvplot(predict_cox_ti, data = tibble(fin = 1, age = 21, race = 1, wexp = 1, mar = 0, paro = 1, prio = 4, work = c(0,1)), ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, legend.title = &quot;work&quot;, legend.labs = c(0,1), ggtheme = theme_bw()) -&gt; p5 p5$plot + scale_color_nejm()+ scale_fill_nejm()+ labs(x = &quot;week&quot;, y = &quot;survival probability&quot;)+ theme_bw(base_size = 16)+ theme(legend.position = &quot;top&quot;)+ coord_cartesian(ylim = c(0.5,1))+ scale_y_continuous(breaks = seq(0,1,0.05)) 図4.8: 時間依存独立変数をもつモデルから推定された生存曲線 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. Cox, D. R. (1972). Regression models and life-tables. J. R. Stat. Soc., 34(2), 187–202. 杉本知之. (2021). 生存時間解析. 朝倉書店. 粕谷英一. (2012). 一般化線形モデル. 共立出版. 比例ハザードモデルは\\(h(t) = h_0(t) + exp(b_1x_1 + b_2x_2)\\)のように表されることも多い。このとき、\\(h_0(t)\\)は基準ハザード関数(baseline hazard function)と呼ばれ、式(4.1)からわかるように\\(h_0(t) = exp(a(t))\\)である。↩︎ 交互作用の解釈については、 粕谷 (2012) なども参照。↩︎ "],["Chapter5.html", "5 複数事象のモデル 5.1 複数事象の分類 5.2 競合リスク・モデル 5.3 部分分布を用いた競合リスクの分析", " 5 複数事象のモデル これまでの章では、分析対象の事象を全て同じように扱ってきた。例えば、第2章では昇進の種類を区別していないし、第3~4章は再犯の際の犯罪の種類を区別していない。本章では、複数の事象がある場合に分析を行う方法を解説する。基本的には、一種類の事象の場合に解説した方法を応用できる。 5.1 複数事象の分類 まず話を簡単にするために、二種類の事象がある場合のみに限定して事象が発生する状況を分類する。なお、繰り返しのある事象については次章(6)で解説する。 5.1.1 条件付き過程 まず一つ目は条件付き過程であり、次のように定義される。 事象の発生または非発生は一連の因果プロセスによって決定される。ある条件が与えられた後、因果メカニズムによってどの種類の事象が発生するかが決定される。 例としては、携帯電話を購入することを決定した後、iPhoneとAndroidのどちらを購入するかを決定する場合などが挙げられる。こうしたタイプに対して適切な分析は、⓵まずイベント・ヒストリー分析を行って事象の区別をせずに事象の発生だけに着目した分析を行い、⓶どの種類の事象が発生するかを別のモデル(通常は二項ロジットモデルや多項ロジットモデル)で分析する。 5.1.2 並行的過程 5.1.2.1 4つのタイプ 次に考えられるのは並行的過程と呼ばれるタイプのものであり、次の条件を満たす。 それぞれの種類の事象の発生は異なる因果メカニズムによって決定される。 異なる因果メカニズムとは、それぞれの種類の事象の発生が異なる独立変数によって影響されたり、同じ独立変数が事象の種類によって異なる偏回帰係数や線形関数を持っていたりすることを指す。この仮定は、以下の4つの下位タイプに分類できる。 2a. ある種類の事象を経験した個体はほかの種類の事象を経験する可能性がなくなる(= 競合リスク)。 例としては、競合する原因による死亡などが挙げられる。心臓病とがんの両方が原因で死亡する可能性はないので、心臓病が原因で死亡した個体はもはやがんで死亡する可能性がない。 2b. ある種類の事象を経験すると、その個体はほかの種類の事象の観察対象から外れる。 例えば国内移動と国外移動を考えるとき、もし個体が国外移動するとその個体を追跡することが困難になることが珍しくない。 2c. ある一つの種類の事象を経験しても、他の種類の事象を経験する可能性や個体の観察の継続性に影響を与えない。 二つの種類の事象が全く無関係であることはないが、分析する際にあたかも無関係のように扱うことが可能な場合はある。例えば、選挙で投票に行くことと結婚することはほとんど関係がないと仮定できるので、そのように扱える。 2d. ある一つの事象が生じると、ほかの種類の事象を経験する可能性が増大/減少する。 例えば、妊娠すると結婚する可能性が高まる、といった場合がこれに該当する 5.1.2.2 並行的過程のタイプごとの分析 2c それぞれの種類の事象が独立すると仮定できるので、前章までの分析をそれぞれに適用すればよい。 2d 二つ目の事象について検討する際に必ず一つ目についても考慮する必要がある。この方法はすでに前章までに解説しており、要するに一つ目の事象を時間依存的な独立変数として扱ってしまえばよい。例えば元服役囚の再犯の例では、各週ごとに就業しているかを独立変数に加えていた。 2b ある種類の事象の発生によって、他の種類の発生についての右側打ち切りが生じている例である。このタイプは、前章までの方法で分析することができる。すなわち、ある事象を経験することで個体が観察から脱落してしまったら、その時点で打ち切りが生じたかのように扱えばよい。 2a このタイプに対する分析は2bと似ているが、さらに詳しい解説が必要である。次章以降では、こうしたタイプの事象を扱う「競合リスク・モデル」について解説する。 5.2 競合リスク・モデル 5.2.1 モデルの概要 競合リスクのある事象を分析する方法で最も一般的なものは、タイプ固有(type-specific)ハザード関数と呼ばれるものを定義する方法である。\\(m\\)種類の異なる事象があり、\\(j = 1,2,...,m\\)とする。\\(P_j(t,t+s)\\)を陸巣集合に入っている個体が種類\\(j\\)の事象を時点\\(t\\)から\\(t+s\\)の期間で経験する条件付き確率とする。ただし、個体が時点\\(t\\)より前に\\(m\\)個の事象のいずれかを経験していたらリスク集合には入っていないものとする。 タイプ固有ハザード関数は以下のように定義される。各種類の事象に独自のハザード関数が定義される。 \\[ h_j(t) \\lim_{s \\rightarrow 0} \\frac{P_j(t,t+s)}{s} \\] 分析では、タイプ固有のハザード関数一つひとつについてモデルを作ることができる。前章までに説明したイベント・ヒストリーのモデルはどれも競合リスクの分析に用いることができる。次章の種類によって全く異なるモデルを当てはめることも可能である。いずれのモデルでも事象の種類ごとに別々に尤度関数を作り、最尤推定法または部分尤度推定法でパラメータを推定する。 5.2.2 Rでの実装 分析の例として、元服役囚の再犯についての研究を再度取り上げる。再犯で逮捕された犯罪を財産犯(強盗・窃盗など)とそれ以外に分ける。経済的支援は財産犯による再犯のリスクは減らす可能性があるが、それ以外の犯罪には大きく影響するとは考えられない。 ここでは、以下の式のコックス比例ハザードモデルで推定を行う(式(5.1))。いずれの種類の事象にも同じ独立変数を考えるが、偏回帰係数は異なるとしている。 \\[ log(h_j(t)) = a_j(t) + b_{j1}x_1 + b_{j2}x_2 + \\cdots \\tag{5.1} \\] 変数は以下の通り。今回は時間依存変数は含めない。 従属変数に関わるもの - arrest: 再犯の有無 - type: 再犯の種類(0: 再犯なし、1: 非財産犯、2: 財産犯) - arrstday: 再逮捕されたときに出所後何日だったか 独立変数 - fin: 経済的支援の有無 - white: 人種(白人か否か) - edcomb: 教育レベル（学校教育を受けた年数) - married: 出所時の配偶状態(0/1) - age: 出所時の年齢 - male: 性別(0/1) - numarst: 前科の数 - numprop: 過去の財産犯の有罪判決の数 - crimprop: 最後の服役が財産犯によるものか(0/1) - paro: 出所が仮釈放か否か(0/1) データは以下のとおりである。 tarp &lt;- read_dta(&quot;data/tarp.dta&quot;) datatable(tarp, options = list(scrollX = 60)) データを見ると、打ち切りになった個体(type = 0)が598人、非財産犯で逮捕された個体(type = 1)が137人、財産犯で逮捕された個体(type = 2)が197人いたことが分かる(表5.1)。 tarp %&gt;% group_by(type) %&gt;% summarise(N = n()) %&gt;% kable(caption = &quot;財産犯/非財産犯で逮捕された個体数&quot;) %&gt;% kable_styling(font_size = 15, full_width = FALSE) 表5.1: 財産犯/非財産犯で逮捕された個体数 type N 0 598 1 137 2 197 5.2.2.1 事象の種類を区別しないで分析 まず、再犯による逮捕の種類を区別しないモデルを以下のように推定する。これは前章で解説した方法と全く一緒である。 mod_rsk_all &lt;- coxph(Surv(arrstday,arrest) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb, data = tarp) 結果は以下の通り。age、white、numprop、crimprop、numarrst、edcombの影響が5%水準で有意になっている。 mod_rsk_all ## Call: ## coxph(formula = Surv(arrstday, arrest) ~ fin + age + white + ## male + married + paro + numprop + crimprop + numarst + edcomb, ## data = tarp) ## ## coef exp(coef) se(coef) z p ## fin 0.120982 1.128605 0.113735 1.064 0.287456 ## age -0.034417 0.966168 0.008578 -4.012 6.01e-05 ## white -0.240927 0.785899 0.118271 -2.037 0.041643 ## male 0.501650 1.651443 0.309194 1.622 0.104708 ## married -0.221696 0.801159 0.129709 -1.709 0.087418 ## paro -0.211252 0.809570 0.118415 -1.784 0.074425 ## numprop 0.310299 1.363832 0.071903 4.316 1.59e-05 ## crimprop 0.424965 1.529536 0.137179 3.098 0.001949 ## numarst 0.017689 1.017847 0.004638 3.814 0.000137 ## edcomb -0.067607 0.934628 0.025304 -2.672 0.007544 ## ## Likelihood ratio test=85.33 on 10 df, p=4.497e-14 ## n= 932, number of events= 334 ggforest()関数によって図示した結果が図5.1である。 ggforest(mod_rsk_all) 図5.1: mod_rsk_allで推定されたハザード比 5.2.2.2 再犯の種類ごとに分析 それぞれの独立変数は再犯の種類ごとに異なる影響を与えている可能性があるため、財産犯とそうでない再犯に分けて比例ハザードモデルを推定する。財産犯について分析する際は、非財産犯で逮捕された個体は打ち切りとして扱い、非財産犯について分析する際はその逆である。 データフレームに財産犯で再犯を犯した場合は1、それ以外は0とする列を作成する(prop)。非財産犯についても同様の列を作成する(non_prop)。 tarp %&gt;% mutate(prop = ifelse(type == &quot;2&quot;, 1, 0)) %&gt;% mutate(non_prop = ifelse(type == &quot;1&quot;, 1, 0)) -&gt; tarp 5.2.2.2.1 財産犯についての分析 財産犯についてモデリングした結果は以下のとおりである。 mod_rsk_prop &lt;- coxph(Surv(arrstday,prop) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb, data = tarp) mod_rsk_prop ## Call: ## coxph(formula = Surv(arrstday, prop) ~ fin + age + white + male + ## married + paro + numprop + crimprop + numarst + edcomb, data = tarp) ## ## coef exp(coef) se(coef) z p ## fin 0.201143 1.222800 0.149431 1.346 0.178284 ## age -0.041430 0.959416 0.012239 -3.385 0.000712 ## white -0.353086 0.702517 0.155856 -2.265 0.023484 ## male 0.111079 1.117483 0.345574 0.321 0.747881 ## married -0.332356 0.717232 0.177081 -1.877 0.060537 ## paro -0.146924 0.863360 0.153704 -0.956 0.339129 ## numprop 0.318580 1.375173 0.097219 3.277 0.001049 ## crimprop 0.883210 2.418651 0.205986 4.288 1.81e-05 ## numarst 0.018666 1.018841 0.006264 2.980 0.002886 ## edcomb -0.053404 0.947997 0.034110 -1.566 0.117428 ## ## Likelihood ratio test=79.48 on 10 df, p=6.359e-13 ## n= 932, number of events= 197 ggforest()関数によって図示した結果が図5.2である。事象を区別しなかった場合と異なり、教育レベル(edcomb)が5%水準で有意にならなかったが、それ以外は同じ独立変数が有意になり、効果の方向性も変わらなかった。 ggforest(mod_rsk_prop) 図5.2: mod_rsk_propで推定されたハザード比 5.2.2.2.2 非財産犯についての分析 財産犯についてモデリングした結果は以下のとおりである。 mod_rsk_nonprop &lt;- coxph(Surv(arrstday,non_prop) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb, data = tarp) mod_rsk_nonprop ## Call: ## coxph(formula = Surv(arrstday, non_prop) ~ fin + age + white + ## male + married + paro + numprop + crimprop + numarst + edcomb, ## data = tarp) ## ## coef exp(coef) se(coef) z p ## fin 0.007344 1.007371 0.175793 0.042 0.9667 ## age -0.027191 0.973175 0.012037 -2.259 0.0239 ## white -0.077279 0.925632 0.182082 -0.424 0.6713 ## male 1.387656 4.005452 0.714747 1.941 0.0522 ## married -0.073327 0.929297 0.192562 -0.381 0.7034 ## paro -0.302124 0.739246 0.186428 -1.621 0.1051 ## numprop 0.308181 1.360947 0.107084 2.878 0.0040 ## crimprop -0.068915 0.933406 0.192115 -0.359 0.7198 ## numarst 0.016305 1.016438 0.006936 2.351 0.0187 ## edcomb -0.082639 0.920684 0.037831 -2.184 0.0289 ## ## Likelihood ratio test=29.47 on 10 df, p=0.001044 ## n= 932, number of events= 137 ggforest()関数によって図示した結果が図5.3である。age、numprop、numarrst、edcombの4つのみが5%水準で有意に影響しているという結果になった。 ggforest(mod_rsk_nonprop) 図5.3: mod_rsk_nonpropで推定されたハザード比 5.2.2.2.3 結果の比較 以上の3つのモデルで推定された偏回帰係数を比較したのが表5.2である。経済的支援(fin)はいずれでも有意ではなかったが、財産犯で最も大きな影響を持っていた。しかし、偏回帰係数の符号は予想とは逆であり、経済的支援をした元服役囚の方が、していない服役囚よりも財産犯を犯すリスクが高い傾向にあった。年齢(age)、過去に犯した財産犯の有罪判決の数(numprop)、前科の数(numarrst)はいずれのモデルでも再犯に影響を与えていたが、人種(white)は非財産犯のみで有意な影響がみられなかった。また、最後の服役が財産犯であったか(cromprop)も非財産犯のみで有意でなかったが、教育レベル(edcomb)は逆に財産犯のみで有意でなかった。 tibble(Covariate = rownames(mod_rsk_all$coefficients %&gt;% data.frame()), &quot;Coef(all)&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_rsk_all))[1:10]), &quot;Exp(Coef_all)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_rsk_all)))[1:10]), &quot;Coef(prop)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_rsk_prop))[1:10], &quot;Exp(Coef_prop)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_rsk_prop)))[1:10], &quot;Coef(nonprop)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_rsk_nonprop))[1:10], &quot;Exp(Coef_nonprop)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_rsk_nonprop))[1:10])) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2,2), values = c(&quot;&quot;,&quot;全ての種類&quot;,&quot;財産犯&quot;, &quot;非財産犯&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-dfd95d42{}.cl-dfd125fa{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-dfd42f7a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-dfd4449c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-dfd444a6{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-dfd444a7{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表5.2: 各モデルの推定値の比較 全ての種類財産犯非財産犯CovariateCoef(all)Exp(Coef_all)Coef(prop)Exp(Coef_prop)Coef(nonprop)Exp(Coef_nonprop)fin0.1211.1290.2011.2230.0071.007age-0.0340.966-0.0410.959-0.0270.973white-0.2410.786-0.3530.703-0.0770.926male0.5021.6510.1111.1171.3884.005married-0.2220.801-0.3320.717-0.0730.929paro-0.2110.810-0.1470.863-0.3020.739numprop0.3101.3640.3191.3750.3081.361crimprop0.4251.5300.8832.419-0.0690.933numarst0.0181.0180.0191.0190.0161.016edcomb-0.0680.935-0.0530.948-0.0830.921 では、財産犯についてのモデル(mod_rsk_prop)と非財産犯についてのモデル(mod_rsk_nonprop)で推定された偏回帰係数の差は統計的に有意だろうか。以下の統計量\\(z\\)は二つの偏回帰係数に差がないという帰無仮説の下では理論上標準正規分布に従う。つまり、\\(z &lt; -1.96\\)または\\(z &gt; 1.96\\)であれば、二つの偏回帰係数は有意に異なるということになる。なお、\\(se(b_1)\\)と\\(se(b_2)\\)はそれぞれ偏回帰係数\\(b_1\\)と\\(b_2\\)の標準誤差である。 \\[ z = \\frac{b_1 - b_2}{\\sqrt se(b_1)^2 + se(b_2)^2 } \\] 各独立変数について\\(z\\)を計算したのが表5.3である。最後の服役が財産犯であったか(cromprop)のみが5%水準で有意に偏回帰係数の推定値が異なっていた。 tibble( Covariate = rownames(mod_rsk_all$coefficients %&gt;% data.frame()), b_prop = mod_rsk_prop$coefficients, se_b_prop = sqrt(diag(mod_rsk_prop$var)), b_nonprop = mod_rsk_nonprop$coefficients, se_b_nonprop = sqrt(diag(mod_rsk_nonprop$var))) %&gt;% mutate(z = (b_prop - b_nonprop)/sqrt(se_b_prop^2 + se_b_nonprop^2)) %&gt;% mutate_if(.predicate = is.numeric, .funs = ~sprintf(&quot;%.3f&quot;,.)) %&gt;% kable(caption = &quot;各独立変数についてのz値&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表5.3: 各独立変数についてのz値 Covariate b_prop se_b_prop b_nonprop se_b_nonprop z fin 0.201 0.149 0.007 0.176 0.840 age -0.041 0.012 -0.027 0.012 -0.829 white -0.353 0.156 -0.077 0.182 -1.151 male 0.111 0.346 1.388 0.715 -1.608 married -0.332 0.177 -0.073 0.193 -0.990 paro -0.147 0.154 -0.302 0.186 0.642 numprop 0.319 0.097 0.308 0.107 0.072 crimprop 0.883 0.206 -0.069 0.192 3.380 numarst 0.019 0.006 0.016 0.007 0.253 edcomb -0.053 0.034 -0.083 0.038 0.574 5.2.3 注意点 競合リスク・モデルでは、他の種類の事象が発生したことにより生じた打ち切りについてはモデル中に情報がないので、ランダムな打ち切りでなくてはならない(2.8参照)。こうした無情報性の仮定が妥当かは検定することができない。ただし、すべての種類の事象の発生に影響を与える独立変数がモデルに十分に含まれているのであれば、打ち切りが無情報になる可能性は高くなるので、その点に留意してモデリングすることはできる。 5.3 部分分布を用いた競合リスクの分析 5.3.1 モデルの概要 競合事象を分析するもう一つの方法は、部分分布を用いる方法である。この方法は打ち切りが無情報である必要がない。一方で、分析目的が予測のときには有益だが、因果関係の推論には適していないとされる。 ここで、\\(j = 1,2,3,...,k\\)個の競合する事象があったとする。時点\\(t\\)において事象\\(j\\)が発生する確率を\\(f_j(t)\\)とすると、時点\\(t\\)までの事象\\(j\\)の累積発生率関数(= 時点\\(t\\)までに事象\\(j\\)が発生する確率)は以下のように定義され、部分分布(subdistribution)あるいは累積発生率関数(cumulative incidence function)と呼ばれる。 \\[ F_j(t) = \\int_0^t f_j(u) du \\] 一方で、時点\\(t\\)までの全ての事象の累積発生率関数は \\[ F(t) = \\sum_{j=1}^k F_j(t) \\] で表され、生存関数は\\(S(t) = 1-F(t)\\)と書くことができる。このとき、事象\\(j\\)のハザード関数は以下のようになる。 \\[ h_j(t) = f_j(t)/S(t) \\] 独立変数を\\(x\\)、偏回帰係数を\\(\\beta\\)とすると、部分分布のハザード関数に基づいた競合リスクの比例ハザードモデルは以下のように書ける。 \\[ h_j(t,x_i) = h_j(t) \\times exp(\\beta x_i) \\] 5.3.2 Rでの実装 Rでは、tidycmprskパッケージのcrr()関数を用いて部分分布を使った分析を行える。 ## 事象の種類を表す変数は因子型でなくてはならない。 tarp &lt;- mutate(tarp, type2 = as.factor(type)) ## 財産犯のモデル mod_subd_prop &lt;- tidycmprsk::crr(Surv(arrstday,type2) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb, ## 着目する事象の種類。ここでは財産犯。 failcode = 2, data = tarp) ## 非財産犯のモデル mod_subd_nonprop &lt;- tidycmprsk::crr(Surv(arrstday,type2) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb, ## 着目する事象の種類。ここでは非財産犯。 failcode = 1, data = tarp) 財産犯に着目したモデルの結果は以下の通り。HRはハザード比(偏回帰係数を対数変換したもの)を表す。age、white、married、numprop、crimprop、numarrstの影響が5%水準で有意になっていた。 mod_subd_prop ## ## Variable Coef SE HR 95% CI p-value ## fin 0.236 0.152 1.27 0.94, 1.70 0.12 ## age -0.040 0.014 0.96 0.93, 0.99 0.003 ## white -0.351 0.162 0.70 0.51, 0.97 0.030 ## male 0.043 0.372 1.04 0.50, 2.16 0.91 ## married -0.308 0.176 0.74 0.52, 1.04 0.081 ## paro -0.108 0.154 0.90 0.66, 1.21 0.48 ## numprop 0.276 0.102 1.32 1.08, 1.61 0.007 ## crimprop 0.887 0.208 2.43 1.61, 3.65 &lt;0.001 ## numarst 0.015 0.007 1.02 1.00, 1.03 0.030 ## edcomb -0.049 0.037 0.95 0.88, 1.02 0.19 非財産犯に着目したモデルの結果は以下の通り。male、numprop、edcombの3つのみが5%水準で有意で、特にmaleの効果が大きいと推定された。 mod_subd_nonprop ## ## Variable Coef SE HR 95% CI p-value ## fin 0.004 0.177 1.00 0.71, 1.42 0.98 ## age -0.022 0.011 0.98 0.96, 1.00 0.053 ## white -0.010 0.174 0.99 0.70, 1.39 0.95 ## male 1.44 0.713 4.20 1.04, 17.0 0.044 ## married -0.035 0.200 0.97 0.65, 1.43 0.86 ## paro -0.279 0.179 0.76 0.53, 1.07 0.12 ## numprop 0.258 0.102 1.29 1.06, 1.58 0.012 ## crimprop -0.184 0.192 0.83 0.57, 1.21 0.34 ## numarst 0.011 0.007 1.01 1.00, 1.02 0.10 ## edcomb -0.075 0.037 0.93 0.86, 1.00 0.042 二つのモデルで推定された偏回帰係数を比較するために作成したのが表5.4である。競合リスク・モデルの推定値(表5.2)と大きくは変わっていないが、\\(z\\)統計量の値が少し小さくなっている。一般に、因果推論を行うならば競合リスク・モデルの方がよいとされる。 tibble(Covariate = rownames(mod_subd_prop$coefs %&gt;% data.frame()), &quot;Coef(prop)&quot; = c(sprintf(&quot;%.3f&quot;,mod_subd_prop$coefs)[1:10]), &quot;Exp(Coef_prop)&quot; = c(sprintf(&quot;%.3f&quot;,exp(mod_subd_prop$coefs))[1:10]), &quot;Coef(nonprop)&quot; = sprintf(&quot;%.3f&quot;,mod_subd_nonprop$coefs)[1:10], &quot;Exp(Coef_nonprop)&quot; = sprintf(&quot;%.3f&quot;,exp(mod_subd_nonprop$coefs))[1:10]) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,2,2), values = c(&quot;&quot;,&quot;財産犯&quot;, &quot;非財産犯&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-514e4aae{}.cl-51470582{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-514a27bc{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-514a3ebe{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-514a3ebf{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-514a3ec8{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表5.4: 各モデルの推定値の比較 財産犯非財産犯CovariateCoef(prop)Exp(Coef_prop)Coef(nonprop)Exp(Coef_nonprop)fin0.2361.2660.0041.004age-0.0400.960-0.0220.978white-0.3510.704-0.0100.990male0.0431.0431.4364.204married-0.3080.735-0.0350.966paro-0.1080.898-0.2790.756numprop0.2761.3170.2581.294crimprop0.8872.429-0.1840.832numarst0.0151.0150.0111.011edcomb-0.0490.952-0.0750.928 5.3.3 累積発生率関数の予測値 一方で、部分分布を用いたモデルは予測を行う場合には優れているとされる。 時点\\(t\\)における事象\\(j\\)の累積発生率関数は以下のように定義される。 \\[ F_j(t) = \\int_0^t f_j(u)du = \\int_0^t h_j(u)S(u)du \\] 累積発生率関数の図示はtidycmprskパッケージのcuminc()関数と、ggsurvfitパッケージのggsuminc()関数を利用して行える(図5.4)。 tidycmprsk::cuminc(Surv(arrstday,type2) ~ 1, rho = 0, data = tarp) -&gt; pred_cuminc ggcuminc(pred_cuminc, outcome = c(&quot;1&quot;,&quot;2&quot;))+ add_confidence_interval()+ theme_bw(base_size = 16)+ scale_linetype_discrete(labels = c(&quot;nonprop&quot;,&quot;prop&quot;))+ theme(aspect.ratio = 1.1)+ scale_x_continuous(breaks = seq(0,350,50)) 図5.4: 部分分布モデルから推定された累積発生率関数 なお、コックス回帰モデルを使用した競合リスク・モデルも以下のようにすれば累積発生関数を図示できる(図5.5)。しかし、競合リスク・モデルはそれぞれの種類を別々のモデルで推定しているため、両方の予測値を足すと1を超えてしまう場合がある点に注意が必要。 predict_rsk_prop &lt;- survfit(mod_rsk_prop, conf.int = 0.95) predict_rsk_nonprop &lt;- survfit(mod_rsk_nonprop, conf.int = 0.95) ## 財産犯 ggsurvplot(predict_rsk_prop, data = tarp, ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, ggtheme = theme_bw(), ## 累積ハザード関数を指定 fun = &quot;cumhaz&quot;) -&gt; p_rsk_prop p_rsk_prop$plot + theme_bw(base_size = 16)+ labs(x = &quot;week&quot;, y = &quot;cumulative hazard&quot;, title = &quot;prop&quot;)+ theme(legend.position = &quot;none&quot;)+ coord_cartesian(xlim = c(0,370), ylim = c(0,0.24))+ scale_x_continuous(breaks = seq(0,350,100))+ theme(aspect.ratio=1.1)-&gt; p_rsk_prop2 ## 非財産犯 ggsurvplot(predict_rsk_nonprop, data = tarp, ## 塗りつぶしの濃さ conf.int.alpha = 0.15, size = 0.5, ## TRUEなら打ち切りデータの場所が明示される censor = FALSE, ggtheme = theme_bw(), ## 累積ハザード関数を指定 fun = &quot;cumhaz&quot;) -&gt; p_rsk_nonprop p_rsk_nonprop$plot + theme_bw(base_size = 16)+ labs(x = &quot;week&quot;, y = &quot;cumulative hazard&quot;, title = &quot;nonprop&quot;)+ theme(legend.position = &quot;none&quot;)+ coord_cartesian(xlim = c(0,370), ylim = c(0,0.24))+ scale_x_continuous(breaks = seq(0,350,100))+ theme(aspect.ratio=1.1)-&gt; p_rsk_nonprop2 p_rsk_prop2 + p_rsk_nonprop2 図5.5: 競合リスク・モデルから推定された累積発生関数 "],["Chapter6.html", "6 繰り返しのある事象モデル 6.1 繰り返しのある事象のカウントデータ・モデル 6.2 時間のギャップに基づく方法 6.3 観察開始からの時間に基づく方法 6.4 分析モデルの拡張", " 6 繰り返しのある事象モデル 研究で扱うほとんどの事象には繰り返しがある。例えば、一個体が繰り返し経験しうる転職・出産・離婚・逮捕などがこれに該当する。 第5章で扱った元服役囚の再犯データにも実は繰り返し逮捕された元服役囚がいた。逮捕された回数(arrstcount)ごとに人数を見てみると、以下のようになる(表6.1)。1年間の間に最大6回まで再犯を犯した個体がいる。再犯を犯した服役囚の内、2回以上逮捕された元服役囚は実に約39.5%にのぼる(132/334)。 tarp %&gt;% group_by(arrstcount) %&gt;% summarise(N = n()) %&gt;% kable(caption = &quot;逮捕回数ごとの人数&quot;) %&gt;% kable_styling(font_size = 13, full_width = FALSE) 表6.1: 逮捕回数ごとの人数 arrstcount N 0 598 1 202 2 88 3 28 4 10 5 4 6 2 本章ではこうした繰り返しの事象を扱う方法を解説する。なお、話を簡単にするため、繰り返された逮捕は一種類の犯罪であると仮定する。 6.1 繰り返しのある事象のカウントデータ・モデル 6.1.1 モデルの概要 もっとも簡単な方法は、事象が発生するタイミングを無視して国個体の事象発生数を従属変数にするものである。これは、以下の2つが仮定できる場合には最善の方法である。なぜならば、以下の条件を満たすのであれば。データに含まれている観察期間における事象の発生タイミングは有益な情報をほとんど持たないからである。 時間依存独立変数がない 独立変数が観測期間全てで同じ効果を持っている カウントデータの分析で最も適切かつ容易に利用できるのは負の二項分布モデルである。ポアソン分布モデルも使えるが、しばしば過分散の問題が生じる13。個体\\(i\\)に発生した事象の数を\\(Y_i\\)とし、\\(Y_i\\)が期待値\\(\\lambda_i\\)の負の二項分布に従うと仮定するとき、回帰モデルは以下のように表現される(式(6.1))。つまり、通常の一般化線形モデルと同様である。 \\[ \\begin{aligned} Y_i &amp;\\sim NegBinomial(\\lambda_i)\\\\ log(\\lambda_i) &amp;= b_0 + b_1x_{i1} + b_1x_{i2} + \\cdots + b_kx_{ik} \\end{aligned} \\tag{6.1} \\] 6.1.2 Rでの実装 負の二項モデルはMASSパッケージのglm.nb()関数で以下のように実行できる。 mod_nb &lt;- glm.nb(arrstcount ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb, data = tarp) 結果は以下の通り(表6.2)。 model_parameters(mod_nb) %&gt;% data.frame() %&gt;% mutate(`95%CI` = str_c(&quot;[&quot;,sprintf(&quot;%.2f&quot;,CI_low),&quot;, &quot;,sprintf(&quot;%.2f&quot;,CI_high),&quot;}&quot;)) %&gt;% mutate(`Exp(Coef)` = exp(Coefficient)) %&gt;% dplyr::select(-df_error, -CI_low, -CI_high, -CI) %&gt;% dplyr::select(Parameter, Coefficient, `95%CI`, `Exp(Coef)`, everything()) %&gt;% mutate_if(.predicate = is.numeric,.funs = ~sprintf(&quot;%.3f&quot;,.)) %&gt;% kable(align = &quot;c&quot;, caption = &quot;mod1の結果&quot;) %&gt;% kable_styling(font_size = 11, full_width = FALSE) 表6.2: mod1の結果 Parameter Coefficient 95%CI Exp(Coef) SE z p (Intercept) 0.201 [-0.69, 1.09} 1.223 0.458 0.439 0.661 fin 0.148 [-0.06, 0.36} 1.160 0.109 1.359 0.174 age -0.033 [-0.05, -0.02} 0.968 0.008 -4.132 0.000 white -0.153 [-0.38, 0.07} 0.858 0.113 -1.354 0.176 male 0.372 [-0.14, 0.92} 1.450 0.270 1.379 0.168 married -0.052 [-0.29, 0.18} 0.949 0.120 -0.435 0.664 paro -0.323 [-0.55, -0.10} 0.724 0.116 -2.795 0.005 numprop 0.278 [0.13, 0.43} 1.321 0.073 3.827 0.000 crimprop 0.343 [0.09, 0.60} 1.409 0.129 2.658 0.008 numarst 0.013 [0.00, 0.02} 1.013 0.005 2.904 0.004 edcomb -0.060 [-0.11, -0.01} 0.942 0.024 -2.478 0.013 負の二項分布モデルではオフセット項に観察期間を含めることで、観察期間の違う複数の個体がいるデータについても簡単に分析が可能である14。 6.2 時間のギャップに基づく方法 6.2.1 モデルの概要 時間依存変数や独立変数の影響が時間によって変化すると仮定される場合は、より複雑な方法が必要になる。この方法では、観察の開始から最初の事象までを一つの記録、また次の事象までを発生までを別の一つの記録、というように事象の発生ごとに観察期間を区切ったデータを作成する。 データはすでに作成されているので読み込む。lengthが事象間の時間のギャップを表している。 arrest &lt;- read_dta(&quot;data/arrests.dta&quot;) datatable(arrest, options = list(scrollX = 60)) 分析では、これらの観察期間の記録全てを異なった個体の観測値とみなし、「時間のギャップ」(= 観測の開始時点と終了時点の差)をコックス回帰で分析する。 6.2.2 Rでの実装 第3で解説したのと同様にコックス回帰を行う。データにはなぜかlengthが負になるものが含まれているので、それらは除く。 arrest &lt;- filter(arrest, length &gt; 0) mod_tg &lt;- coxph(Surv(length,arrind) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb, data = arrest) 分析の結果は以下の通り。 mod_tg ## Call: ## coxph(formula = Surv(length, arrind) ~ fin + age + white + male + ## married + paro + numprop + crimprop + numarst + edcomb, data = arrest) ## ## coef exp(coef) se(coef) z p ## fin 0.135958 1.145633 0.090046 1.510 0.131075 ## age -0.030654 0.969811 0.006762 -4.533 5.82e-06 ## white -0.156933 0.854761 0.094189 -1.666 0.095683 ## male 0.339312 1.403981 0.230061 1.475 0.140246 ## married -0.093797 0.910468 0.100009 -0.938 0.348303 ## paro -0.303321 0.738362 0.096908 -3.130 0.001748 ## numprop 0.258334 1.294771 0.056161 4.600 4.23e-06 ## crimprop 0.304769 1.356312 0.109110 2.793 0.005218 ## numarst 0.011737 1.011806 0.003474 3.379 0.000728 ## edcomb -0.053929 0.947500 0.019860 -2.715 0.006620 ## ## Likelihood ratio test=93.22 on 10 df, p=1.227e-15 ## n= 1444, number of events= 530 6.2.3 データの非独立性の問題 今回の分析では、同じ個体のデータが複数個入っていることがあるにもかかわらず、全てのデータが独立であると仮定されてしまっている。その結果、先ほどのモデル(mod_tg)の偏回帰係数の標準誤差は実際より小さく推定されてしまっており、結果的に\\(z\\)値は過大に評価されてしまっている。正しい統計的推論を行うためには、これを修正する必要がある。修正方法は主に二つある。 6.2.3.1 頑強推定 これは、「サンドイッチ」推定法と呼ばれる方法を使って標準誤差を計算することである。Rでは以下のようにcloster(id)を式に加えることで実行できる。 mod_tg_rob &lt;- coxph(Surv(length,arrind) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb + cluster(id), data = arrest) 結果は以下の通り。偏回帰係数の推定値自体は先ほどのモデルと全く同じである。一方で、頑強推定を行わない場合の標準誤差(se(coef))よりも、頑強推定での標準誤差(robust se)の方が大きくなっており、先ほどより\\(z\\)値が小さくなっていることが分かる。 mod_tg_rob ## Call: ## coxph(formula = Surv(length, arrind) ~ fin + age + white + male + ## married + paro + numprop + crimprop + numarst + edcomb, data = arrest, ## cluster = id) ## ## coef exp(coef) se(coef) robust se z p ## fin 0.135958 1.145633 0.090046 0.102972 1.320 0.186721 ## age -0.030654 0.969811 0.006762 0.008399 -3.650 0.000263 ## white -0.156933 0.854761 0.094189 0.113864 -1.378 0.168126 ## male 0.339312 1.403981 0.230061 0.290408 1.168 0.242646 ## married -0.093797 0.910468 0.100009 0.122438 -0.766 0.443630 ## paro -0.303321 0.738362 0.096908 0.105280 -2.881 0.003963 ## numprop 0.258334 1.294771 0.056161 0.065745 3.929 8.52e-05 ## crimprop 0.304769 1.356312 0.109110 0.131040 2.326 0.020030 ## numarst 0.011737 1.011806 0.003474 0.004411 2.661 0.007789 ## edcomb -0.053929 0.947500 0.019860 0.025856 -2.086 0.037004 ## ## Likelihood ratio test=93.22 on 10 df, p=1.227e-15 ## n= 1444, number of events= 530 6.2.3.2 共用フレイルティ・モデル 一般的なコックス回帰の場合、通常は標準誤差を修正するだけでは理想的ではない。「共用フレイルティ」を回帰モデルの構成要素として含むモデルは、頑強モデルだけでは十分でない点も修正することができる。 基本的なモデルは、標準のコックス回帰モデルにランダム切片15を加えたランダム効果モデル(混合モデル)である。式(6.2)の\\(h_ij(t)\\)は個体\\(i\\)が\\(j\\)番目の事象を経験するハザード率であり、\\(t\\)は事象が最後に発生した時点からの経過時間である。\\(e_i\\)は「共用フレイルティ」で、全ての測定されていない個体ごとの異質性を表す。\\(e_i\\)は独立変数とは独立であると仮定され、平均0で分散\\(\\theta\\)の正規分布かガンマ分布が仮定される。\\(\\theta\\)が大きいほど、同じ個体のデータ同士の依存度が高くなる。 \\[ log(h_ij(t)) = a(t) + b_1x_{i1} + b_2x_{i2} + e_i \\tag{6.2} \\] Rでは、以下のようにして簡単に実行できる。\\(e_i\\)の分布に正規分布を仮定するなら式にfrailty.gaussian(id)をガンマ分布を仮定するならfrailty.gamma(id)を追加する。 mod_tg_frail &lt;- coxph(Surv(length,arrind) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb + frailty.gaussian(id), data = arrest) 結果は以下の通り。\\(\\theta\\)は0.49と推定された。偏回帰係数の標準誤差は頑強推定と似通っている。StataやSASとは異なり、統計検定量は\\(\\chi^2\\)値で出力されるようだ。 summary(mod_tg_frail) ## Call: ## coxph(formula = Surv(length, arrind) ~ fin + age + white + male + ## married + paro + numprop + crimprop + numarst + edcomb + ## frailty.gaussian(id), data = arrest) ## ## n= 1444, number of events= 530 ## ## coef se(coef) se2 Chisq DF p ## fin 0.13868 0.104475 0.091060 1.76 1.0 1.8e-01 ## age -0.03250 0.007734 0.006917 17.66 1.0 2.6e-05 ## white -0.15138 0.108495 0.094794 1.95 1.0 1.6e-01 ## male 0.36425 0.260060 0.232914 1.96 1.0 1.6e-01 ## married -0.10136 0.115930 0.101118 0.76 1.0 3.8e-01 ## paro -0.30459 0.111573 0.098411 7.45 1.0 6.3e-03 ## numprop 0.27501 0.070026 0.058390 15.42 1.0 8.6e-05 ## crimprop 0.32415 0.124763 0.110972 6.75 1.0 9.4e-03 ## numarst 0.01226 0.004419 0.003650 7.70 1.0 5.5e-03 ## edcomb -0.05746 0.022866 0.019871 6.31 1.0 1.2e-02 ## frailty.gaussian(id) 285.23 188.1 6.1e-06 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## fin 1.1488 0.8705 0.9361 1.4098 ## age 0.9680 1.0330 0.9535 0.9828 ## white 0.8595 1.1634 0.6949 1.0632 ## male 1.4394 0.6947 0.8646 2.3964 ## married 0.9036 1.1067 0.7199 1.1341 ## paro 0.7374 1.3561 0.5926 0.9177 ## numprop 1.3165 0.7596 1.1477 1.5102 ## crimprop 1.3829 0.7231 1.0829 1.7659 ## numarst 1.0123 0.9878 1.0036 1.0211 ## edcomb 0.9442 1.0591 0.9028 0.9874 ## ## Iterations: 6 outer, 29 Newton-Raphson ## Variance of random effect= 0.4898072 ## Degrees of freedom for terms= 0.8 0.8 0.8 0.8 0.8 0.8 0.7 0.8 0.7 0.8 188.1 ## Concordance= 0.829 (se = 0.008 ) ## Likelihood ratio test= 537.6 on 195.7 df, p=&lt;2e-16 なお、coxmeパッケージのcoxme()関数を用いても共用フレイルティ・モデルの推定は行えるようである。ただし、こちらはランダム効果の分布に正規分布のみが仮定できる。 mod_tg_frail_b &lt;- coxme(Surv(length,arrind) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb + (1|id), data = arrest) 結果は以下の通り。\\(\\theta\\)は0.52と推定され、偏回帰係数の推定値も少し違うようだ。この違いが何によるものかは不明だが、おそらく推定方法の違いによるものと思われる。 summary(mod_tg_frail_b) ## Cox mixed-effects model fit by maximum likelihood ## Data: arrest ## events, n = 530, 1444 ## Iterations= 13 70 ## NULL Integrated Fitted ## Log-likelihood -3663.536 -3598.781 -3386.021 ## ## Chisq df p AIC BIC ## Integrated loglik 129.51 11.00 0 107.51 60.51 ## Penalized loglik 555.03 206.67 0 141.68 -741.41 ## ## Model: Surv(length, arrind) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb + (1 | id) ## Fixed coefficients ## coef exp(coef) se(coef) z p ## fin 0.13891349 1.1490247 0.105410172 1.32 1.9e-01 ## age -0.03262094 0.9679054 0.007796089 -4.18 2.9e-05 ## white -0.15146381 0.8594490 0.109447779 -1.38 1.7e-01 ## male 0.36627568 1.4423528 0.262117579 1.40 1.6e-01 ## married -0.10216178 0.9028835 0.116970737 -0.87 3.8e-01 ## paro -0.30459710 0.7374204 0.112528421 -2.71 6.8e-03 ## numprop 0.27621349 1.3181292 0.070848073 3.90 9.7e-05 ## crimprop 0.32554843 1.3847899 0.125788213 2.59 9.7e-03 ## numarst 0.01227966 1.0123554 0.004473929 2.74 6.1e-03 ## edcomb -0.05770664 0.9439268 0.023065816 -2.50 1.2e-02 ## ## Random effects ## Group Variable Std Dev Variance ## id Intercept 0.7222207 0.5216028 6.2.3.3 モデルの比較 「時間のギャップ」を用いた3つのモデルで推定された偏回帰係数とそれを指数変換したもの、\\(z\\)値をまとめたのが表6.3である。なお、頑強推定(mod_tg_rob)でも通常のコックス回帰(mod_tg)と偏回帰係数の推定値自体は変わらないので、それらは省略している。共用フレイルティのあるモデルでは、統計的に有意であるような変数の偏回帰係数の推定値(Coef(frail))が通常のコックス回帰(Coef)よりも大きくなっている。\\(z\\)値(Z(frail))は基本的には頑強推定のもの(Z(robust))と似通っているが、有意な変数では頑強推定のものより高くなっている。しかし、どの変数も通常のコックス回帰の\\(z\\)値(Z)よりは小さくなっている。 tibble(Covariate = rownames(mod_tg$coefficients %&gt;% data.frame()), &quot;Coef&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_tg))[1:10]), &quot;Exp(Coef)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_tg)))[1:10]), &quot;Z&quot; = sprintf(&quot;%.3f&quot;,coef(mod_tg)/sqrt(diag(vcov(mod_tg))))[1:10], &quot;Z(robust)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_tg)/sqrt(diag(vcov(mod_tg_rob))))[1:10], &quot;Coef(frail)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_tg_frail))[1:10], &quot;Exp(Coef_frail)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_tg_frail))[1:10]), &quot;Z(frail)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_tg_frail)/sqrt(diag(vcov(mod_tg_frail))))[1:10]) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,4,3), values = c(&quot;&quot;,&quot;コックス回帰\\n(通常＋頑強推定)&quot;, &quot;コックス回帰\\n(共用フレイルティ)&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-a51642b2{}.cl-a50fd756{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-a5127c2c{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-a512905e{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a512905f{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-a5129060{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表6.3: 各モデルの推定値の比較 コックス回帰(通常＋頑強推定)コックス回帰(共用フレイルティ)CovariateCoefExp(Coef)ZZ(robust)Coef(frail)Exp(Coef_frail)Z(frail)fin0.1361.1461.5101.3200.1391.1491.327age-0.0310.970-4.533-3.650-0.0320.968-4.202white-0.1570.855-1.666-1.378-0.1510.860-1.395male0.3391.4041.4751.1680.3641.4391.401married-0.0940.910-0.938-0.766-0.1010.904-0.874paro-0.3030.738-3.130-2.881-0.3050.737-2.730numprop0.2581.2954.6003.9290.2751.3173.927crimprop0.3051.3562.7932.3260.3241.3832.598numarst0.0121.0123.3792.6610.0121.0122.775edcomb-0.0540.947-2.715-2.086-0.0570.944-2.513 なお、ここで紹介したモデルは全てパラメトリックなモデル(例えばワイブル回帰モデル)に対しても同様に適用できる。 6.3 観察開始からの時間に基づく方法 6.3.1 モデルの概要 ほとんどの場合では、時間のギャップを用いるのが最善であると考えられる。しかし、場合によってはハザード率を他の時間の長さに依存させた方が妥当かもしれない。例えば、再逮捕のハザード率は最後の逮捕からの時間ではなく、最初に刑務所を出所してからの時間に依存しているかもしれない。 この分析でも先ほどと同じデータを使用するが、一つ一つの観察期間を従属変数にするのではなく、時間依存変数があるときのように各行のデータの開始時点と終了時点を明示的に指定する形になる。データarrestには、各行の観察開始時点を表す変数beginと終了を表す変数endが存在する。 6.3.2 Rでの実装 Rでは、従属変数をSurv(begin, end, arrind)とすることでこのような推定ができる。今回も同じ個体のデータが複数あるので、頑強モデルと共用フレイルティモデルの両方を推定する。 mod_st_rob &lt;- coxph(Surv(begin, end, arrind) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb + cluster(id), data = arrest) mod_st_frail &lt;- coxph(Surv(begin, end, arrind) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb + frailty.gaussian(id), data = arrest) 両モデルで推定された偏回帰係数とそれを指数変換したもの、\\(z\\)値をまとめたのが表6.4である。いずれも時間のギャップを用いたモデル(表6.4)と非常によく似ている。 tibble(Covariate = rownames(mod_st_rob$coefficients %&gt;% data.frame()), &quot;Coef(rob)&quot; = c(sprintf(&quot;%.3f&quot;,coef(mod_st_rob))[1:10]), &quot;Exp(Coef_rob)&quot; = c(sprintf(&quot;%.3f&quot;,exp(coef(mod_st_rob)))[1:10]), &quot;Z(rob)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_st_rob)/sqrt(diag(vcov(mod_st_rob))))[1:10], &quot;Coef(frail)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_st_frail))[1:10], &quot;Exp(Coef_frail)&quot; = sprintf(&quot;%.3f&quot;,exp(coef(mod_st_frail))[1:10]), &quot;Z(frail)&quot; = sprintf(&quot;%.3f&quot;,coef(mod_st_frail)/sqrt(diag(vcov(mod_st_frail))))[1:10]) %&gt;% flextable() %&gt;% add_header_row(colwidth = c(1,3,3), values = c(&quot;&quot;,&quot;コックス回帰\\n(頑強推定)&quot;, &quot;コックス回帰\\n(共用フレイルティ)&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;各モデルの推定値の比較&quot;) .cl-67567072{}.cl-674ed696{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-67524b32{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-67526fea{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-67526ff4{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-67526ff5{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表6.4: 各モデルの推定値の比較 コックス回帰(頑強推定)コックス回帰(共用フレイルティ)CovariateCoef(rob)Exp(Coef_rob)Z(rob)Coef(frail)Exp(Coef_frail)Z(frail)fin0.1401.1501.3200.1401.1511.343age-0.0310.970-3.638-0.0320.968-4.165white-0.1530.858-1.311-0.1440.866-1.331male0.3441.4111.1470.3611.4341.390married-0.1440.866-1.140-0.1360.873-1.171paro-0.3130.731-2.938-0.3090.734-2.773numprop0.2781.3204.0920.2831.3274.055crimprop0.3031.3542.2570.3161.3722.537numarst0.0111.0112.4660.0121.0122.630edcomb-0.0580.944-2.151-0.0590.943-2.583 6.3.3 観察開始時点からの時間を使う利点 この方法の魅力の一つは、独立変数の影響が観察期間全体で変化するかを調べることができる点である。これは、独立変数と開始時点からの時間(\\(t\\))の交互作用項を含めることでモデリングできる。 \\[ log(h_ij(t)) = a(t) + b_1x_{i1} + b_2x_{i2} + b_3x_{i2}t \\] 実際に、先ほどの頑強推定モデル(mod_st_rob)で比例ハザード性が満たされているか、シェーンフィールド残差を用いて調べたところ、人種(white)、前科の数(numarst)、教育レベル(edcomb)は満たされていないことが示唆された。 cox.zph(mod_st_rob) ## chisq df p ## fin 1.549 1 0.2133 ## age 0.606 1 0.4361 ## white 6.917 1 0.0085 ## male 1.945 1 0.1631 ## married 0.713 1 0.3986 ## paro 3.570 1 0.0588 ## numprop 1.062 1 0.3029 ## crimprop 0.192 1 0.6615 ## numarst 9.802 1 0.0017 ## edcomb 8.450 1 0.0037 ## GLOBAL 37.849 10 4e-05 そこで、これらと時間の交互作用を含むモデルを考える。 mod_st_rob_int &lt;- coxph(Surv(begin, end, arrind) ~ fin + age + white + male + married + paro + numprop + crimprop + numarst + edcomb + white:end + numarst:end + edcomb:end + cluster(id), data = arrest) 結果が以下の通り。交互作用はいずれも5%水準で有意になっていることが分かる。 mod_st_rob_int ## Call: ## coxph(formula = Surv(begin, end, arrind) ~ fin + age + white + ## male + married + paro + numprop + crimprop + numarst + edcomb + ## white:end + numarst:end + edcomb:end, data = arrest, cluster = id) ## ## coef exp(coef) se(coef) robust se z p ## fin 1.484e-01 1.160e+00 9.381e-02 1.098e-01 1.352 0.176359 ## age -5.265e-02 9.487e-01 7.309e-03 9.226e-03 -5.706 1.15e-08 ## white 1.072e+00 2.921e+00 2.072e-01 2.813e-01 3.810 0.000139 ## male 5.813e-01 1.788e+00 2.368e-01 2.913e-01 1.995 0.045996 ## married -2.620e-01 7.695e-01 1.071e-01 1.217e-01 -2.153 0.031297 ## paro -3.028e-01 7.388e-01 1.005e-01 1.158e-01 -2.614 0.008953 ## numprop 2.184e-01 1.244e+00 6.102e-02 7.316e-02 2.985 0.002840 ## crimprop 7.244e-02 1.075e+00 1.140e-01 1.206e-01 0.601 0.548112 ## numarst 3.972e-02 1.041e+00 6.570e-03 1.177e-02 3.375 0.000739 ## edcomb 1.173e+00 3.231e+00 4.338e-02 7.149e-02 16.403 &lt; 2e-16 ## white:end -3.368e-03 9.966e-01 8.888e-04 1.095e-03 -3.075 0.002104 ## numarst:end -2.565e-04 9.997e-01 4.673e-05 8.041e-05 -3.189 0.001426 ## edcomb:end -4.789e-03 9.952e-01 1.548e-04 2.492e-04 -19.215 &lt; 2e-16 ## ## Likelihood ratio test=2604 on 13 df, p=&lt; 2.2e-16 ## n= 1444, number of events= 530 例えば前科の数と教育レベルに着目すると、それぞれの独立変数の偏回帰係数(\\(b+ct\\))は時間と共に減少していき、途中で負に転じることが分かる(表6.5)。 tibble(t = seq(0,365,50), `偏回帰係数\\n(b + ct)` = sprintf(&quot;%.3f&quot;,mod_st_rob_int$coefficients[[9]] + mod_st_rob_int$coefficients[[12]]*t), `Exp(b+ct)` = sprintf(&quot;%.3f&quot;, exp(mod_st_rob_int$coefficients[[9]] + mod_st_rob_int$coefficients[[12]]*t)), `偏回帰係数\\n(b + ct) ` = sprintf(&quot;%.3f&quot;, mod_st_rob_int$coefficients[[10]] + mod_st_rob_int$coefficients[[13]]*t), `Exp(b+ct) ` = sprintf(&quot;%.3f&quot;, exp(mod_st_rob_int$coefficients[[10]] + mod_st_rob_int$coefficients[[13]]*t))) %&gt;% rename(`出所して\\nからの日数(t)` = t) %&gt;% flextable() %&gt;% width(width = 2/2) %&gt;% add_header_row(colwidth = c(1,2,2), values = c(&quot;&quot;,&quot;前科の数&quot;,&quot;教育レベル&quot;)) %&gt;% flextable::align(align = &quot;center&quot;, part = &quot;all&quot;) %&gt;% set_caption(&quot;モデルから推定された交互作用項を含む偏回帰係数&quot;) .cl-9bb293f0{}.cl-9bacb0fc{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9baefa24{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9baf07a8{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9baf07b2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9baf07bc{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} 表6.5: モデルから推定された交互作用項を含む偏回帰係数 前科の数教育レベル出所してからの日数(t)偏回帰係数(b + ct)Exp(b+ct)偏回帰係数(b + ct) Exp(b+ct) 00.0401.0411.1733.231500.0271.0270.9332.5431000.0141.0140.6942.0011500.0011.0010.4541.575200-0.0120.9880.2151.240250-0.0240.976-0.0250.976300-0.0370.963-0.2640.768350-0.0500.951-0.5040.604 6.4 分析モデルの拡張 繰り返し発生する事象について、これまで検討した方法はさまざまに拡張できる。例えば競合リスク・モデルや離散時間モデルについても同様の方法が適用できる。一つの個体が複数の観察記録を持つ問題については、本章で解説したように頑強推定を用いたり、ランダム効果モデルを用いたりすることで対処できる。 References 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 大東健太郎. (2010). 線形モデルから一般化線形モデル（GLM）へ. 雑草研究, 55(4), 268–274. 粕谷英一. (2012). 一般化線形モデル. 共立出版. 過分散については 大東 (2010) や 粕谷 (2012) を参照。負の二項分布については、こちらも参照。簡単に言えば負の二項分布はポワソン分布の期待値\\(\\lambda\\)が毎回ガンマ分布から得られると仮定する混合分布である。よって、ポワソン分布は負の二項分布の特殊例といえる。↩︎ オフセット項については 久保 (2012) を参照。↩︎ ランダム効果については、 久保 (2012) や 粕谷 (2012) を参照。↩︎ "],["Chapterx.html", "補遺 ノンパラメトリックな推定 Kaplan-Meier法 Nelson-Aalen法", " 補遺 ノンパラメトリックな推定 Allison (2014) ではほとんど解説がなかったが、分布に何も仮定を置かないノンパラメトリックな方法で分析を行うこともできる。以下では、2つの代表的な方法を紹介する。 Kaplan-Meier法 Kaplan-Maier法は生存関数を推定するための推定量で、時点\\(t_n\\)における生存率\\(S_n\\)の推定値は以下のように定義される。なお、時点\\(t_n\\)でのリスク集合の大きさを\\(l_n\\)、時点\\(t_n\\)に発生した事象の数を\\(d_n\\)としている。推定量は最尤推定によって得られる。 \\[ \\begin{aligned} S(t_n) &amp;= \\biggl(1-\\frac{d_1}{l_1}\\biggl) \\times \\biggl(1-\\frac{d_2}{l_2}\\biggl) \\times \\cdots \\times \\biggl(1-\\frac{d_n}{l_n}\\biggl) \\\\ &amp;= \\prod_{k=1}^n \\biggl(1-\\frac{d_k}{l_k}\\biggl) \\end{aligned} \\] Kaplan-Meier推定量は1からスタートし、事象の発生が確認されるたびに値が小さくなる階段関数である。Rではsurvivalパケージのsurvfit()関数で推定できる。ここでは、第2章で使用した生化学者の准教授への昇進データ(rank)を使用する。 library(haven) rank &lt;- read_dta(&quot;data/rank.dta&quot;) 第3章と第4章のモデルと同様に、従属変数をSurv(観察期間, 事象の発生の有無)もしくは、Surv(観察開始時点, 観察終了時点, 事象の発生の有無)として推定できる。推定の結果は以下のとおりである。 est_km &lt;- survfit(Surv(dur, promo) ~ 1, type = &quot;kaplan-meier&quot;, data = rank) summary(est_km) ## Call: survfit(formula = Surv(dur, promo) ~ 1, data = rank, type = &quot;kaplan-meier&quot;) ## ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 1 301 1 0.997 0.00332 0.990 1.000 ## 2 299 1 0.993 0.00469 0.984 1.000 ## 3 292 17 0.936 0.01431 0.908 0.964 ## 4 263 42 0.786 0.02431 0.740 0.835 ## 5 211 53 0.589 0.02970 0.533 0.650 ## 6 149 46 0.407 0.03030 0.352 0.471 ## 7 96 31 0.276 0.02825 0.225 0.337 ## 8 59 15 0.205 0.02622 0.160 0.264 ## 9 42 7 0.171 0.02484 0.129 0.228 ## 10 29 4 0.148 0.02406 0.107 0.203 結果の図示はsurvminerパッケージのggsurvplot()関数で行うことができる(図6.1)。 ggsurvplot(est_km, data = rank, censor = FALSE, palette = &quot;black&quot;, size = 0.5, conf.int.alpha = 0.15, legend = &quot;none&quot;, legend.title = &quot;&quot;) -&gt; p_km p_km$plot + labs(x = &quot;year&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ coord_cartesian(ylim = c(0.15,1)) 図6.1: Kaplan-Meier法で推定した生存曲線 説明変数を含めて、独立変数の値ごとに推定することもできる。 est_km2 &lt;- survfit(Surv(dur, promo) ~ phdmed, data = rank, type = &quot;kaplan-meier&quot;) summary(est_km2) ## Call: survfit(formula = Surv(dur, promo) ~ phdmed, data = rank, type = &quot;kaplan-meier&quot;) ## ## phdmed=0 ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 3 107 6 0.944 0.0222 0.9013 0.989 ## 4 96 19 0.757 0.0423 0.6785 0.845 ## 5 73 17 0.581 0.0496 0.4913 0.687 ## 6 54 19 0.376 0.0496 0.2908 0.487 ## 7 31 11 0.243 0.0455 0.1682 0.351 ## 8 17 4 0.186 0.0428 0.1182 0.292 ## 9 13 3 0.143 0.0395 0.0831 0.245 ## 10 8 1 0.125 0.0383 0.0685 0.228 ## ## phdmed=1 ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 1 189 1 0.995 0.00528 0.984 1.000 ## 2 188 1 0.989 0.00744 0.975 1.000 ## 3 185 11 0.931 0.01857 0.895 0.968 ## 4 167 23 0.802 0.02953 0.747 0.862 ## 5 138 36 0.593 0.03710 0.525 0.670 ## 6 95 27 0.425 0.03819 0.356 0.506 ## 7 65 20 0.294 0.03591 0.231 0.373 ## 8 42 11 0.217 0.03317 0.161 0.293 ## 9 29 4 0.187 0.03179 0.134 0.261 ## 10 21 3 0.160 0.03076 0.110 0.233 また、2つ以上の集団で生存関数が有意に異なるかを、ログランク検定や一般化ウィルコクソン検定で調べることもできる。Rではsurvdiff()関数で以下のように実行することができる。今回は、医学博士を持っているか否か(phdmed)によって生存関数が有意に異なるわけではないことが分かった。コックス回帰などとは異なり、他の変数の影響を統制できない点は注意が必要である。 ## ログランク検定 survdiff(Surv(dur, promo) ~ phdmed, data = rank, rho = 0) ## Call: ## survdiff(formula = Surv(dur, promo) ~ phdmed, data = rank, rho = 0) ## ## N Observed Expected (O-E)^2/E (O-E)^2/V ## phdmed=0 112 80 74.9 0.345 0.685 ## phdmed=1 189 137 142.1 0.182 0.685 ## ## Chisq= 0.7 on 1 degrees of freedom, p= 0.4 ## 一般化ウィルコクソン検定 survdiff(Surv(dur, promo) ~ phdmed, data = rank, rho = 1) ## Call: ## survdiff(formula = Surv(dur, promo) ~ phdmed, data = rank, rho = 1) ## ## N Observed Expected (O-E)^2/E (O-E)^2/V ## phdmed=0 112 54.6 51.4 0.206 0.516 ## phdmed=1 189 91.1 94.4 0.112 0.516 ## ## Chisq= 0.5 on 1 degrees of freedom, p= 0.5 検定の結果を反映させた図を作成することもできる(図6.2)。 ggsurvplot(est_km2, data = rank, censor = FALSE, conf.int = TRUE, palette = c(&quot;blue3&quot;,&quot;red2&quot;), size = 0.5, conf.int.alpha = 0.15, legend.title = &quot;&quot;, ## p値を表示 pval = TRUE, ## 一般化ウィルコクソン検定の場合は&quot;S1&quot; log.rank.weights = &quot;1&quot;) -&gt; p_km2 p_km2$plot + labs(x = &quot;year&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;top&quot;)+ coord_cartesian(ylim = c(0.15,1)) 図6.2: ロングランク検定の結果を示した生存曲線 Nelson-Aalen法 もう一つよく用いられる方法がNelson-Aalen法であり、累積ハザード関数(ある時点までのハザード率の総和)を推定するための推定量である。時点\\(t_n\\)における累積ハザード率$ H_n\\(の推定値は以下のように定義される。なお、時点\\)t_n\\(でのリスク集合の大きさを\\)l_n\\(、時点\\)t_n\\(に発生した事象の数を\\)d_n$としている。 \\[ \\begin{aligned} H(t_n) &amp;= \\biggl(\\frac{d_1}{l_1}\\biggl) + \\biggl(\\frac{d_2}{l_2}\\biggl) + \\cdots + \\biggl(\\frac{d_n}{l_n}\\biggl) \\\\ &amp;= \\sum_{k=1}^n \\biggl(\\frac{d_k}{l_k}\\biggl) \\end{aligned} \\] Nelson-Aalen推定量は0からスタートし、事象の発生が確認されるたびに値が大きくなる階段関数である。Rではcoxph()で説明変数のないモデルを推定したのち、basehaz()関数で求められる。 est_na &lt;- coxph(Surv(dur, promo) ~ 1, data = rank) basehaz(est_na) 結果の図示はsurvminerパッケージのggsurvplot()関数で、fun = \"cumhaz\"とすることで行うことができる(図6.3)。 fit_na &lt;- survfit(est_na, data = rank, ## 信頼区間の範囲 conf.int = 0.95) ggsurvplot(fit_na, fun = &quot;cumhaz&quot;, data = rank, censor = FALSE, legend = &quot;none&quot;) -&gt; p_na p_na$plot + labs(x = &quot;year&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;) 図6.3: Nelson-Aalen法で推定した累積ハザード関数 生存関数\\(S_n\\)と累積ハザード関数\\(H(t_n)\\)の関係は以下のように記述できる。よって、Nelson-Aalen法で推定した累積ハザード関数から生存関数を推定することもできる。 \\[ S(t_n) = exp[-H(t_n)] \\] Nelson-Aalen法によって推定された生存関数は以下のように図示できる。 est_na2 &lt;- survfit(Surv(dur, promo) ~ 1, data = rank, type = &quot;fh&quot;) ggsurvplot(est_na2, data = rank, censor = FALSE, legend = &quot;none&quot;, palette = &quot;black&quot;, conf.int.alpha = 0.15, size = 0.5) -&gt; p_na2 p_na2$plot + labs(x = &quot;year&quot;)+ theme_bw(base_size = 16)+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ coord_cartesian(ylim = c(0.15,1)) 図6.4: Nelson-Aalen法で推定した生存曲線 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] coxme_2.2-18.1 bdsmatrix_1.3-6 MASS_7.3-58.1 cmprsk_2.2-11 ## [5] survminer_0.4.9 ggpubr_0.5.0 ggplotify_0.1.0 flextable_0.9.1 ## [9] flexsurv_2.2.2 eha_2.10.3 ggeffects_1.1.4 rstanarm_2.21.4 ## [13] brms_2.18.0 Rcpp_1.0.9 fontregisterer_0.3 systemfonts_1.0.4 ## [17] extrafont_0.18 lemon_0.4.6 ggsci_2.9 stargazer_5.2.3 ## [21] kableExtra_1.3.4 knitr_1.42 DT_0.27 patchwork_1.1.2 ## [25] data.table_1.14.6 see_0.7.5.5 report_0.5.7.4 parameters_0.20.3 ## [29] performance_0.10.3 modelbased_0.8.6.3 insight_0.19.1.4 effectsize_0.8.3.6 ## [33] datawizard_0.7.1.1 correlation_0.8.4 bayestestR_0.13.1 easystats_0.6.0.8 ## [37] haven_2.5.1 forcats_1.0.0 stringr_1.5.0 dplyr_1.1.2 ## [41] purrr_1.0.0 readr_2.1.3 tidyr_1.2.1 tibble_3.2.1 ## [45] tidyverse_1.3.2 ggplot2_3.4.2 ggsurvfit_0.3.0 survival_3.5-5 ## ## loaded via a namespace (and not attached): ## [1] utf8_1.2.2 tidyselect_1.2.0 lme4_1.1-31 ## [4] htmlwidgets_1.6.1 grid_4.2.2 munsell_0.5.0 ## [7] ragg_1.2.4 codetools_0.2-18 statmod_1.5.0 ## [10] miniUI_0.1.1.1 withr_2.5.0 Brobdingnag_1.2-9 ## [13] colorspace_2.0-3 muhaz_1.2.6.4 uuid_1.1-0 ## [16] rstudioapi_0.14 stats4_4.2.2 ggsignif_0.6.4 ## [19] officer_0.6.2 Rttf2pt1_1.3.8 fontLiberation_0.1.0 ## [22] bayesplot_1.10.0 emmeans_1.8.3 rstan_2.26.13 ## [25] KMsurv_0.1-5 farver_2.1.1 bridgesampling_1.1-2 ## [28] coda_0.19-4 vctrs_0.6.2 generics_0.1.3 ## [31] xfun_0.36 timechange_0.1.1 fontquiver_0.2.1 ## [34] R6_2.5.1 markdown_1.7 gridGraphics_0.5-1 ## [37] cachem_1.0.6 assertthat_0.2.1 promises_1.2.0.1 ## [40] scales_1.2.1 googlesheets4_1.0.1 gtable_0.3.3 ## [43] processx_3.8.0 rlang_1.1.1 splines_4.2.2 ## [46] rstatix_0.7.1 extrafontdb_1.0 gargle_1.2.1 ## [49] broom_1.0.2 checkmate_2.1.0 inline_0.3.19 ## [52] yaml_2.3.7 reshape2_1.4.4 abind_1.4-5 ## [55] modelr_0.1.10 threejs_0.3.3 crosstalk_1.2.0 ## [58] backports_1.4.1 httpuv_1.6.7 tensorA_0.36.2 ## [61] tools_4.2.2 bookdown_0.31 ellipsis_0.3.2 ## [64] jquerylib_0.1.4 posterior_1.3.1 plyr_1.8.8 ## [67] base64enc_0.1-3 ps_1.7.2 prettyunits_1.1.1 ## [70] openssl_2.0.5 deSolve_1.34 zoo_1.8-11 ## [73] fs_1.5.2 crul_1.3 magrittr_2.0.3 ## [76] colourpicker_1.2.0 reprex_2.0.2 googledrive_2.0.0 ## [79] mvtnorm_1.1-3 matrixStats_0.63.0 hms_1.1.2 ## [82] shinyjs_2.1.0 mime_0.12 evaluate_0.20 ## [85] xtable_1.8-4 shinystan_2.6.0 readxl_1.4.1 ## [88] gridExtra_2.3 rstantools_2.2.0 compiler_4.2.2 ## [91] fontBitstreamVera_0.1.1 V8_4.2.2 crayon_1.5.2 ## [94] minqa_1.2.5 StanHeaders_2.26.13 htmltools_0.5.4 ## [97] later_1.3.0 tzdb_0.3.0 RcppParallel_5.1.6 ## [100] lubridate_1.9.0 DBI_1.1.3 dbplyr_2.2.1 ## [103] boot_1.3-28 car_3.1-1 Matrix_1.5-1 ## [106] cli_3.6.0 quadprog_1.5-8 parallel_4.2.2 ## [109] igraph_1.3.5 km.ci_0.5-6 pkgconfig_2.0.3 ## [112] numDeriv_2016.8-1.1 xml2_1.3.3 dygraphs_1.1.1.6 ## [115] svglite_2.1.1 bslib_0.4.2 webshot_0.5.4 ## [118] estimability_1.4.1 rvest_1.0.3 yulab.utils_0.0.6 ## [121] distributional_0.3.1 callr_3.7.3 digest_0.6.31 ## [124] httpcode_0.3.0 rmarkdown_2.20 cellranger_1.1.0 ## [127] survMisc_0.5.6 gdtools_0.3.3 curl_4.3.3 ## [130] shiny_1.7.4 gtools_3.9.4 nloptr_2.0.3 ## [133] lifecycle_1.0.3 nlme_3.1-160 jsonlite_1.8.4 ## [136] mstate_0.3.2 carData_3.0-5 askpass_1.1 ## [139] viridisLite_0.4.1 fansi_1.0.3 pillar_1.9.0 ## [142] lattice_0.20-45 loo_2.5.1 fastmap_1.1.0 ## [145] httr_1.4.4 pkgbuild_1.4.0 glue_1.6.2 ## [148] xts_0.12.2 zip_2.2.2 shinythemes_1.2.0 ## [151] stringi_1.7.8 sass_0.4.5 textshaping_0.3.6 ## [154] gfonts_0.2.0 References Allison, P. D. (2014). Event history and survival analysis: Regression for longitudinal event data. SAGE Publications. Broström, G. (2021). Event history analysis with R. CRC Press. Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Cox, D. R. (1972). Regression models and life-tables. J. R. Stat. Soc., 34(2), 187–202. Ellis, S., Snyder-Mackler, N., Ruiz-Lambides, A., Platt, M. L., &amp; Brent, L. J. N. (2019). Deconstructing sociality: The types of social connections that predict longevity in a group-living primate. Proc. Biol. Sci., 286(1917), 20191991. Rossi, P. H., Berk, R. A., &amp; Lenihan, K. J. (1980). Money, work and crime: Some experimental results. New York: Academic Press. Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C., Engh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth, R. M., &amp; Cheney, D. L. (2010). Strong and consistent social bonds enhance the longevity of female baboons. Curr. Biol., 20(15), 1359–1361. Swedell, L., Saunders, J., Schreier, A., Davis, B., Tesfaye, T., &amp; Pines, M. (2011). Female “dispersal” in hamadryas baboons: Transfer among social units in a multilevel society. Am. J. Phys. Anthropol., 145(3), 360–370. Thompson, N. A., &amp; Cords, M. (2018). Stronger social bonds do not always predict greater longevity in a gregarious primate. Ecol. Evol., 8(3), 1604–1614. Tung, J., Archie, E. A., Altmann, J., &amp; Alberts, S. C. (2016). Cumulative early life adversity predicts longevity in wild baboons. Nat. Commun., 7. Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 久保拓弥. (2012). データ解析のための統計モデリング入門. 岩波書店. 大東健太郎. (2010). 線形モデルから一般化線形モデル（GLM）へ. 雑草研究, 55(4), 268–274. 大橋靖雄., 浜田知久馬., &amp; 魚住龍史. (2021). 生存時間解析 第2版 SASによる生物統計. 東京大学出版. 杉本知之. (2021). 生存時間解析. 朝倉書店. 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. 粕谷英一. (2012). 一般化線形モデル. 共立出版. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
